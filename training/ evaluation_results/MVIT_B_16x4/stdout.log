[05/07 11:03:40][INFO] train_net.py:  518: Train with config:
[05/07 11:03:40][INFO] train_net.py:  519: {'AUG': {'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1',
         'COLOR_JITTER': 0.4,
         'ENABLE': True,
         'GEN_MASK_LOADER': False,
         'INTERPOLATION': 'bicubic',
         'MASK_FRAMES': False,
         'MASK_RATIO': 0.0,
         'MASK_TUBE': False,
         'MASK_WINDOW_SIZE': [8, 7, 7],
         'MAX_MASK_PATCHES_PER_BLOCK': None,
         'NUM_SAMPLE': 2,
         'RE_COUNT': 1,
         'RE_MODE': 'pixel',
         'RE_PROB': 0.25,
         'RE_SPLIT': False},
 'AVA': {'ANNOTATION_DIR': '../ava/annotations',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.0,
         'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv',
         'FRAME_DIR': '../ava/frames',
         'FRAME_LIST_DIR': '../ava/frame_lists',
         'FULL_TEST_ON_VAL': True,
         'GROUNDTRUTH_FILE': 'ava_val_gt.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'label_map.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'],
         'TRAIN_GT_BOX_LISTS': ['ava_train.csv'],
         'TRAIN_LISTS': ['train.csv'],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': [],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'GLOBAL_SYNC': False,
        'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'CONTRASTIVE': {'BN_MLP': False,
                 'BN_SYNC_MLP': False,
                 'DELTA_CLIPS_MAX': inf,
                 'DELTA_CLIPS_MIN': -inf,
                 'DIM': 128,
                 'INTERP_MEMORY': False,
                 'KNN_ON': True,
                 'LENGTH': 239975,
                 'LOCAL_SHUFFLE_BN': True,
                 'MEM_TYPE': '1d',
                 'MLP_DIM': 2048,
                 'MOCO_MULTI_VIEW_QUEUE': False,
                 'MOMENTUM': 0.5,
                 'MOMENTUM_ANNEALING': False,
                 'NUM_CLASSES_DOWNSTREAM': 400,
                 'NUM_MLP_LAYERS': 1,
                 'PREDICTOR_DEPTHS': [],
                 'QUEUE_LEN': 65536,
                 'SEQUENTIAL': False,
                 'SIMCLR_DIST_ON': True,
                 'SWAV_QEUE_LEN': 0,
                 'T': 0.07,
                 'TYPE': 'mem'},
 'DATA': {'COLOR_RND_GRAYSCALE': 0.0,
          'DECODING_BACKEND': 'torchvision',
          'DECODING_SHORT_SIZE': 256,
          'DUMMY_LOAD': False,
          'ENSEMBLE_METHOD': 'sum',
          'IN22K_TRAINVAL': False,
          'IN22k_VAL_IN1K': '',
          'INPUT_CHANNEL_NUM': [3],
          'INV_UNIFORM_SAMPLE': False,
          'IN_VAL_CROP_RATIO': 0.875,
          'LOADER_CHUNK_OVERALL_SIZE': 0,
          'LOADER_CHUNK_SIZE': 0,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 16,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '../ava',
          'PATH_TO_PRELOAD_IMDB': '',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 4,
          'SKIP_ROWS': 0,
          'SSL_BLUR_SIGMA_MAX': [0.0, 2.0],
          'SSL_BLUR_SIGMA_MIN': [0.0, 0.1],
          'SSL_COLOR_BRI_CON_SAT': [0.4, 0.4, 0.4],
          'SSL_COLOR_HUE': 0.1,
          'SSL_COLOR_JITTER': False,
          'SSL_MOCOV2_AUG': False,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 30,
          'TEST_CROP_SIZE': 224,
          'TIME_DIFF_PROB': 0.0,
          'TRAIN_CROP_NUM_SPATIAL': 1,
          'TRAIN_CROP_NUM_TEMPORAL': 1,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333],
          'TRAIN_JITTER_FPS': 0.0,
          'TRAIN_JITTER_MOTION_SHIFT': False,
          'TRAIN_JITTER_SCALES': [256, 320],
          'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0],
          'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
          'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                               [-0.5808, -0.0045, -0.814],
                               [-0.5836, -0.6948, 0.4203]],
          'USE_OFFSET_SAMPLING': True},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 8,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': True,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 10,
 'MASK': {'DECODER_DEPTH': 0,
          'DECODER_EMBED_DIM': 512,
          'DECODER_SEP_POS_EMBED': False,
          'DEC_KV_KERNEL': [],
          'DEC_KV_STRIDE': [],
          'ENABLE': False,
          'HEAD_TYPE': 'separate',
          'MAE_ON': False,
          'MAE_RND_MASK': False,
          'NORM_PRED_PIXEL': True,
          'PER_FRAME_MASKING': False,
          'PRED_HOG': False,
          'PRETRAIN_DEPTH': [15],
          'SCALE_INIT_BY_DEPTH': False,
          'TIME_STRIDE_LOSS': True},
 'MIXUP': {'ALPHA': 0.8,
           'CUTMIX_ALPHA': 1.0,
           'ENABLE': False,
           'LABEL_SMOOTH_VALUE': 0.1,
           'PROB': 1.0,
           'SWITCH_PROB': 0.5},
 'MODEL': {'ACT_CHECKPOINT': False,
           'ARCH': 'mvit',
           'DETACH_FINAL_FC': False,
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'FP16_ALLREDUCE': False,
           'FROZEN_BN': False,
           'HEAD_ACT': 'none',
           'LOSS_FUNC': 'bce_logit',
           'MODEL_NAME': 'MViT',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 50,
           'SINGLE_PATHWAY_ARCH': ['2d',
                                   'c2d',
                                   'i3d',
                                   'slow',
                                   'x3d',
                                   'mvit',
                                   'maskmvit']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'MVIT': {'CLS_EMBED_ON': True,
          'DEPTH': 16,
          'DIM_MUL': [[1, 2.0], [3, 2.0], [14, 2.0]],
          'DIM_MUL_IN_ATT': False,
          'DROPOUT_RATE': 0.0,
          'DROPPATH_RATE': 0.2,
          'EMBED_DIM': 96,
          'HEAD_INIT_SCALE': 1.0,
          'HEAD_MUL': [[1, 2.0], [3, 2.0], [14, 2.0]],
          'LAYER_SCALE_INIT_VALUE': 0.0,
          'MLP_RATIO': 4.0,
          'MODE': 'conv',
          'NORM': 'layernorm',
          'NORM_STEM': False,
          'NUM_HEADS': 1,
          'PATCH_2D': False,
          'PATCH_KERNEL': [3, 7, 7],
          'PATCH_PADDING': [1, 3, 3],
          'PATCH_STRIDE': [2, 4, 4],
          'POOL_FIRST': False,
          'POOL_KVQ_KERNEL': [3, 3, 3],
          'POOL_KV_STRIDE': [],
          'POOL_KV_STRIDE_ADAPTIVE': [1, 8, 8],
          'POOL_Q_STRIDE': [[1, 1, 2, 2], [3, 1, 2, 2], [14, 1, 2, 2]],
          'QKV_BIAS': True,
          'REL_POS_SPATIAL': False,
          'REL_POS_TEMPORAL': False,
          'REL_POS_ZERO_INIT': False,
          'RESIDUAL_POOLING': False,
          'REV': {'BUFFER_LAYERS': [],
                  'ENABLE': False,
                  'PRE_Q_FUSION': 'avg',
                  'RESPATH_FUSE': 'concat',
                  'RES_PATH': 'conv'},
          'SEPARATE_QKV': False,
          'SEP_POS_EMBED': True,
          'USE_ABS_POS': True,
          'USE_FIXED_SINCOS_POS': False,
          'USE_MEAN_POOLING': False,
          'ZERO_DECAY_POS_CLS': False},
 'NONLOCAL': {'GROUP': [[1], [1], [1], [1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[]], [[]], [[]], [[]]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 3,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '/home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1], [1], [1], [1]],
            'SPATIAL_STRIDES': [[1], [2], [2], [2]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': False,
            'ZERO_INIT_FINAL_CONV': False},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 8,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 5},
 'SOLVER': {'BASE_LR': 0.0001,
            'BASE_LR_SCALE_NUM_SHARDS': False,
            'BETAS': (0.9, 0.999),
            'CLIP_GRAD_L2NORM': 1.0,
            'CLIP_GRAD_VAL': None,
            'COSINE_AFTER_WARMUP': False,
            'COSINE_END_LR': 0.0,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LARS_ON': False,
            'LAYER_DECAY': 1.0,
            'LRS': [1, 0.1, 0.01, 0.001, 0.0001],
            'LR_POLICY': 'steps_with_relative_lrs',
            'MAX_EPOCH': 60,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'adamw',
            'STEPS': [0, 20, 30, 40, 50],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 5.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 1e-06,
            'WEIGHT_DECAY': 0.05,
            'ZERO_WD_1D_PARAM': False},
 'TASK': '',
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': False,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 3,
          'CHECKPOINT_FILE_PATH': '/home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/checkpoints/checkpoint_epoch_00045.pyth',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ava',
          'ENABLE': False,
          'NUM_ENSEMBLE_VIEWS': 10,
          'NUM_SPATIAL_CROPS': 1,
          'NUM_TEMPORAL_CLIPS': [],
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 48,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': True,
           'CHECKPOINT_FILE_PATH': '/home/lqi/lqi_temp/trainingspace/pretrained_models/MVIT_B_16x4.pyth',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_IN_INIT': False,
           'CHECKPOINT_PERIOD': 5,
           'CHECKPOINT_TYPE': 'pytorch',
           'DATASET': 'ava',
           'ENABLE': True,
           'EVAL_PERIOD': 5,
           'KILL_LOSS_EXPLOSION_FACTOR': 0.0,
           'MIXED_PRECISION': True},
 'VIS_MASK': CfgNode({'ENABLE': False}),
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[05/07 11:03:41][INFO] misc.py:  186: Model:
DistributedDataParallel(
  (module): MViT(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
    )
    (blocks): ModuleList(
      (0): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=384, out_features=192, bias=True)
        )
        (proj): Linear(in_features=96, out_features=192, bias=True)
      )
      (1): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (2): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=384, bias=True)
        )
        (proj): Linear(in_features=192, out_features=384, bias=True)
      )
      (3): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (4-12): 9 x MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (13): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=768, bias=True)
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
      )
      (14): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (15): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (head): ResNetRoIHead(
      (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
      (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=768, out_features=50, bias=True)
      (act): Identity()
    )
  )
)
[05/07 11:03:41][INFO] misc.py:  188: Params: 36,341,522
[05/07 11:03:41][INFO] misc.py:  189: Mem: 0.2725391387939453 MB
[05/07 11:03:42][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat encountered 1 time(s)
[05/07 11:03:42][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[05/07 11:03:42][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 33 time(s)
[05/07 11:03:42][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 1 time(s)
[05/07 11:03:42][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 130 time(s)
[05/07 11:03:42][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/07 11:03:42][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/07 11:03:42][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/07 11:03:42][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/07 11:03:42][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/07 11:03:42][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/07 11:03:42][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/07 11:03:42][INFO] misc.py:  191: Flops: 70.803616128 G
[05/07 11:03:43][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat encountered 1 time(s)
[05/07 11:03:43][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[05/07 11:03:43][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 33 time(s)
[05/07 11:03:43][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 1 time(s)
[05/07 11:03:43][WARNING] jit_analysis.py:  499: Unsupported operator aten::layer_norm encountered 68 time(s)
[05/07 11:03:43][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 130 time(s)
[05/07 11:03:43][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/07 11:03:43][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/07 11:03:43][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/07 11:03:43][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/07 11:03:43][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/07 11:03:43][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/07 11:03:43][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/07 11:03:43][INFO] misc.py:  192: Activations: 239.822315 M
[05/07 11:03:43][INFO] misc.py:  197: nvidia-smi
[05/07 11:03:43][INFO] train_net.py:  560: Load from given checkpoint file.
[05/07 11:03:43][INFO] checkpoint.py:  213: Loading network weights from /home/lqi/lqi_temp/trainingspace/pretrained_models/MVIT_B_16x4.pyth.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights cls_token not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights pos_embed_spatial not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights pos_embed_temporal not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights pos_embed_class not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights patch_embed.proj.weight not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights patch_embed.proj.bias not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights blocks.0.attn.qkv.weight not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights blocks.0.attn.qkv.bias not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights blocks.1.attn.qkv.weight not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights blocks.1.attn.qkv.bias not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights blocks.2.attn.qkv.weight not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights blocks.2.attn.qkv.bias not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights blocks.3.attn.qkv.weight not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights blocks.3.attn.qkv.bias not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights blocks.4.attn.qkv.weight not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights blocks.4.attn.qkv.bias not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights blocks.5.attn.qkv.weight not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights blocks.5.attn.qkv.bias not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights blocks.6.attn.qkv.weight not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights blocks.6.attn.qkv.bias not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights blocks.7.attn.qkv.weight not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights blocks.7.attn.qkv.bias not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights blocks.8.attn.qkv.weight not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights blocks.8.attn.qkv.bias not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights blocks.9.attn.qkv.weight not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights blocks.9.attn.qkv.bias not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights blocks.10.attn.qkv.weight not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights blocks.10.attn.qkv.bias not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights blocks.11.attn.qkv.weight not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights blocks.11.attn.qkv.bias not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights blocks.12.attn.qkv.weight not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights blocks.12.attn.qkv.bias not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights blocks.13.attn.qkv.weight not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights blocks.13.attn.qkv.bias not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights blocks.14.attn.qkv.weight not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights blocks.14.attn.qkv.bias not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights blocks.15.attn.qkv.weight not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights blocks.15.attn.qkv.bias not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights norm.weight not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights norm.bias not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights head.projection.weight not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  502: Network weights head.projection.bias not loaded.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights patch_embed.patch_model.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights patch_embed.patch_model.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights cls_positional_encoding.cls_token not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights cls_positional_encoding.pos_embed_spatial not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights cls_positional_encoding.pos_embed_temporal not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights cls_positional_encoding.pos_embed_class not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.0.attn.q.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.0.attn.q.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.0.attn.k.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.0.attn.k.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.0.attn.v.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.0.attn.v.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.1.attn.q.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.1.attn.q.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.1.attn.k.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.1.attn.k.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.1.attn.v.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.1.attn.v.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.2.attn.q.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.2.attn.q.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.2.attn.k.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.2.attn.k.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.2.attn.v.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.2.attn.v.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.3.attn.q.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.3.attn.q.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.3.attn.k.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.3.attn.k.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.3.attn.v.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.3.attn.v.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.4.attn.q.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.4.attn.q.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.4.attn.k.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.4.attn.k.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.4.attn.v.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.4.attn.v.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.5.attn.q.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.5.attn.q.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.5.attn.k.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.5.attn.k.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.5.attn.v.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.5.attn.v.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.6.attn.q.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.6.attn.q.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.6.attn.k.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.6.attn.k.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.6.attn.v.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.6.attn.v.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.7.attn.q.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.7.attn.q.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.7.attn.k.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.7.attn.k.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.7.attn.v.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.7.attn.v.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.8.attn.q.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.8.attn.q.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.8.attn.k.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.8.attn.k.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.8.attn.v.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.8.attn.v.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.9.attn.q.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.9.attn.q.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.9.attn.k.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.9.attn.k.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.9.attn.v.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.9.attn.v.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.10.attn.q.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.10.attn.q.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.10.attn.k.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.10.attn.k.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.10.attn.v.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.10.attn.v.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.11.attn.q.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.11.attn.q.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.11.attn.k.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.11.attn.k.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.11.attn.v.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.11.attn.v.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.12.attn.q.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.12.attn.q.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.12.attn.k.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.12.attn.k.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.12.attn.v.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.12.attn.v.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.13.attn.q.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.13.attn.q.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.13.attn.k.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.13.attn.k.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.13.attn.v.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.13.attn.v.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.14.attn.q.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.14.attn.q.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.14.attn.k.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.14.attn.k.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.14.attn.v.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.14.attn.v.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.15.attn.q.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.15.attn.q.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.15.attn.k.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.15.attn.k.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.15.attn.v.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights blocks.15.attn.v.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights norm_embed.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights norm_embed.bias not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights head.proj.weight not used.
[05/07 11:03:46][INFO] checkpoint.py:  505: Network weights head.proj.bias not used.
[05/07 11:03:46][INFO] ava_helper.py:   58: Finished loading image paths from: ../ava/frame_lists/train.csv
[05/07 11:03:47][INFO] ava_helper.py:  139: Finished loading annotations from: ../ava/annotations/ava_train.csv
[05/07 11:03:47][INFO] ava_helper.py:  140: Detection threshold: 0.0
[05/07 11:03:47][INFO] ava_helper.py:  141: Number of unique boxes: 4029
[05/07 11:03:47][INFO] ava_helper.py:  142: Number of annotations: 9266
[05/07 11:03:47][INFO] ava_helper.py:  185: 3835 keyframes used.
[05/07 11:03:47][INFO] ava_dataset.py:  130: === AVA dataset summary ===
[05/07 11:03:47][INFO] ava_dataset.py:  131: Split: train
[05/07 11:03:47][INFO] ava_dataset.py:  132: Number of videos: 3331
[05/07 11:03:47][INFO] ava_dataset.py:  136: Number of frames: 299789
[05/07 11:03:47][INFO] ava_dataset.py:  137: Number of key frames: 3835
[05/07 11:03:47][INFO] ava_dataset.py:  138: Number of boxes: 4029.
[05/07 11:03:47][INFO] ava_helper.py:   58: Finished loading image paths from: ../ava/frame_lists/val.csv
[05/07 11:03:47][INFO] ava_helper.py:  139: Finished loading annotations from: ../ava/annotations/ava_val_predicted_boxes.csv
[05/07 11:03:47][INFO] ava_helper.py:  140: Detection threshold: 0.0
[05/07 11:03:47][INFO] ava_helper.py:  141: Number of unique boxes: 570
[05/07 11:03:47][INFO] ava_helper.py:  142: Number of annotations: 0
[05/07 11:03:47][INFO] ava_helper.py:  185: 542 keyframes used.
[05/07 11:03:47][INFO] ava_dataset.py:  130: === AVA dataset summary ===
[05/07 11:03:47][INFO] ava_dataset.py:  131: Split: val
[05/07 11:03:47][INFO] ava_dataset.py:  132: Number of videos: 475
[05/07 11:03:47][INFO] ava_dataset.py:  136: Number of frames: 42751
[05/07 11:03:47][INFO] ava_dataset.py:  137: Number of key frames: 542
[05/07 11:03:47][INFO] ava_dataset.py:  138: Number of boxes: 570.
[05/07 11:03:47][INFO] ava_helper.py:   58: Finished loading image paths from: ../ava/frame_lists/train.csv
[05/07 11:03:47][INFO] ava_helper.py:   58: Finished loading image paths from: ../ava/frame_lists/val.csv
[05/07 11:03:47][INFO] train_net.py:  611: Start epoch: 1
[05/07 11:04:29][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "1/60", "cur_iter": "10", "eta": "0:00:49", "dt": 0.70937, "dt_data": 0.00046, "dt_net": 0.70891, "mode": "train", "loss": 0.70860, "lr": 0.00000}
[05/07 11:04:37][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "1/60", "cur_iter": "20", "eta": "0:00:43", "dt": 0.72102, "dt_data": 0.00045, "dt_net": 0.72057, "mode": "train", "loss": 0.68938, "lr": 0.00001}
[05/07 11:04:44][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "1/60", "cur_iter": "30", "eta": "0:00:36", "dt": 0.73109, "dt_data": 0.00044, "dt_net": 0.73065, "mode": "train", "loss": 0.65361, "lr": 0.00001}
[05/07 11:04:51][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "1/60", "cur_iter": "40", "eta": "0:00:29", "dt": 0.73842, "dt_data": 0.00039, "dt_net": 0.73803, "mode": "train", "loss": 0.59890, "lr": 0.00001}
[05/07 11:04:59][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "1/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.73906, "dt_data": 0.00037, "dt_net": 0.73868, "mode": "train", "loss": 0.54365, "lr": 0.00001}
[05/07 11:05:06][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "1/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.75099, "dt_data": 0.00044, "dt_net": 0.75055, "mode": "train", "loss": 0.47496, "lr": 0.00002}
[05/07 11:05:14][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "1/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.75331, "dt_data": 0.00023, "dt_net": 0.75308, "mode": "train", "loss": 0.45183, "lr": 0.00002}
[05/07 11:05:21][INFO] train_net.py:  669: Epoch 0 takes 94.01s. Epochs from 0 to 0 take 94.01s in average and 94.01s in median.
[05/07 11:05:21][INFO] train_net.py:  675: For epoch 0, each iteraction takes 1.19s in average. From epoch 0 to 0, each iteraction takes 1.19s in average.
[05/07 11:06:04][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "2/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71802, "dt_data": 0.00040, "dt_net": 0.71762, "mode": "train", "loss": 0.40178, "lr": 0.00002}
[05/07 11:06:11][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "2/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.73459, "dt_data": 0.00037, "dt_net": 0.73423, "mode": "train", "loss": 0.37970, "lr": 0.00003}
[05/07 11:06:18][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "2/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.74440, "dt_data": 0.00036, "dt_net": 0.74404, "mode": "train", "loss": 0.35697, "lr": 0.00003}
[05/07 11:06:26][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "2/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75738, "dt_data": 0.00038, "dt_net": 0.75700, "mode": "train", "loss": 0.32701, "lr": 0.00003}
[05/07 11:06:33][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "2/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.75425, "dt_data": 0.00040, "dt_net": 0.75384, "mode": "train", "loss": 0.29796, "lr": 0.00003}
[05/07 11:06:41][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "2/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.75716, "dt_data": 0.00039, "dt_net": 0.75678, "mode": "train", "loss": 0.30157, "lr": 0.00004}
[05/07 11:06:48][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "2/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.74043, "dt_data": 0.00022, "dt_net": 0.74021, "mode": "train", "loss": 0.30253, "lr": 0.00004}
[05/07 11:06:56][INFO] train_net.py:  669: Epoch 1 takes 94.83s. Epochs from 0 to 1 take 94.42s in average and 94.42s in median.
[05/07 11:06:56][INFO] train_net.py:  675: For epoch 1, each iteraction takes 1.20s in average. From epoch 0 to 1, each iteraction takes 1.20s in average.
[05/07 11:07:38][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "3/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71571, "dt_data": 0.00039, "dt_net": 0.71532, "mode": "train", "loss": 0.29216, "lr": 0.00004}
[05/07 11:07:46][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "3/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.73718, "dt_data": 0.00036, "dt_net": 0.73682, "mode": "train", "loss": 0.27747, "lr": 0.00005}
[05/07 11:07:53][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "3/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.74549, "dt_data": 0.00030, "dt_net": 0.74519, "mode": "train", "loss": 0.25142, "lr": 0.00005}
[05/07 11:08:01][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "3/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75211, "dt_data": 0.00035, "dt_net": 0.75176, "mode": "train", "loss": 0.28464, "lr": 0.00005}
[05/07 11:08:08][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "3/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.75855, "dt_data": 0.00036, "dt_net": 0.75818, "mode": "train", "loss": 0.27010, "lr": 0.00005}
[05/07 11:08:16][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "3/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.75871, "dt_data": 0.00044, "dt_net": 0.75826, "mode": "train", "loss": 0.26454, "lr": 0.00006}
[05/07 11:08:23][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "3/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.75878, "dt_data": 0.00021, "dt_net": 0.75857, "mode": "train", "loss": 0.23512, "lr": 0.00006}
[05/07 11:08:31][INFO] train_net.py:  669: Epoch 2 takes 94.97s. Epochs from 0 to 2 take 94.60s in average and 94.83s in median.
[05/07 11:08:31][INFO] train_net.py:  675: For epoch 2, each iteraction takes 1.20s in average. From epoch 0 to 2, each iteraction takes 1.20s in average.
[05/07 11:09:11][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "4/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71990, "dt_data": 0.00042, "dt_net": 0.71947, "mode": "train", "loss": 0.24768, "lr": 0.00006}
[05/07 11:09:18][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "4/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.74092, "dt_data": 0.00046, "dt_net": 0.74045, "mode": "train", "loss": 0.23704, "lr": 0.00007}
[05/07 11:09:25][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "4/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.74835, "dt_data": 0.00050, "dt_net": 0.74785, "mode": "train", "loss": 0.26802, "lr": 0.00007}
[05/07 11:09:33][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "4/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75677, "dt_data": 0.00040, "dt_net": 0.75636, "mode": "train", "loss": 0.27026, "lr": 0.00007}
[05/07 11:09:40][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "4/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.76557, "dt_data": 0.00037, "dt_net": 0.76520, "mode": "train", "loss": 0.24167, "lr": 0.00007}
[05/07 11:09:48][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "4/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.76320, "dt_data": 0.00045, "dt_net": 0.76276, "mode": "train", "loss": 0.24653, "lr": 0.00008}
[05/07 11:09:56][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "4/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.76453, "dt_data": 0.00021, "dt_net": 0.76431, "mode": "train", "loss": 0.26838, "lr": 0.00008}
[05/07 11:10:04][INFO] train_net.py:  669: Epoch 3 takes 92.41s. Epochs from 0 to 3 take 94.06s in average and 94.42s in median.
[05/07 11:10:04][INFO] train_net.py:  675: For epoch 3, each iteraction takes 1.17s in average. From epoch 0 to 3, each iteraction takes 1.19s in average.
[05/07 11:10:43][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "5/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71960, "dt_data": 0.00039, "dt_net": 0.71920, "mode": "train", "loss": 0.24222, "lr": 0.00008}
[05/07 11:10:50][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "5/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.74274, "dt_data": 0.00039, "dt_net": 0.74234, "mode": "train", "loss": 0.23045, "lr": 0.00008}
[05/07 11:10:58][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "5/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.74900, "dt_data": 0.00036, "dt_net": 0.74864, "mode": "train", "loss": 0.26156, "lr": 0.00009}
[05/07 11:11:05][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "5/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75064, "dt_data": 0.00040, "dt_net": 0.75024, "mode": "train", "loss": 0.24638, "lr": 0.00009}
[05/07 11:11:13][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "5/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.74053, "dt_data": 0.00037, "dt_net": 0.74016, "mode": "train", "loss": 0.25047, "lr": 0.00009}
[05/07 11:11:20][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "5/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.75862, "dt_data": 0.00043, "dt_net": 0.75819, "mode": "train", "loss": 0.26363, "lr": 0.00009}
[05/07 11:11:28][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "5/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.75643, "dt_data": 0.00021, "dt_net": 0.75622, "mode": "train", "loss": 0.24376, "lr": 0.00010}
[05/07 11:11:36][INFO] train_net.py:  669: Epoch 4 takes 92.29s. Epochs from 0 to 4 take 93.70s in average and 94.01s in median.
[05/07 11:11:36][INFO] train_net.py:  675: For epoch 4, each iteraction takes 1.17s in average. From epoch 0 to 4, each iteraction takes 1.19s in average.
[05/07 11:12:15][INFO] logging.py:   98: json_stats: {"_type": "val_iter", "cur_epoch": "5/60", "cur_iter": "10", "eta": "0:00:01", "dt": 0.36033, "dt_data": 0.01201, "dt_net": 0.34832, "mode": "val"}
[05/07 11:12:16][INFO] ava_eval_helper.py:  204: Evaluating with 542 unique GT frames.
[05/07 11:12:16][INFO] ava_eval_helper.py:  208: Evaluating with 542 unique detection frames
[05/07 11:12:16][INFO] ava_eval_helper.py:  469: AVA results wrote to detections_latest.csv
[05/07 11:12:16][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 11:12:16][INFO] ava_eval_helper.py:  469: AVA results wrote to groundtruth_latest.csv
[05/07 11:12:16][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 11:12:19][INFO] object_detection_evaluation.py:  751: The following classes have no ground truth examples: [ 2  3  4  5 10 13 15 16 18 19 20 21 23 25 28 31 32 33 35 37 39 40 41 42
 44 49 50 51 52 53 54 55 56 57 63 64 67 68 70 71 72 73 75 77]
[05/07 11:12:20][INFO] ava_eval_helper.py:  298: mAP@0.5 = 0.11208 | macro-F1 = 0.04332 | macro-AUROC = 0.59226 | macro-recall = 0.04118
[05/07 11:12:20][INFO] logging.py:   98: json_stats: {"mode": "val", "cur_epoch": "5", "map": 0.11208, "f1_macro": 0.04332, "auroc_macro": 0.59226, "recall_macro": 0.04118, "gpu_mem": "16.96G", "RAM": "67.49/251.58G", "_type": "val_epoch"}
[05/07 11:12:20][INFO] ava_eval_helper.py:  469: AVA results wrote to /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/detections_val_5.csv
[05/07 11:12:20][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 11:12:20][INFO] meters.py:  327: Saved CSVs:
  per-class AP: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/ap_per_class_val_5.csv
  detections: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/detections_val_5.csv
[05/07 11:13:03][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "6/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71656, "dt_data": 0.00038, "dt_net": 0.71618, "mode": "train", "loss": 0.24279, "lr": 0.00010}
[05/07 11:13:10][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "6/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.73539, "dt_data": 0.00041, "dt_net": 0.73498, "mode": "train", "loss": 0.21185, "lr": 0.00010}
[05/07 11:13:18][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "6/60", "cur_iter": "30", "eta": "0:00:36", "dt": 0.73776, "dt_data": 0.00037, "dt_net": 0.73738, "mode": "train", "loss": 0.23769, "lr": 0.00010}
[05/07 11:13:25][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "6/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75056, "dt_data": 0.00044, "dt_net": 0.75012, "mode": "train", "loss": 0.21333, "lr": 0.00010}
[05/07 11:13:33][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "6/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.75248, "dt_data": 0.00039, "dt_net": 0.75209, "mode": "train", "loss": 0.23282, "lr": 0.00010}
[05/07 11:13:40][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "6/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.75324, "dt_data": 0.00041, "dt_net": 0.75282, "mode": "train", "loss": 0.24310, "lr": 0.00010}
[05/07 11:13:48][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "6/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.74121, "dt_data": 0.00022, "dt_net": 0.74099, "mode": "train", "loss": 0.23854, "lr": 0.00010}
[05/07 11:13:56][INFO] train_net.py:  669: Epoch 5 takes 96.34s. Epochs from 0 to 5 take 94.14s in average and 94.42s in median.
[05/07 11:13:56][INFO] train_net.py:  675: For epoch 5, each iteraction takes 1.22s in average. From epoch 0 to 5, each iteraction takes 1.19s in average.
[05/07 11:14:36][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "7/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.72358, "dt_data": 0.00049, "dt_net": 0.72309, "mode": "train", "loss": 0.23563, "lr": 0.00010}
[05/07 11:14:43][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "7/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.73973, "dt_data": 0.00048, "dt_net": 0.73925, "mode": "train", "loss": 0.22318, "lr": 0.00010}
[05/07 11:14:50][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "7/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.75187, "dt_data": 0.00050, "dt_net": 0.75136, "mode": "train", "loss": 0.25089, "lr": 0.00010}
[05/07 11:14:58][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "7/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75016, "dt_data": 0.00039, "dt_net": 0.74976, "mode": "train", "loss": 0.24180, "lr": 0.00010}
[05/07 11:15:06][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "7/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.75682, "dt_data": 0.00043, "dt_net": 0.75640, "mode": "train", "loss": 0.24528, "lr": 0.00010}
[05/07 11:15:13][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "7/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.76054, "dt_data": 0.00047, "dt_net": 0.76007, "mode": "train", "loss": 0.22746, "lr": 0.00010}
[05/07 11:15:21][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "7/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.76078, "dt_data": 0.00021, "dt_net": 0.76057, "mode": "train", "loss": 0.24769, "lr": 0.00010}
[05/07 11:15:29][INFO] train_net.py:  669: Epoch 6 takes 92.70s. Epochs from 0 to 6 take 93.94s in average and 94.01s in median.
[05/07 11:15:29][INFO] train_net.py:  675: For epoch 6, each iteraction takes 1.17s in average. From epoch 0 to 6, each iteraction takes 1.19s in average.
[05/07 11:16:09][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "8/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71973, "dt_data": 0.00036, "dt_net": 0.71937, "mode": "train", "loss": 0.21908, "lr": 0.00010}
[05/07 11:16:17][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "8/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.73796, "dt_data": 0.00041, "dt_net": 0.73755, "mode": "train", "loss": 0.22398, "lr": 0.00010}
[05/07 11:16:24][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "8/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.74869, "dt_data": 0.00035, "dt_net": 0.74834, "mode": "train", "loss": 0.23643, "lr": 0.00010}
[05/07 11:16:32][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "8/60", "cur_iter": "40", "eta": "0:00:29", "dt": 0.74198, "dt_data": 0.00033, "dt_net": 0.74164, "mode": "train", "loss": 0.22766, "lr": 0.00010}
[05/07 11:16:39][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "8/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.75247, "dt_data": 0.00038, "dt_net": 0.75209, "mode": "train", "loss": 0.25139, "lr": 0.00010}
[05/07 11:16:47][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "8/60", "cur_iter": "60", "eta": "0:00:14", "dt": 0.74612, "dt_data": 0.00046, "dt_net": 0.74566, "mode": "train", "loss": 0.24360, "lr": 0.00010}
[05/07 11:16:54][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "8/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.72648, "dt_data": 0.00021, "dt_net": 0.72626, "mode": "train", "loss": 0.23537, "lr": 0.00010}
[05/07 11:17:02][INFO] train_net.py:  669: Epoch 7 takes 93.30s. Epochs from 0 to 7 take 93.86s in average and 93.66s in median.
[05/07 11:17:02][INFO] train_net.py:  675: For epoch 7, each iteraction takes 1.18s in average. From epoch 0 to 7, each iteraction takes 1.19s in average.
[05/07 11:17:41][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "9/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71922, "dt_data": 0.00061, "dt_net": 0.71861, "mode": "train", "loss": 0.21701, "lr": 0.00010}
[05/07 11:17:48][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "9/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.73867, "dt_data": 0.00039, "dt_net": 0.73828, "mode": "train", "loss": 0.26374, "lr": 0.00010}
[05/07 11:17:56][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "9/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.74862, "dt_data": 0.00041, "dt_net": 0.74821, "mode": "train", "loss": 0.24152, "lr": 0.00010}
[05/07 11:18:03][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "9/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75156, "dt_data": 0.00039, "dt_net": 0.75117, "mode": "train", "loss": 0.21921, "lr": 0.00010}
[05/07 11:18:11][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "9/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.76313, "dt_data": 0.00041, "dt_net": 0.76271, "mode": "train", "loss": 0.21712, "lr": 0.00010}
[05/07 11:18:18][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "9/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.75833, "dt_data": 0.00045, "dt_net": 0.75788, "mode": "train", "loss": 0.20359, "lr": 0.00010}
[05/07 11:18:26][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "9/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.75947, "dt_data": 0.00024, "dt_net": 0.75922, "mode": "train", "loss": 0.22845, "lr": 0.00010}
[05/07 11:18:34][INFO] train_net.py:  669: Epoch 8 takes 92.03s. Epochs from 0 to 8 take 93.66s in average and 93.30s in median.
[05/07 11:18:34][INFO] train_net.py:  675: For epoch 8, each iteraction takes 1.16s in average. From epoch 0 to 8, each iteraction takes 1.19s in average.
[05/07 11:19:16][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "10/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71701, "dt_data": 0.00048, "dt_net": 0.71653, "mode": "train", "loss": 0.21922, "lr": 0.00010}
[05/07 11:19:23][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "10/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.74183, "dt_data": 0.00042, "dt_net": 0.74140, "mode": "train", "loss": 0.22546, "lr": 0.00010}
[05/07 11:19:30][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "10/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.75033, "dt_data": 0.00045, "dt_net": 0.74987, "mode": "train", "loss": 0.24041, "lr": 0.00010}
[05/07 11:19:38][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "10/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75014, "dt_data": 0.00064, "dt_net": 0.74949, "mode": "train", "loss": 0.22958, "lr": 0.00010}
[05/07 11:19:45][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "10/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.74243, "dt_data": 0.00067, "dt_net": 0.74175, "mode": "train", "loss": 0.23279, "lr": 0.00010}
[05/07 11:19:53][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "10/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.75654, "dt_data": 0.00056, "dt_net": 0.75597, "mode": "train", "loss": 0.21238, "lr": 0.00010}
[05/07 11:20:01][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "10/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.74780, "dt_data": 0.00021, "dt_net": 0.74758, "mode": "train", "loss": 0.24223, "lr": 0.00010}
[05/07 11:20:08][INFO] train_net.py:  669: Epoch 9 takes 94.49s. Epochs from 0 to 9 take 93.74s in average and 93.66s in median.
[05/07 11:20:08][INFO] train_net.py:  675: For epoch 9, each iteraction takes 1.20s in average. From epoch 0 to 9, each iteraction takes 1.19s in average.
[05/07 11:20:47][INFO] logging.py:   98: json_stats: {"_type": "val_iter", "cur_epoch": "10/60", "cur_iter": "10", "eta": "0:00:01", "dt": 0.36120, "dt_data": 0.01219, "dt_net": 0.34900, "mode": "val"}
[05/07 11:20:48][INFO] ava_eval_helper.py:  204: Evaluating with 542 unique GT frames.
[05/07 11:20:48][INFO] ava_eval_helper.py:  208: Evaluating with 542 unique detection frames
[05/07 11:20:48][INFO] ava_eval_helper.py:  469: AVA results wrote to detections_latest.csv
[05/07 11:20:48][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 11:20:48][INFO] ava_eval_helper.py:  469: AVA results wrote to groundtruth_latest.csv
[05/07 11:20:48][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 11:20:51][INFO] object_detection_evaluation.py:  751: The following classes have no ground truth examples: [ 2  3  4  5 10 13 15 16 18 19 20 21 23 25 28 31 32 33 35 37 39 40 41 42
 44 49 50 51 52 53 54 55 56 57 63 64 67 68 70 71 72 73 75 77]
[05/07 11:20:52][INFO] ava_eval_helper.py:  298: mAP@0.5 = 0.12172 | macro-F1 = 0.04402 | macro-AUROC = 0.62102 | macro-recall = 0.04264
[05/07 11:20:52][INFO] logging.py:   98: json_stats: {"mode": "val", "cur_epoch": "10", "map": 0.12172, "f1_macro": 0.04402, "auroc_macro": 0.62102, "recall_macro": 0.04264, "gpu_mem": "16.96G", "RAM": "67.35/251.58G", "_type": "val_epoch"}
[05/07 11:20:52][INFO] ava_eval_helper.py:  469: AVA results wrote to /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/detections_val_10.csv
[05/07 11:20:52][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 11:20:52][INFO] meters.py:  327: Saved CSVs:
  per-class AP: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/ap_per_class_val_10.csv
  detections: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/detections_val_10.csv
[05/07 11:21:32][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "11/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71648, "dt_data": 0.00048, "dt_net": 0.71600, "mode": "train", "loss": 0.19754, "lr": 0.00010}
[05/07 11:21:39][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "11/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.73633, "dt_data": 0.00045, "dt_net": 0.73588, "mode": "train", "loss": 0.21443, "lr": 0.00010}
[05/07 11:21:47][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "11/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.75715, "dt_data": 0.00038, "dt_net": 0.75677, "mode": "train", "loss": 0.23147, "lr": 0.00010}
[05/07 11:21:54][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "11/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75018, "dt_data": 0.00042, "dt_net": 0.74976, "mode": "train", "loss": 0.20721, "lr": 0.00010}
[05/07 11:22:02][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "11/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.75232, "dt_data": 0.00059, "dt_net": 0.75173, "mode": "train", "loss": 0.22867, "lr": 0.00010}
[05/07 11:22:09][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "11/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.75565, "dt_data": 0.00045, "dt_net": 0.75520, "mode": "train", "loss": 0.23529, "lr": 0.00010}
[05/07 11:22:17][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "11/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.75879, "dt_data": 0.00020, "dt_net": 0.75858, "mode": "train", "loss": 0.22513, "lr": 0.00010}
[05/07 11:22:25][INFO] train_net.py:  669: Epoch 10 takes 93.31s. Epochs from 0 to 10 take 93.70s in average and 93.31s in median.
[05/07 11:22:25][INFO] train_net.py:  675: For epoch 10, each iteraction takes 1.18s in average. From epoch 0 to 10, each iteraction takes 1.19s in average.
[05/07 11:23:05][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "12/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.72076, "dt_data": 0.00039, "dt_net": 0.72036, "mode": "train", "loss": 0.20795, "lr": 0.00010}
[05/07 11:23:12][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "12/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.74628, "dt_data": 0.00040, "dt_net": 0.74587, "mode": "train", "loss": 0.21424, "lr": 0.00010}
[05/07 11:23:20][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "12/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.74737, "dt_data": 0.00042, "dt_net": 0.74696, "mode": "train", "loss": 0.21658, "lr": 0.00010}
[05/07 11:23:27][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "12/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75713, "dt_data": 0.00059, "dt_net": 0.75653, "mode": "train", "loss": 0.22838, "lr": 0.00010}
[05/07 11:23:35][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "12/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.75256, "dt_data": 0.00045, "dt_net": 0.75211, "mode": "train", "loss": 0.21249, "lr": 0.00010}
[05/07 11:23:42][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "12/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.76328, "dt_data": 0.00043, "dt_net": 0.76285, "mode": "train", "loss": 0.23702, "lr": 0.00010}
[05/07 11:23:50][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "12/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.76960, "dt_data": 0.00021, "dt_net": 0.76939, "mode": "train", "loss": 0.22502, "lr": 0.00010}
[05/07 11:23:58][INFO] train_net.py:  669: Epoch 11 takes 93.03s. Epochs from 0 to 11 take 93.64s in average and 93.31s in median.
[05/07 11:23:58][INFO] train_net.py:  675: For epoch 11, each iteraction takes 1.18s in average. From epoch 0 to 11, each iteraction takes 1.19s in average.
[05/07 11:24:37][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "13/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71955, "dt_data": 0.00043, "dt_net": 0.71912, "mode": "train", "loss": 0.24568, "lr": 0.00010}
[05/07 11:24:45][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "13/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.74214, "dt_data": 0.00039, "dt_net": 0.74175, "mode": "train", "loss": 0.20998, "lr": 0.00010}
[05/07 11:24:52][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "13/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.75230, "dt_data": 0.00040, "dt_net": 0.75190, "mode": "train", "loss": 0.21741, "lr": 0.00010}
[05/07 11:25:00][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "13/60", "cur_iter": "40", "eta": "0:00:29", "dt": 0.74927, "dt_data": 0.00041, "dt_net": 0.74886, "mode": "train", "loss": 0.23448, "lr": 0.00010}
[05/07 11:25:07][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "13/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.76123, "dt_data": 0.00041, "dt_net": 0.76082, "mode": "train", "loss": 0.22203, "lr": 0.00010}
[05/07 11:25:15][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "13/60", "cur_iter": "60", "eta": "0:00:14", "dt": 0.74973, "dt_data": 0.00067, "dt_net": 0.74906, "mode": "train", "loss": 0.21528, "lr": 0.00010}
[05/07 11:25:22][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "13/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.74603, "dt_data": 0.00023, "dt_net": 0.74580, "mode": "train", "loss": 0.22735, "lr": 0.00010}
[05/07 11:25:30][INFO] train_net.py:  669: Epoch 12 takes 92.23s. Epochs from 0 to 12 take 93.54s in average and 93.30s in median.
[05/07 11:25:30][INFO] train_net.py:  675: For epoch 12, each iteraction takes 1.17s in average. From epoch 0 to 12, each iteraction takes 1.18s in average.
[05/07 11:26:10][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "14/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.72044, "dt_data": 0.00033, "dt_net": 0.72010, "mode": "train", "loss": 0.23388, "lr": 0.00010}
[05/07 11:26:17][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "14/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.74263, "dt_data": 0.00051, "dt_net": 0.74211, "mode": "train", "loss": 0.21531, "lr": 0.00010}
[05/07 11:26:25][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "14/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.75633, "dt_data": 0.00043, "dt_net": 0.75590, "mode": "train", "loss": 0.21956, "lr": 0.00010}
[05/07 11:26:32][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "14/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75315, "dt_data": 0.00045, "dt_net": 0.75270, "mode": "train", "loss": 0.23340, "lr": 0.00010}
[05/07 11:26:40][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "14/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.75936, "dt_data": 0.00039, "dt_net": 0.75897, "mode": "train", "loss": 0.22809, "lr": 0.00010}
[05/07 11:26:48][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "14/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.76269, "dt_data": 0.00042, "dt_net": 0.76227, "mode": "train", "loss": 0.22342, "lr": 0.00010}
[05/07 11:26:55][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "14/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.76482, "dt_data": 0.00024, "dt_net": 0.76458, "mode": "train", "loss": 0.21381, "lr": 0.00010}
[05/07 11:27:03][INFO] train_net.py:  669: Epoch 13 takes 93.02s. Epochs from 0 to 13 take 93.50s in average and 93.17s in median.
[05/07 11:27:03][INFO] train_net.py:  675: For epoch 13, each iteraction takes 1.18s in average. From epoch 0 to 13, each iteraction takes 1.18s in average.
[05/07 11:27:43][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "15/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71851, "dt_data": 0.00039, "dt_net": 0.71812, "mode": "train", "loss": 0.24736, "lr": 0.00010}
[05/07 11:27:50][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "15/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.74501, "dt_data": 0.00047, "dt_net": 0.74454, "mode": "train", "loss": 0.21488, "lr": 0.00010}
[05/07 11:27:58][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "15/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.75518, "dt_data": 0.00061, "dt_net": 0.75457, "mode": "train", "loss": 0.24921, "lr": 0.00010}
[05/07 11:28:05][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "15/60", "cur_iter": "40", "eta": "0:00:29", "dt": 0.73695, "dt_data": 0.00039, "dt_net": 0.73656, "mode": "train", "loss": 0.21293, "lr": 0.00010}
[05/07 11:28:13][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "15/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.75670, "dt_data": 0.00044, "dt_net": 0.75625, "mode": "train", "loss": 0.22944, "lr": 0.00010}
[05/07 11:28:21][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "15/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.76430, "dt_data": 0.00046, "dt_net": 0.76383, "mode": "train", "loss": 0.21102, "lr": 0.00010}
[05/07 11:28:28][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "15/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.76769, "dt_data": 0.00022, "dt_net": 0.76746, "mode": "train", "loss": 0.21925, "lr": 0.00010}
[05/07 11:28:36][INFO] train_net.py:  669: Epoch 14 takes 93.06s. Epochs from 0 to 14 take 93.47s in average and 93.06s in median.
[05/07 11:28:36][INFO] train_net.py:  675: For epoch 14, each iteraction takes 1.18s in average. From epoch 0 to 14, each iteraction takes 1.18s in average.
[05/07 11:29:14][INFO] logging.py:   98: json_stats: {"_type": "val_iter", "cur_epoch": "15/60", "cur_iter": "10", "eta": "0:00:01", "dt": 0.36160, "dt_data": 0.01212, "dt_net": 0.34948, "mode": "val"}
[05/07 11:29:16][INFO] ava_eval_helper.py:  204: Evaluating with 542 unique GT frames.
[05/07 11:29:16][INFO] ava_eval_helper.py:  208: Evaluating with 542 unique detection frames
[05/07 11:29:16][INFO] ava_eval_helper.py:  469: AVA results wrote to detections_latest.csv
[05/07 11:29:16][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 11:29:16][INFO] ava_eval_helper.py:  469: AVA results wrote to groundtruth_latest.csv
[05/07 11:29:16][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 11:29:19][INFO] object_detection_evaluation.py:  751: The following classes have no ground truth examples: [ 2  3  4  5 10 13 15 16 18 19 20 21 23 25 28 31 32 33 35 37 39 40 41 42
 44 49 50 51 52 53 54 55 56 57 63 64 67 68 70 71 72 73 75 77]
[05/07 11:29:19][INFO] ava_eval_helper.py:  298: mAP@0.5 = 0.12860 | macro-F1 = 0.04331 | macro-AUROC = 0.66430 | macro-recall = 0.03844
[05/07 11:29:19][INFO] logging.py:   98: json_stats: {"mode": "val", "cur_epoch": "15", "map": 0.12860, "f1_macro": 0.04331, "auroc_macro": 0.66430, "recall_macro": 0.03844, "gpu_mem": "16.96G", "RAM": "67.37/251.58G", "_type": "val_epoch"}
[05/07 11:29:19][INFO] ava_eval_helper.py:  469: AVA results wrote to /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/detections_val_15.csv
[05/07 11:29:19][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 11:29:19][INFO] meters.py:  327: Saved CSVs:
  per-class AP: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/ap_per_class_val_15.csv
  detections: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/detections_val_15.csv
[05/07 11:30:03][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "16/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71707, "dt_data": 0.00044, "dt_net": 0.71662, "mode": "train", "loss": 0.22412, "lr": 0.00010}
[05/07 11:30:11][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "16/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.73732, "dt_data": 0.00036, "dt_net": 0.73696, "mode": "train", "loss": 0.23348, "lr": 0.00010}
[05/07 11:30:18][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "16/60", "cur_iter": "30", "eta": "0:00:36", "dt": 0.73544, "dt_data": 0.00039, "dt_net": 0.73505, "mode": "train", "loss": 0.23557, "lr": 0.00010}
[05/07 11:30:26][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "16/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75600, "dt_data": 0.00038, "dt_net": 0.75561, "mode": "train", "loss": 0.24539, "lr": 0.00010}
[05/07 11:30:33][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "16/60", "cur_iter": "50", "eta": "0:00:23", "dt": 0.77129, "dt_data": 0.00040, "dt_net": 0.77088, "mode": "train", "loss": 0.21801, "lr": 0.00010}
[05/07 11:30:41][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "16/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.77516, "dt_data": 0.00047, "dt_net": 0.77469, "mode": "train", "loss": 0.19815, "lr": 0.00010}
[05/07 11:30:48][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "16/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.73841, "dt_data": 0.00021, "dt_net": 0.73820, "mode": "train", "loss": 0.24949, "lr": 0.00010}
[05/07 11:30:56][INFO] train_net.py:  669: Epoch 15 takes 97.08s. Epochs from 0 to 15 take 93.70s in average and 93.18s in median.
[05/07 11:30:56][INFO] train_net.py:  675: For epoch 15, each iteraction takes 1.23s in average. From epoch 0 to 15, each iteraction takes 1.19s in average.
[05/07 11:31:37][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "17/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71839, "dt_data": 0.00041, "dt_net": 0.71798, "mode": "train", "loss": 0.22302, "lr": 0.00010}
[05/07 11:31:44][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "17/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.74323, "dt_data": 0.00045, "dt_net": 0.74278, "mode": "train", "loss": 0.19198, "lr": 0.00010}
[05/07 11:31:51][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "17/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.75013, "dt_data": 0.00055, "dt_net": 0.74958, "mode": "train", "loss": 0.23070, "lr": 0.00010}
[05/07 11:31:59][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "17/60", "cur_iter": "40", "eta": "0:00:29", "dt": 0.74734, "dt_data": 0.00038, "dt_net": 0.74696, "mode": "train", "loss": 0.22139, "lr": 0.00010}
[05/07 11:32:06][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "17/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.75636, "dt_data": 0.00043, "dt_net": 0.75593, "mode": "train", "loss": 0.24734, "lr": 0.00010}
[05/07 11:32:14][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "17/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.76248, "dt_data": 0.00054, "dt_net": 0.76194, "mode": "train", "loss": 0.22302, "lr": 0.00010}
[05/07 11:32:22][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "17/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.76198, "dt_data": 0.00022, "dt_net": 0.76176, "mode": "train", "loss": 0.21634, "lr": 0.00010}
[05/07 11:32:30][INFO] train_net.py:  669: Epoch 16 takes 93.58s. Epochs from 0 to 16 take 93.69s in average and 93.30s in median.
[05/07 11:32:30][INFO] train_net.py:  675: For epoch 16, each iteraction takes 1.18s in average. From epoch 0 to 16, each iteraction takes 1.19s in average.
[05/07 11:33:09][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "18/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71958, "dt_data": 0.00040, "dt_net": 0.71918, "mode": "train", "loss": 0.22383, "lr": 0.00010}
[05/07 11:33:17][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "18/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.74069, "dt_data": 0.00052, "dt_net": 0.74016, "mode": "train", "loss": 0.21805, "lr": 0.00010}
[05/07 11:33:24][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "18/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.74915, "dt_data": 0.00042, "dt_net": 0.74872, "mode": "train", "loss": 0.20943, "lr": 0.00010}
[05/07 11:33:32][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "18/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75137, "dt_data": 0.00052, "dt_net": 0.75084, "mode": "train", "loss": 0.22604, "lr": 0.00010}
[05/07 11:33:39][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "18/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.75904, "dt_data": 0.00035, "dt_net": 0.75869, "mode": "train", "loss": 0.22878, "lr": 0.00010}
[05/07 11:33:47][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "18/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.76369, "dt_data": 0.00052, "dt_net": 0.76317, "mode": "train", "loss": 0.21854, "lr": 0.00010}
[05/07 11:33:54][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "18/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.76008, "dt_data": 0.00022, "dt_net": 0.75986, "mode": "train", "loss": 0.22643, "lr": 0.00010}
[05/07 11:34:02][INFO] train_net.py:  669: Epoch 17 takes 92.62s. Epochs from 0 to 17 take 93.63s in average and 93.18s in median.
[05/07 11:34:02][INFO] train_net.py:  675: For epoch 17, each iteraction takes 1.17s in average. From epoch 0 to 17, each iteraction takes 1.19s in average.
[05/07 11:34:42][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "19/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71711, "dt_data": 0.00035, "dt_net": 0.71676, "mode": "train", "loss": 0.22027, "lr": 0.00010}
[05/07 11:34:49][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "19/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.73935, "dt_data": 0.00050, "dt_net": 0.73885, "mode": "train", "loss": 0.22279, "lr": 0.00010}
[05/07 11:34:57][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "19/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.74597, "dt_data": 0.00042, "dt_net": 0.74555, "mode": "train", "loss": 0.23541, "lr": 0.00010}
[05/07 11:35:04][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "19/60", "cur_iter": "40", "eta": "0:00:29", "dt": 0.74645, "dt_data": 0.00036, "dt_net": 0.74609, "mode": "train", "loss": 0.23408, "lr": 0.00010}
[05/07 11:35:12][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "19/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.76131, "dt_data": 0.00039, "dt_net": 0.76091, "mode": "train", "loss": 0.19356, "lr": 0.00010}
[05/07 11:35:19][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "19/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.75594, "dt_data": 0.00041, "dt_net": 0.75552, "mode": "train", "loss": 0.22633, "lr": 0.00010}
[05/07 11:35:27][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "19/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.75840, "dt_data": 0.00024, "dt_net": 0.75815, "mode": "train", "loss": 0.20967, "lr": 0.00010}
[05/07 11:35:35][INFO] train_net.py:  669: Epoch 18 takes 92.70s. Epochs from 0 to 18 take 93.58s in average and 93.06s in median.
[05/07 11:35:35][INFO] train_net.py:  675: For epoch 18, each iteraction takes 1.17s in average. From epoch 0 to 18, each iteraction takes 1.18s in average.
[05/07 11:36:15][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "20/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71798, "dt_data": 0.00040, "dt_net": 0.71758, "mode": "train", "loss": 0.20810, "lr": 0.00010}
[05/07 11:36:22][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "20/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.74038, "dt_data": 0.00040, "dt_net": 0.73997, "mode": "train", "loss": 0.19851, "lr": 0.00010}
[05/07 11:36:30][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "20/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.75312, "dt_data": 0.00050, "dt_net": 0.75261, "mode": "train", "loss": 0.23409, "lr": 0.00010}
[05/07 11:36:37][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "20/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75150, "dt_data": 0.00042, "dt_net": 0.75107, "mode": "train", "loss": 0.21471, "lr": 0.00010}
[05/07 11:36:45][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "20/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.75490, "dt_data": 0.00086, "dt_net": 0.75404, "mode": "train", "loss": 0.21628, "lr": 0.00010}
[05/07 11:36:52][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "20/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.75986, "dt_data": 0.00053, "dt_net": 0.75933, "mode": "train", "loss": 0.22044, "lr": 0.00010}
[05/07 11:37:00][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "20/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.76356, "dt_data": 0.00022, "dt_net": 0.76333, "mode": "train", "loss": 0.20180, "lr": 0.00010}
[05/07 11:37:08][INFO] train_net.py:  669: Epoch 19 takes 93.11s. Epochs from 0 to 19 take 93.56s in average and 93.08s in median.
[05/07 11:37:08][INFO] train_net.py:  675: For epoch 19, each iteraction takes 1.18s in average. From epoch 0 to 19, each iteraction takes 1.18s in average.
[05/07 11:37:52][INFO] logging.py:   98: json_stats: {"_type": "val_iter", "cur_epoch": "20/60", "cur_iter": "10", "eta": "0:00:01", "dt": 0.36036, "dt_data": 0.01216, "dt_net": 0.34820, "mode": "val"}
[05/07 11:37:53][INFO] ava_eval_helper.py:  204: Evaluating with 542 unique GT frames.
[05/07 11:37:53][INFO] ava_eval_helper.py:  208: Evaluating with 542 unique detection frames
[05/07 11:37:53][INFO] ava_eval_helper.py:  469: AVA results wrote to detections_latest.csv
[05/07 11:37:53][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 11:37:53][INFO] ava_eval_helper.py:  469: AVA results wrote to groundtruth_latest.csv
[05/07 11:37:53][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 11:37:56][INFO] object_detection_evaluation.py:  751: The following classes have no ground truth examples: [ 2  3  4  5 10 13 15 16 18 19 20 21 23 25 28 31 32 33 35 37 39 40 41 42
 44 49 50 51 52 53 54 55 56 57 63 64 67 68 70 71 72 73 75 77]
[05/07 11:37:56][INFO] ava_eval_helper.py:  298: mAP@0.5 = 0.16521 | macro-F1 = 0.07088 | macro-AUROC = 0.70557 | macro-recall = 0.06416
[05/07 11:37:56][INFO] logging.py:   98: json_stats: {"mode": "val", "cur_epoch": "20", "map": 0.16521, "f1_macro": 0.07088, "auroc_macro": 0.70557, "recall_macro": 0.06416, "gpu_mem": "16.96G", "RAM": "69.04/251.58G", "_type": "val_epoch"}
[05/07 11:37:56][INFO] ava_eval_helper.py:  469: AVA results wrote to /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/detections_val_20.csv
[05/07 11:37:56][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 11:37:56][INFO] meters.py:  327: Saved CSVs:
  per-class AP: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/ap_per_class_val_20.csv
  detections: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/detections_val_20.csv
[05/07 11:38:37][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "21/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71804, "dt_data": 0.00052, "dt_net": 0.71752, "mode": "train", "loss": 0.22108, "lr": 0.00001}
[05/07 11:38:44][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "21/60", "cur_iter": "20", "eta": "0:00:43", "dt": 0.73201, "dt_data": 0.00044, "dt_net": 0.73157, "mode": "train", "loss": 0.21446, "lr": 0.00001}
[05/07 11:38:52][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "21/60", "cur_iter": "30", "eta": "0:00:36", "dt": 0.73792, "dt_data": 0.00039, "dt_net": 0.73752, "mode": "train", "loss": 0.21054, "lr": 0.00001}
[05/07 11:38:59][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "21/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75291, "dt_data": 0.00040, "dt_net": 0.75252, "mode": "train", "loss": 0.23158, "lr": 0.00001}
[05/07 11:39:07][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "21/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.76014, "dt_data": 0.00043, "dt_net": 0.75970, "mode": "train", "loss": 0.20437, "lr": 0.00001}
[05/07 11:39:14][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "21/60", "cur_iter": "60", "eta": "0:00:14", "dt": 0.74815, "dt_data": 0.00063, "dt_net": 0.74751, "mode": "train", "loss": 0.22016, "lr": 0.00001}
[05/07 11:39:22][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "21/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.75279, "dt_data": 0.00024, "dt_net": 0.75255, "mode": "train", "loss": 0.22973, "lr": 0.00001}
[05/07 11:39:30][INFO] train_net.py:  669: Epoch 20 takes 93.39s. Epochs from 0 to 20 take 93.55s in average and 93.11s in median.
[05/07 11:39:30][INFO] train_net.py:  675: For epoch 20, each iteraction takes 1.18s in average. From epoch 0 to 20, each iteraction takes 1.18s in average.
[05/07 11:40:10][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "22/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71638, "dt_data": 0.00041, "dt_net": 0.71597, "mode": "train", "loss": 0.20892, "lr": 0.00001}
[05/07 11:40:18][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "22/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.74027, "dt_data": 0.00050, "dt_net": 0.73977, "mode": "train", "loss": 0.24531, "lr": 0.00001}
[05/07 11:40:25][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "22/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.75055, "dt_data": 0.00039, "dt_net": 0.75016, "mode": "train", "loss": 0.21032, "lr": 0.00001}
[05/07 11:40:33][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "22/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75102, "dt_data": 0.00050, "dt_net": 0.75052, "mode": "train", "loss": 0.23347, "lr": 0.00001}
[05/07 11:40:40][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "22/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.74373, "dt_data": 0.00036, "dt_net": 0.74337, "mode": "train", "loss": 0.23483, "lr": 0.00001}
[05/07 11:40:48][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "22/60", "cur_iter": "60", "eta": "0:00:14", "dt": 0.74471, "dt_data": 0.00064, "dt_net": 0.74407, "mode": "train", "loss": 0.20760, "lr": 0.00001}
[05/07 11:40:55][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "22/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.75806, "dt_data": 0.00023, "dt_net": 0.75783, "mode": "train", "loss": 0.21649, "lr": 0.00001}
[05/07 11:41:03][INFO] train_net.py:  669: Epoch 21 takes 93.64s. Epochs from 0 to 21 take 93.55s in average and 93.21s in median.
[05/07 11:41:03][INFO] train_net.py:  675: For epoch 21, each iteraction takes 1.19s in average. From epoch 0 to 21, each iteraction takes 1.18s in average.
[05/07 11:41:44][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "23/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.72048, "dt_data": 0.00040, "dt_net": 0.72008, "mode": "train", "loss": 0.20448, "lr": 0.00001}
[05/07 11:41:51][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "23/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.73779, "dt_data": 0.00051, "dt_net": 0.73728, "mode": "train", "loss": 0.21320, "lr": 0.00001}
[05/07 11:41:59][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "23/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.75401, "dt_data": 0.00044, "dt_net": 0.75356, "mode": "train", "loss": 0.20308, "lr": 0.00001}
[05/07 11:42:06][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "23/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.76137, "dt_data": 0.00045, "dt_net": 0.76092, "mode": "train", "loss": 0.20309, "lr": 0.00001}
[05/07 11:42:14][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "23/60", "cur_iter": "50", "eta": "0:00:23", "dt": 0.76790, "dt_data": 0.00041, "dt_net": 0.76748, "mode": "train", "loss": 0.20505, "lr": 0.00001}
[05/07 11:42:21][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "23/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.76466, "dt_data": 0.00046, "dt_net": 0.76420, "mode": "train", "loss": 0.22111, "lr": 0.00001}
[05/07 11:42:29][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "23/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.77112, "dt_data": 0.00022, "dt_net": 0.77090, "mode": "train", "loss": 0.21085, "lr": 0.00001}
[05/07 11:42:37][INFO] train_net.py:  669: Epoch 22 takes 93.59s. Epochs from 0 to 22 take 93.55s in average and 93.30s in median.
[05/07 11:42:37][INFO] train_net.py:  675: For epoch 22, each iteraction takes 1.18s in average. From epoch 0 to 22, each iteraction takes 1.18s in average.
[05/07 11:43:17][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "24/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.72018, "dt_data": 0.00039, "dt_net": 0.71978, "mode": "train", "loss": 0.21890, "lr": 0.00001}
[05/07 11:43:25][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "24/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.74208, "dt_data": 0.00039, "dt_net": 0.74169, "mode": "train", "loss": 0.22708, "lr": 0.00001}
[05/07 11:43:32][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "24/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.75037, "dt_data": 0.00038, "dt_net": 0.74999, "mode": "train", "loss": 0.22652, "lr": 0.00001}
[05/07 11:43:40][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "24/60", "cur_iter": "40", "eta": "0:00:29", "dt": 0.73690, "dt_data": 0.00039, "dt_net": 0.73651, "mode": "train", "loss": 0.19789, "lr": 0.00001}
[05/07 11:43:47][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "24/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.74422, "dt_data": 0.00042, "dt_net": 0.74380, "mode": "train", "loss": 0.20730, "lr": 0.00001}
[05/07 11:43:55][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "24/60", "cur_iter": "60", "eta": "0:00:14", "dt": 0.74899, "dt_data": 0.00057, "dt_net": 0.74842, "mode": "train", "loss": 0.22386, "lr": 0.00001}
[05/07 11:44:02][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "24/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.73883, "dt_data": 0.00025, "dt_net": 0.73858, "mode": "train", "loss": 0.20168, "lr": 0.00001}
[05/07 11:44:10][INFO] train_net.py:  669: Epoch 23 takes 93.36s. Epochs from 0 to 23 take 93.55s in average and 93.31s in median.
[05/07 11:44:10][INFO] train_net.py:  675: For epoch 23, each iteraction takes 1.18s in average. From epoch 0 to 23, each iteraction takes 1.18s in average.
[05/07 11:44:52][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "25/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71894, "dt_data": 0.00037, "dt_net": 0.71856, "mode": "train", "loss": 0.18528, "lr": 0.00001}
[05/07 11:44:59][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "25/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.74135, "dt_data": 0.00044, "dt_net": 0.74091, "mode": "train", "loss": 0.21779, "lr": 0.00001}
[05/07 11:45:07][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "25/60", "cur_iter": "30", "eta": "0:00:38", "dt": 0.76996, "dt_data": 0.00059, "dt_net": 0.76936, "mode": "train", "loss": 0.21441, "lr": 0.00001}
[05/07 11:45:14][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "25/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75023, "dt_data": 0.00039, "dt_net": 0.74984, "mode": "train", "loss": 0.20192, "lr": 0.00001}
[05/07 11:45:22][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "25/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.74747, "dt_data": 0.00037, "dt_net": 0.74710, "mode": "train", "loss": 0.20932, "lr": 0.00001}
[05/07 11:45:29][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "25/60", "cur_iter": "60", "eta": "0:00:14", "dt": 0.74925, "dt_data": 0.00048, "dt_net": 0.74877, "mode": "train", "loss": 0.22751, "lr": 0.00001}
[05/07 11:45:37][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "25/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.73618, "dt_data": 0.00021, "dt_net": 0.73597, "mode": "train", "loss": 0.22885, "lr": 0.00001}
[05/07 11:45:45][INFO] train_net.py:  669: Epoch 24 takes 94.42s. Epochs from 0 to 24 take 93.58s in average and 93.31s in median.
[05/07 11:45:45][INFO] train_net.py:  675: For epoch 24, each iteraction takes 1.20s in average. From epoch 0 to 24, each iteraction takes 1.18s in average.
[05/07 11:46:26][INFO] logging.py:   98: json_stats: {"_type": "val_iter", "cur_epoch": "25/60", "cur_iter": "10", "eta": "0:00:01", "dt": 0.36029, "dt_data": 0.01199, "dt_net": 0.34830, "mode": "val"}
[05/07 11:46:27][INFO] ava_eval_helper.py:  204: Evaluating with 542 unique GT frames.
[05/07 11:46:27][INFO] ava_eval_helper.py:  208: Evaluating with 542 unique detection frames
[05/07 11:46:27][INFO] ava_eval_helper.py:  469: AVA results wrote to detections_latest.csv
[05/07 11:46:27][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 11:46:27][INFO] ava_eval_helper.py:  469: AVA results wrote to groundtruth_latest.csv
[05/07 11:46:27][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 11:46:30][INFO] object_detection_evaluation.py:  751: The following classes have no ground truth examples: [ 2  3  4  5 10 13 15 16 18 19 20 21 23 25 28 31 32 33 35 37 39 40 41 42
 44 49 50 51 52 53 54 55 56 57 63 64 67 68 70 71 72 73 75 77]
[05/07 11:46:30][INFO] ava_eval_helper.py:  298: mAP@0.5 = 0.17282 | macro-F1 = 0.07463 | macro-AUROC = 0.71685 | macro-recall = 0.06571
[05/07 11:46:30][INFO] logging.py:   98: json_stats: {"mode": "val", "cur_epoch": "25", "map": 0.17282, "f1_macro": 0.07463, "auroc_macro": 0.71685, "recall_macro": 0.06571, "gpu_mem": "16.96G", "RAM": "69.20/251.58G", "_type": "val_epoch"}
[05/07 11:46:30][INFO] ava_eval_helper.py:  469: AVA results wrote to /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/detections_val_25.csv
[05/07 11:46:30][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 11:46:30][INFO] meters.py:  327: Saved CSVs:
  per-class AP: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/ap_per_class_val_25.csv
  detections: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/detections_val_25.csv
[05/07 11:47:15][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "26/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71505, "dt_data": 0.00045, "dt_net": 0.71461, "mode": "train", "loss": 0.21955, "lr": 0.00001}
[05/07 11:47:22][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "26/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.73572, "dt_data": 0.00050, "dt_net": 0.73522, "mode": "train", "loss": 0.21341, "lr": 0.00001}
[05/07 11:47:30][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "26/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.75252, "dt_data": 0.00048, "dt_net": 0.75203, "mode": "train", "loss": 0.22654, "lr": 0.00001}
[05/07 11:47:37][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "26/60", "cur_iter": "40", "eta": "0:00:29", "dt": 0.74773, "dt_data": 0.00046, "dt_net": 0.74726, "mode": "train", "loss": 0.20638, "lr": 0.00001}
[05/07 11:47:45][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "26/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.75206, "dt_data": 0.00049, "dt_net": 0.75157, "mode": "train", "loss": 0.19485, "lr": 0.00001}
[05/07 11:47:52][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "26/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.75578, "dt_data": 0.00044, "dt_net": 0.75534, "mode": "train", "loss": 0.19557, "lr": 0.00001}
[05/07 11:48:00][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "26/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.76434, "dt_data": 0.00039, "dt_net": 0.76394, "mode": "train", "loss": 0.21228, "lr": 0.00001}
[05/07 11:48:08][INFO] train_net.py:  669: Epoch 25 takes 97.32s. Epochs from 0 to 25 take 93.73s in average and 93.34s in median.
[05/07 11:48:08][INFO] train_net.py:  675: For epoch 25, each iteraction takes 1.23s in average. From epoch 0 to 25, each iteraction takes 1.19s in average.
[05/07 11:48:48][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "27/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71900, "dt_data": 0.00044, "dt_net": 0.71857, "mode": "train", "loss": 0.21418, "lr": 0.00001}
[05/07 11:48:55][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "27/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.73926, "dt_data": 0.00040, "dt_net": 0.73887, "mode": "train", "loss": 0.20466, "lr": 0.00001}
[05/07 11:49:02][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "27/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.74832, "dt_data": 0.00056, "dt_net": 0.74776, "mode": "train", "loss": 0.19002, "lr": 0.00001}
[05/07 11:49:10][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "27/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75312, "dt_data": 0.00046, "dt_net": 0.75266, "mode": "train", "loss": 0.21049, "lr": 0.00001}
[05/07 11:49:17][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "27/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.75683, "dt_data": 0.00038, "dt_net": 0.75645, "mode": "train", "loss": 0.20944, "lr": 0.00001}
[05/07 11:49:25][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "27/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.76085, "dt_data": 0.00040, "dt_net": 0.76044, "mode": "train", "loss": 0.21690, "lr": 0.00001}
[05/07 11:49:33][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "27/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.75878, "dt_data": 0.00021, "dt_net": 0.75857, "mode": "train", "loss": 0.22612, "lr": 0.00001}
[05/07 11:49:41][INFO] train_net.py:  669: Epoch 26 takes 92.92s. Epochs from 0 to 26 take 93.70s in average and 93.31s in median.
[05/07 11:49:41][INFO] train_net.py:  675: For epoch 26, each iteraction takes 1.18s in average. From epoch 0 to 26, each iteraction takes 1.19s in average.
[05/07 11:50:21][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "28/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71705, "dt_data": 0.00041, "dt_net": 0.71664, "mode": "train", "loss": 0.21173, "lr": 0.00001}
[05/07 11:50:29][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "28/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.74025, "dt_data": 0.00044, "dt_net": 0.73980, "mode": "train", "loss": 0.21498, "lr": 0.00001}
[05/07 11:50:36][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "28/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.74909, "dt_data": 0.00039, "dt_net": 0.74870, "mode": "train", "loss": 0.23365, "lr": 0.00001}
[05/07 11:50:44][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "28/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75223, "dt_data": 0.00038, "dt_net": 0.75185, "mode": "train", "loss": 0.24025, "lr": 0.00001}
[05/07 11:50:51][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "28/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.73829, "dt_data": 0.00060, "dt_net": 0.73769, "mode": "train", "loss": 0.20988, "lr": 0.00001}
[05/07 11:50:59][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "28/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.76649, "dt_data": 0.00105, "dt_net": 0.76544, "mode": "train", "loss": 0.21992, "lr": 0.00001}
[05/07 11:51:06][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "28/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.75523, "dt_data": 0.00023, "dt_net": 0.75500, "mode": "train", "loss": 0.22966, "lr": 0.00001}
[05/07 11:51:14][INFO] train_net.py:  669: Epoch 27 takes 93.72s. Epochs from 0 to 27 take 93.70s in average and 93.34s in median.
[05/07 11:51:14][INFO] train_net.py:  675: For epoch 27, each iteraction takes 1.19s in average. From epoch 0 to 27, each iteraction takes 1.19s in average.
[05/07 11:51:55][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "29/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.72083, "dt_data": 0.00059, "dt_net": 0.72024, "mode": "train", "loss": 0.21699, "lr": 0.00001}
[05/07 11:52:02][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "29/60", "cur_iter": "20", "eta": "0:00:43", "dt": 0.73111, "dt_data": 0.00043, "dt_net": 0.73068, "mode": "train", "loss": 0.19161, "lr": 0.00001}
[05/07 11:52:10][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "29/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.75254, "dt_data": 0.00043, "dt_net": 0.75211, "mode": "train", "loss": 0.22314, "lr": 0.00001}
[05/07 11:52:17][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "29/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75362, "dt_data": 0.00035, "dt_net": 0.75326, "mode": "train", "loss": 0.20155, "lr": 0.00001}
[05/07 11:52:25][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "29/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.74522, "dt_data": 0.00049, "dt_net": 0.74473, "mode": "train", "loss": 0.22103, "lr": 0.00001}
[05/07 11:52:32][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "29/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.75973, "dt_data": 0.00043, "dt_net": 0.75930, "mode": "train", "loss": 0.20735, "lr": 0.00001}
[05/07 11:52:40][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "29/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.76049, "dt_data": 0.00024, "dt_net": 0.76025, "mode": "train", "loss": 0.21279, "lr": 0.00001}
[05/07 11:52:48][INFO] train_net.py:  669: Epoch 28 takes 93.67s. Epochs from 0 to 28 take 93.70s in average and 93.36s in median.
[05/07 11:52:48][INFO] train_net.py:  675: For epoch 28, each iteraction takes 1.19s in average. From epoch 0 to 28, each iteraction takes 1.19s in average.
[05/07 11:53:43][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "30/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71741, "dt_data": 0.00047, "dt_net": 0.71693, "mode": "train", "loss": 0.21305, "lr": 0.00001}
[05/07 11:53:50][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "30/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.73570, "dt_data": 0.00046, "dt_net": 0.73524, "mode": "train", "loss": 0.19895, "lr": 0.00001}
[05/07 11:53:57][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "30/60", "cur_iter": "30", "eta": "0:00:36", "dt": 0.73938, "dt_data": 0.00044, "dt_net": 0.73893, "mode": "train", "loss": 0.21497, "lr": 0.00001}
[05/07 11:54:05][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "30/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75210, "dt_data": 0.00038, "dt_net": 0.75171, "mode": "train", "loss": 0.21888, "lr": 0.00001}
[05/07 11:54:13][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "30/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.74990, "dt_data": 0.00054, "dt_net": 0.74936, "mode": "train", "loss": 0.19222, "lr": 0.00001}
[05/07 11:54:20][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "30/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.75310, "dt_data": 0.00052, "dt_net": 0.75258, "mode": "train", "loss": 0.19611, "lr": 0.00001}
[05/07 11:54:28][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "30/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.75602, "dt_data": 0.00023, "dt_net": 0.75578, "mode": "train", "loss": 0.21298, "lr": 0.00001}
[05/07 11:54:36][INFO] train_net.py:  669: Epoch 29 takes 108.33s. Epochs from 0 to 29 take 94.18s in average and 93.38s in median.
[05/07 11:54:36][INFO] train_net.py:  675: For epoch 29, each iteraction takes 1.37s in average. From epoch 0 to 29, each iteraction takes 1.19s in average.
[05/07 11:55:32][INFO] logging.py:   98: json_stats: {"_type": "val_iter", "cur_epoch": "30/60", "cur_iter": "10", "eta": "0:00:01", "dt": 0.35911, "dt_data": 0.01221, "dt_net": 0.34690, "mode": "val"}
[05/07 11:55:33][INFO] ava_eval_helper.py:  204: Evaluating with 542 unique GT frames.
[05/07 11:55:33][INFO] ava_eval_helper.py:  208: Evaluating with 542 unique detection frames
[05/07 11:55:33][INFO] ava_eval_helper.py:  469: AVA results wrote to detections_latest.csv
[05/07 11:55:33][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 11:55:34][INFO] ava_eval_helper.py:  469: AVA results wrote to groundtruth_latest.csv
[05/07 11:55:34][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 11:55:36][INFO] object_detection_evaluation.py:  751: The following classes have no ground truth examples: [ 2  3  4  5 10 13 15 16 18 19 20 21 23 25 28 31 32 33 35 37 39 40 41 42
 44 49 50 51 52 53 54 55 56 57 63 64 67 68 70 71 72 73 75 77]
[05/07 11:55:37][INFO] ava_eval_helper.py:  298: mAP@0.5 = 0.17596 | macro-F1 = 0.07863 | macro-AUROC = 0.72399 | macro-recall = 0.06808
[05/07 11:55:37][INFO] logging.py:   98: json_stats: {"mode": "val", "cur_epoch": "30", "map": 0.17596, "f1_macro": 0.07863, "auroc_macro": 0.72399, "recall_macro": 0.06808, "gpu_mem": "16.96G", "RAM": "69.43/251.58G", "_type": "val_epoch"}
[05/07 11:55:37][INFO] ava_eval_helper.py:  469: AVA results wrote to /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/detections_val_30.csv
[05/07 11:55:37][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 11:55:37][INFO] meters.py:  327: Saved CSVs:
  per-class AP: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/ap_per_class_val_30.csv
  detections: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/detections_val_30.csv
[05/07 11:56:20][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "31/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71683, "dt_data": 0.00040, "dt_net": 0.71642, "mode": "train", "loss": 0.19597, "lr": 0.00000}
[05/07 11:56:27][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "31/60", "cur_iter": "20", "eta": "0:00:43", "dt": 0.73229, "dt_data": 0.00052, "dt_net": 0.73177, "mode": "train", "loss": 0.21396, "lr": 0.00000}
[05/07 11:56:35][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "31/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.74007, "dt_data": 0.00043, "dt_net": 0.73963, "mode": "train", "loss": 0.21986, "lr": 0.00000}
[05/07 11:56:42][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "31/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75454, "dt_data": 0.00042, "dt_net": 0.75412, "mode": "train", "loss": 0.23700, "lr": 0.00000}
[05/07 11:56:50][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "31/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.74895, "dt_data": 0.00042, "dt_net": 0.74853, "mode": "train", "loss": 0.20307, "lr": 0.00000}
[05/07 11:56:57][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "31/60", "cur_iter": "60", "eta": "0:00:14", "dt": 0.74283, "dt_data": 0.00039, "dt_net": 0.74244, "mode": "train", "loss": 0.23075, "lr": 0.00000}
[05/07 11:57:05][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "31/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.73785, "dt_data": 0.00020, "dt_net": 0.73765, "mode": "train", "loss": 0.20966, "lr": 0.00000}
[05/07 11:57:13][INFO] train_net.py:  669: Epoch 30 takes 96.25s. Epochs from 0 to 30 take 94.25s in average and 93.39s in median.
[05/07 11:57:13][INFO] train_net.py:  675: For epoch 30, each iteraction takes 1.22s in average. From epoch 0 to 30, each iteraction takes 1.19s in average.
[05/07 11:57:52][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "32/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.72224, "dt_data": 0.00039, "dt_net": 0.72184, "mode": "train", "loss": 0.20610, "lr": 0.00000}
[05/07 11:57:59][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "32/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.73900, "dt_data": 0.00044, "dt_net": 0.73855, "mode": "train", "loss": 0.20009, "lr": 0.00000}
[05/07 11:58:07][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "32/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.74978, "dt_data": 0.00048, "dt_net": 0.74930, "mode": "train", "loss": 0.20363, "lr": 0.00000}
[05/07 11:58:14][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "32/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75565, "dt_data": 0.00042, "dt_net": 0.75523, "mode": "train", "loss": 0.18480, "lr": 0.00000}
[05/07 11:58:22][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "32/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.74225, "dt_data": 0.00040, "dt_net": 0.74184, "mode": "train", "loss": 0.20967, "lr": 0.00000}
[05/07 11:58:29][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "32/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.75091, "dt_data": 0.00051, "dt_net": 0.75040, "mode": "train", "loss": 0.21857, "lr": 0.00000}
[05/07 11:58:37][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "32/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.76162, "dt_data": 0.00022, "dt_net": 0.76140, "mode": "train", "loss": 0.19591, "lr": 0.00000}
[05/07 11:58:45][INFO] train_net.py:  669: Epoch 31 takes 92.26s. Epochs from 0 to 31 take 94.19s in average and 93.38s in median.
[05/07 11:58:45][INFO] train_net.py:  675: For epoch 31, each iteraction takes 1.17s in average. From epoch 0 to 31, each iteraction takes 1.19s in average.
[05/07 11:59:24][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "33/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.72007, "dt_data": 0.00041, "dt_net": 0.71967, "mode": "train", "loss": 0.21080, "lr": 0.00000}
[05/07 11:59:32][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "33/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.74071, "dt_data": 0.00041, "dt_net": 0.74030, "mode": "train", "loss": 0.20625, "lr": 0.00000}
[05/07 11:59:39][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "33/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.75140, "dt_data": 0.00044, "dt_net": 0.75096, "mode": "train", "loss": 0.21628, "lr": 0.00000}
[05/07 11:59:47][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "33/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75773, "dt_data": 0.00043, "dt_net": 0.75730, "mode": "train", "loss": 0.20972, "lr": 0.00000}
[05/07 11:59:54][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "33/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.76130, "dt_data": 0.00043, "dt_net": 0.76086, "mode": "train", "loss": 0.21254, "lr": 0.00000}
[05/07 12:00:02][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "33/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.76024, "dt_data": 0.00057, "dt_net": 0.75966, "mode": "train", "loss": 0.22985, "lr": 0.00000}
[05/07 12:00:10][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "33/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.75645, "dt_data": 0.00022, "dt_net": 0.75623, "mode": "train", "loss": 0.19273, "lr": 0.00000}
[05/07 12:00:18][INFO] train_net.py:  669: Epoch 32 takes 92.49s. Epochs from 0 to 32 take 94.14s in average and 93.36s in median.
[05/07 12:00:18][INFO] train_net.py:  675: For epoch 32, each iteraction takes 1.17s in average. From epoch 0 to 32, each iteraction takes 1.19s in average.
[05/07 12:01:02][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "34/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71977, "dt_data": 0.00044, "dt_net": 0.71934, "mode": "train", "loss": 0.22557, "lr": 0.00000}
[05/07 12:01:10][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "34/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.74244, "dt_data": 0.00056, "dt_net": 0.74188, "mode": "train", "loss": 0.20858, "lr": 0.00000}
[05/07 12:01:17][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "34/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.75920, "dt_data": 0.00036, "dt_net": 0.75884, "mode": "train", "loss": 0.20738, "lr": 0.00000}
[05/07 12:01:25][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "34/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75931, "dt_data": 0.00062, "dt_net": 0.75869, "mode": "train", "loss": 0.21202, "lr": 0.00000}
[05/07 12:01:32][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "34/60", "cur_iter": "50", "eta": "0:00:23", "dt": 0.77789, "dt_data": 0.00067, "dt_net": 0.77722, "mode": "train", "loss": 0.19012, "lr": 0.00000}
[05/07 12:01:40][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "34/60", "cur_iter": "60", "eta": "0:00:14", "dt": 0.74979, "dt_data": 0.00051, "dt_net": 0.74927, "mode": "train", "loss": 0.21069, "lr": 0.00000}
[05/07 12:01:47][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "34/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.75270, "dt_data": 0.00021, "dt_net": 0.75249, "mode": "train", "loss": 0.21338, "lr": 0.00000}
[05/07 12:01:55][INFO] train_net.py:  669: Epoch 33 takes 97.58s. Epochs from 0 to 33 take 94.24s in average and 93.38s in median.
[05/07 12:01:55][INFO] train_net.py:  675: For epoch 33, each iteraction takes 1.24s in average. From epoch 0 to 33, each iteraction takes 1.19s in average.
[05/07 12:02:36][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "35/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71893, "dt_data": 0.00035, "dt_net": 0.71858, "mode": "train", "loss": 0.21254, "lr": 0.00000}
[05/07 12:02:44][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "35/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.74395, "dt_data": 0.00042, "dt_net": 0.74353, "mode": "train", "loss": 0.18229, "lr": 0.00000}
[05/07 12:02:51][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "35/60", "cur_iter": "30", "eta": "0:00:36", "dt": 0.73704, "dt_data": 0.00043, "dt_net": 0.73660, "mode": "train", "loss": 0.23845, "lr": 0.00000}
[05/07 12:02:59][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "35/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75013, "dt_data": 0.00038, "dt_net": 0.74974, "mode": "train", "loss": 0.22951, "lr": 0.00000}
[05/07 12:03:06][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "35/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.74639, "dt_data": 0.00039, "dt_net": 0.74599, "mode": "train", "loss": 0.23271, "lr": 0.00000}
[05/07 12:03:14][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "35/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.75652, "dt_data": 0.00042, "dt_net": 0.75610, "mode": "train", "loss": 0.20842, "lr": 0.00000}
[05/07 12:03:21][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "35/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.75761, "dt_data": 0.00020, "dt_net": 0.75741, "mode": "train", "loss": 0.20467, "lr": 0.00000}
[05/07 12:03:29][INFO] train_net.py:  669: Epoch 34 takes 93.96s. Epochs from 0 to 34 take 94.23s in average and 93.39s in median.
[05/07 12:03:29][INFO] train_net.py:  675: For epoch 34, each iteraction takes 1.19s in average. From epoch 0 to 34, each iteraction takes 1.19s in average.
[05/07 12:04:07][INFO] logging.py:   98: json_stats: {"_type": "val_iter", "cur_epoch": "35/60", "cur_iter": "10", "eta": "0:00:01", "dt": 0.36159, "dt_data": 0.01203, "dt_net": 0.34957, "mode": "val"}
[05/07 12:04:08][INFO] ava_eval_helper.py:  204: Evaluating with 542 unique GT frames.
[05/07 12:04:08][INFO] ava_eval_helper.py:  208: Evaluating with 542 unique detection frames
[05/07 12:04:08][INFO] ava_eval_helper.py:  469: AVA results wrote to detections_latest.csv
[05/07 12:04:08][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 12:04:08][INFO] ava_eval_helper.py:  469: AVA results wrote to groundtruth_latest.csv
[05/07 12:04:08][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 12:04:12][INFO] object_detection_evaluation.py:  751: The following classes have no ground truth examples: [ 2  3  4  5 10 13 15 16 18 19 20 21 23 25 28 31 32 33 35 37 39 40 41 42
 44 49 50 51 52 53 54 55 56 57 63 64 67 68 70 71 72 73 75 77]
[05/07 12:04:12][INFO] ava_eval_helper.py:  298: mAP@0.5 = 0.17655 | macro-F1 = 0.07921 | macro-AUROC = 0.72229 | macro-recall = 0.06906
[05/07 12:04:12][INFO] logging.py:   98: json_stats: {"mode": "val", "cur_epoch": "35", "map": 0.17655, "f1_macro": 0.07921, "auroc_macro": 0.72229, "recall_macro": 0.06906, "gpu_mem": "16.96G", "RAM": "70.61/251.58G", "_type": "val_epoch"}
[05/07 12:04:12][INFO] ava_eval_helper.py:  469: AVA results wrote to /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/detections_val_35.csv
[05/07 12:04:12][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 12:04:12][INFO] meters.py:  327: Saved CSVs:
  per-class AP: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/ap_per_class_val_35.csv
  detections: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/detections_val_35.csv
[05/07 12:04:51][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "36/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71740, "dt_data": 0.00044, "dt_net": 0.71696, "mode": "train", "loss": 0.20145, "lr": 0.00000}
[05/07 12:04:59][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "36/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.73790, "dt_data": 0.00045, "dt_net": 0.73744, "mode": "train", "loss": 0.19958, "lr": 0.00000}
[05/07 12:05:06][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "36/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.75213, "dt_data": 0.00040, "dt_net": 0.75173, "mode": "train", "loss": 0.20317, "lr": 0.00000}
[05/07 12:05:14][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "36/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75077, "dt_data": 0.00051, "dt_net": 0.75026, "mode": "train", "loss": 0.22403, "lr": 0.00000}
[05/07 12:05:21][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "36/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.75368, "dt_data": 0.00051, "dt_net": 0.75318, "mode": "train", "loss": 0.18994, "lr": 0.00000}
[05/07 12:05:29][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "36/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.76265, "dt_data": 0.00045, "dt_net": 0.76220, "mode": "train", "loss": 0.22053, "lr": 0.00000}
[05/07 12:05:36][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "36/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.76713, "dt_data": 0.00023, "dt_net": 0.76690, "mode": "train", "loss": 0.18897, "lr": 0.00000}
[05/07 12:05:44][INFO] train_net.py:  669: Epoch 35 takes 92.49s. Epochs from 0 to 35 take 94.18s in average and 93.38s in median.
[05/07 12:05:44][INFO] train_net.py:  675: For epoch 35, each iteraction takes 1.17s in average. From epoch 0 to 35, each iteraction takes 1.19s in average.
[05/07 12:06:24][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "37/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71803, "dt_data": 0.00041, "dt_net": 0.71762, "mode": "train", "loss": 0.23042, "lr": 0.00000}
[05/07 12:06:31][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "37/60", "cur_iter": "20", "eta": "0:00:43", "dt": 0.72820, "dt_data": 0.00039, "dt_net": 0.72781, "mode": "train", "loss": 0.20806, "lr": 0.00000}
[05/07 12:06:39][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "37/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.75613, "dt_data": 0.00041, "dt_net": 0.75572, "mode": "train", "loss": 0.19398, "lr": 0.00000}
[05/07 12:06:46][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "37/60", "cur_iter": "40", "eta": "0:00:29", "dt": 0.73929, "dt_data": 0.00048, "dt_net": 0.73880, "mode": "train", "loss": 0.21891, "lr": 0.00000}
[05/07 12:06:54][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "37/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.75514, "dt_data": 0.00038, "dt_net": 0.75477, "mode": "train", "loss": 0.21517, "lr": 0.00000}
[05/07 12:07:01][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "37/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.75860, "dt_data": 0.00041, "dt_net": 0.75819, "mode": "train", "loss": 0.22485, "lr": 0.00000}
[05/07 12:07:09][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "37/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.75942, "dt_data": 0.00023, "dt_net": 0.75919, "mode": "train", "loss": 0.19523, "lr": 0.00000}
[05/07 12:07:17][INFO] train_net.py:  669: Epoch 36 takes 92.80s. Epochs from 0 to 36 take 94.14s in average and 93.36s in median.
[05/07 12:07:17][INFO] train_net.py:  675: For epoch 36, each iteraction takes 1.17s in average. From epoch 0 to 36, each iteraction takes 1.19s in average.
[05/07 12:07:56][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "38/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71793, "dt_data": 0.00046, "dt_net": 0.71748, "mode": "train", "loss": 0.22702, "lr": 0.00000}
[05/07 12:08:04][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "38/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.74179, "dt_data": 0.00044, "dt_net": 0.74135, "mode": "train", "loss": 0.19103, "lr": 0.00000}
[05/07 12:08:11][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "38/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.75203, "dt_data": 0.00042, "dt_net": 0.75162, "mode": "train", "loss": 0.22019, "lr": 0.00000}
[05/07 12:08:19][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "38/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75732, "dt_data": 0.00042, "dt_net": 0.75690, "mode": "train", "loss": 0.19855, "lr": 0.00000}
[05/07 12:08:26][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "38/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.75555, "dt_data": 0.00066, "dt_net": 0.75488, "mode": "train", "loss": 0.19926, "lr": 0.00000}
[05/07 12:08:34][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "38/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.75782, "dt_data": 0.00043, "dt_net": 0.75739, "mode": "train", "loss": 0.20381, "lr": 0.00000}
[05/07 12:08:41][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "38/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.75548, "dt_data": 0.00022, "dt_net": 0.75526, "mode": "train", "loss": 0.22033, "lr": 0.00000}
[05/07 12:08:49][INFO] train_net.py:  669: Epoch 37 takes 92.26s. Epochs from 0 to 37 take 94.09s in average and 93.34s in median.
[05/07 12:08:49][INFO] train_net.py:  675: For epoch 37, each iteraction takes 1.17s in average. From epoch 0 to 37, each iteraction takes 1.19s in average.
[05/07 12:09:30][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "39/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71804, "dt_data": 0.00045, "dt_net": 0.71758, "mode": "train", "loss": 0.20878, "lr": 0.00000}
[05/07 12:09:37][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "39/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.73665, "dt_data": 0.00042, "dt_net": 0.73623, "mode": "train", "loss": 0.20790, "lr": 0.00000}
[05/07 12:09:45][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "39/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.74710, "dt_data": 0.00039, "dt_net": 0.74670, "mode": "train", "loss": 0.21068, "lr": 0.00000}
[05/07 12:09:52][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "39/60", "cur_iter": "40", "eta": "0:00:29", "dt": 0.74990, "dt_data": 0.00040, "dt_net": 0.74951, "mode": "train", "loss": 0.20378, "lr": 0.00000}
[05/07 12:10:00][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "39/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.75646, "dt_data": 0.00040, "dt_net": 0.75607, "mode": "train", "loss": 0.21677, "lr": 0.00000}
[05/07 12:10:07][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "39/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.75813, "dt_data": 0.00044, "dt_net": 0.75769, "mode": "train", "loss": 0.21151, "lr": 0.00000}
[05/07 12:10:15][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "39/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.75838, "dt_data": 0.00023, "dt_net": 0.75814, "mode": "train", "loss": 0.22664, "lr": 0.00000}
[05/07 12:10:23][INFO] train_net.py:  669: Epoch 38 takes 93.58s. Epochs from 0 to 38 take 94.08s in average and 93.36s in median.
[05/07 12:10:23][INFO] train_net.py:  675: For epoch 38, each iteraction takes 1.18s in average. From epoch 0 to 38, each iteraction takes 1.19s in average.
[05/07 12:11:05][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "40/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71695, "dt_data": 0.00044, "dt_net": 0.71650, "mode": "train", "loss": 0.19710, "lr": 0.00000}
[05/07 12:11:13][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "40/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.73439, "dt_data": 0.00036, "dt_net": 0.73403, "mode": "train", "loss": 0.23085, "lr": 0.00000}
[05/07 12:11:20][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "40/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.75187, "dt_data": 0.00050, "dt_net": 0.75136, "mode": "train", "loss": 0.22540, "lr": 0.00000}
[05/07 12:11:27][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "40/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75426, "dt_data": 0.00044, "dt_net": 0.75382, "mode": "train", "loss": 0.22090, "lr": 0.00000}
[05/07 12:11:35][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "40/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.75899, "dt_data": 0.00042, "dt_net": 0.75857, "mode": "train", "loss": 0.22996, "lr": 0.00000}
[05/07 12:11:43][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "40/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.75841, "dt_data": 0.00058, "dt_net": 0.75783, "mode": "train", "loss": 0.20651, "lr": 0.00000}
[05/07 12:11:50][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "40/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.76168, "dt_data": 0.00022, "dt_net": 0.76146, "mode": "train", "loss": 0.18064, "lr": 0.00000}
[05/07 12:11:58][INFO] train_net.py:  669: Epoch 39 takes 95.34s. Epochs from 0 to 39 take 94.11s in average and 93.38s in median.
[05/07 12:11:58][INFO] train_net.py:  675: For epoch 39, each iteraction takes 1.21s in average. From epoch 0 to 39, each iteraction takes 1.19s in average.
[05/07 12:12:36][INFO] logging.py:   98: json_stats: {"_type": "val_iter", "cur_epoch": "40/60", "cur_iter": "10", "eta": "0:00:01", "dt": 0.36091, "dt_data": 0.01218, "dt_net": 0.34873, "mode": "val"}
[05/07 12:12:38][INFO] ava_eval_helper.py:  204: Evaluating with 542 unique GT frames.
[05/07 12:12:38][INFO] ava_eval_helper.py:  208: Evaluating with 542 unique detection frames
[05/07 12:12:38][INFO] ava_eval_helper.py:  469: AVA results wrote to detections_latest.csv
[05/07 12:12:38][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 12:12:38][INFO] ava_eval_helper.py:  469: AVA results wrote to groundtruth_latest.csv
[05/07 12:12:38][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 12:12:41][INFO] object_detection_evaluation.py:  751: The following classes have no ground truth examples: [ 2  3  4  5 10 13 15 16 18 19 20 21 23 25 28 31 32 33 35 37 39 40 41 42
 44 49 50 51 52 53 54 55 56 57 63 64 67 68 70 71 72 73 75 77]
[05/07 12:12:41][INFO] ava_eval_helper.py:  298: mAP@0.5 = 0.17750 | macro-F1 = 0.07885 | macro-AUROC = 0.72431 | macro-recall = 0.06840
[05/07 12:12:41][INFO] logging.py:   98: json_stats: {"mode": "val", "cur_epoch": "40", "map": 0.17750, "f1_macro": 0.07885, "auroc_macro": 0.72431, "recall_macro": 0.06840, "gpu_mem": "16.96G", "RAM": "70.70/251.58G", "_type": "val_epoch"}
[05/07 12:12:41][INFO] ava_eval_helper.py:  469: AVA results wrote to /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/detections_val_40.csv
[05/07 12:12:41][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 12:12:41][INFO] meters.py:  327: Saved CSVs:
  per-class AP: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/ap_per_class_val_40.csv
  detections: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/detections_val_40.csv
[05/07 12:13:22][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "41/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71556, "dt_data": 0.00062, "dt_net": 0.71493, "mode": "train", "loss": 0.20506, "lr": 0.00000}
[05/07 12:13:29][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "41/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.73631, "dt_data": 0.00042, "dt_net": 0.73588, "mode": "train", "loss": 0.22618, "lr": 0.00000}
[05/07 12:13:36][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "41/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.75244, "dt_data": 0.00042, "dt_net": 0.75202, "mode": "train", "loss": 0.18507, "lr": 0.00000}
[05/07 12:13:44][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "41/60", "cur_iter": "40", "eta": "0:00:29", "dt": 0.74934, "dt_data": 0.00042, "dt_net": 0.74892, "mode": "train", "loss": 0.19782, "lr": 0.00000}
[05/07 12:13:51][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "41/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.75542, "dt_data": 0.00040, "dt_net": 0.75501, "mode": "train", "loss": 0.21117, "lr": 0.00000}
[05/07 12:13:59][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "41/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.76084, "dt_data": 0.00064, "dt_net": 0.76019, "mode": "train", "loss": 0.21019, "lr": 0.00000}
[05/07 12:14:06][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "41/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.74846, "dt_data": 0.00022, "dt_net": 0.74823, "mode": "train", "loss": 0.18937, "lr": 0.00000}
[05/07 12:14:14][INFO] train_net.py:  669: Epoch 40 takes 93.16s. Epochs from 0 to 40 take 94.09s in average and 93.36s in median.
[05/07 12:14:14][INFO] train_net.py:  675: For epoch 40, each iteraction takes 1.18s in average. From epoch 0 to 40, each iteraction takes 1.19s in average.
[05/07 12:14:54][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "42/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71833, "dt_data": 0.00038, "dt_net": 0.71795, "mode": "train", "loss": 0.19986, "lr": 0.00000}
[05/07 12:15:01][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "42/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.74204, "dt_data": 0.00038, "dt_net": 0.74165, "mode": "train", "loss": 0.23933, "lr": 0.00000}
[05/07 12:15:09][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "42/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.74206, "dt_data": 0.00041, "dt_net": 0.74164, "mode": "train", "loss": 0.20226, "lr": 0.00000}
[05/07 12:15:16][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "42/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.76221, "dt_data": 0.00056, "dt_net": 0.76165, "mode": "train", "loss": 0.19284, "lr": 0.00000}
[05/07 12:15:24][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "42/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.75780, "dt_data": 0.00040, "dt_net": 0.75740, "mode": "train", "loss": 0.22935, "lr": 0.00000}
[05/07 12:15:32][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "42/60", "cur_iter": "60", "eta": "0:00:14", "dt": 0.74914, "dt_data": 0.00046, "dt_net": 0.74867, "mode": "train", "loss": 0.22041, "lr": 0.00000}
[05/07 12:15:39][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "42/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.76298, "dt_data": 0.00021, "dt_net": 0.76276, "mode": "train", "loss": 0.21679, "lr": 0.00000}
[05/07 12:15:47][INFO] train_net.py:  669: Epoch 41 takes 93.03s. Epochs from 0 to 41 take 94.06s in average and 93.34s in median.
[05/07 12:15:47][INFO] train_net.py:  675: For epoch 41, each iteraction takes 1.18s in average. From epoch 0 to 41, each iteraction takes 1.19s in average.
[05/07 12:16:27][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "43/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71895, "dt_data": 0.00047, "dt_net": 0.71848, "mode": "train", "loss": 0.20507, "lr": 0.00000}
[05/07 12:16:34][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "43/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.74315, "dt_data": 0.00042, "dt_net": 0.74273, "mode": "train", "loss": 0.19620, "lr": 0.00000}
[05/07 12:16:41][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "43/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.75184, "dt_data": 0.00045, "dt_net": 0.75139, "mode": "train", "loss": 0.19407, "lr": 0.00000}
[05/07 12:16:49][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "43/60", "cur_iter": "40", "eta": "0:00:29", "dt": 0.74103, "dt_data": 0.00042, "dt_net": 0.74061, "mode": "train", "loss": 0.18364, "lr": 0.00000}
[05/07 12:16:57][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "43/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.74865, "dt_data": 0.00039, "dt_net": 0.74825, "mode": "train", "loss": 0.21041, "lr": 0.00000}
[05/07 12:17:04][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "43/60", "cur_iter": "60", "eta": "0:00:14", "dt": 0.74028, "dt_data": 0.00041, "dt_net": 0.73987, "mode": "train", "loss": 0.22272, "lr": 0.00000}
[05/07 12:17:12][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "43/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.76062, "dt_data": 0.00021, "dt_net": 0.76041, "mode": "train", "loss": 0.20350, "lr": 0.00000}
[05/07 12:17:20][INFO] train_net.py:  669: Epoch 42 takes 92.64s. Epochs from 0 to 42 take 94.03s in average and 93.31s in median.
[05/07 12:17:20][INFO] train_net.py:  675: For epoch 42, each iteraction takes 1.17s in average. From epoch 0 to 42, each iteraction takes 1.19s in average.
[05/07 12:17:59][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "44/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71848, "dt_data": 0.00035, "dt_net": 0.71812, "mode": "train", "loss": 0.22357, "lr": 0.00000}
[05/07 12:18:07][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "44/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.74219, "dt_data": 0.00052, "dt_net": 0.74167, "mode": "train", "loss": 0.21105, "lr": 0.00000}
[05/07 12:18:14][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "44/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.75532, "dt_data": 0.00041, "dt_net": 0.75491, "mode": "train", "loss": 0.20540, "lr": 0.00000}
[05/07 12:18:22][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "44/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75682, "dt_data": 0.00044, "dt_net": 0.75638, "mode": "train", "loss": 0.24654, "lr": 0.00000}
[05/07 12:18:29][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "44/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.75065, "dt_data": 0.00041, "dt_net": 0.75024, "mode": "train", "loss": 0.21357, "lr": 0.00000}
[05/07 12:18:37][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "44/60", "cur_iter": "60", "eta": "0:00:14", "dt": 0.74762, "dt_data": 0.00049, "dt_net": 0.74713, "mode": "train", "loss": 0.20265, "lr": 0.00000}
[05/07 12:18:44][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "44/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.75513, "dt_data": 0.00023, "dt_net": 0.75490, "mode": "train", "loss": 0.21032, "lr": 0.00000}
[05/07 12:18:52][INFO] train_net.py:  669: Epoch 43 takes 92.56s. Epochs from 0 to 43 take 94.00s in average and 93.31s in median.
[05/07 12:18:52][INFO] train_net.py:  675: For epoch 43, each iteraction takes 1.17s in average. From epoch 0 to 43, each iteraction takes 1.19s in average.
[05/07 12:19:55][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "45/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71739, "dt_data": 0.00046, "dt_net": 0.71693, "mode": "train", "loss": 0.18658, "lr": 0.00000}
[05/07 12:20:02][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "45/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.73649, "dt_data": 0.00040, "dt_net": 0.73608, "mode": "train", "loss": 0.21557, "lr": 0.00000}
[05/07 12:20:10][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "45/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.74429, "dt_data": 0.00057, "dt_net": 0.74372, "mode": "train", "loss": 0.20296, "lr": 0.00000}
[05/07 12:20:17][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "45/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75343, "dt_data": 0.00046, "dt_net": 0.75297, "mode": "train", "loss": 0.21273, "lr": 0.00000}
[05/07 12:20:25][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "45/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.75530, "dt_data": 0.00036, "dt_net": 0.75494, "mode": "train", "loss": 0.22348, "lr": 0.00000}
[05/07 12:20:33][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "45/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.75822, "dt_data": 0.00044, "dt_net": 0.75777, "mode": "train", "loss": 0.20156, "lr": 0.00000}
[05/07 12:20:40][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "45/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.75725, "dt_data": 0.00022, "dt_net": 0.75702, "mode": "train", "loss": 0.20501, "lr": 0.00000}
[05/07 12:20:48][INFO] train_net.py:  669: Epoch 44 takes 115.67s. Epochs from 0 to 44 take 94.48s in average and 93.31s in median.
[05/07 12:20:48][INFO] train_net.py:  675: For epoch 44, each iteraction takes 1.46s in average. From epoch 0 to 44, each iteraction takes 1.20s in average.
[05/07 12:21:39][INFO] logging.py:   98: json_stats: {"_type": "val_iter", "cur_epoch": "45/60", "cur_iter": "10", "eta": "0:00:01", "dt": 0.35970, "dt_data": 0.01208, "dt_net": 0.34762, "mode": "val"}
[05/07 12:21:41][INFO] ava_eval_helper.py:  204: Evaluating with 542 unique GT frames.
[05/07 12:21:41][INFO] ava_eval_helper.py:  208: Evaluating with 542 unique detection frames
[05/07 12:21:41][INFO] ava_eval_helper.py:  469: AVA results wrote to detections_latest.csv
[05/07 12:21:41][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 12:21:41][INFO] ava_eval_helper.py:  469: AVA results wrote to groundtruth_latest.csv
[05/07 12:21:41][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 12:21:44][INFO] object_detection_evaluation.py:  751: The following classes have no ground truth examples: [ 2  3  4  5 10 13 15 16 18 19 20 21 23 25 28 31 32 33 35 37 39 40 41 42
 44 49 50 51 52 53 54 55 56 57 63 64 67 68 70 71 72 73 75 77]
[05/07 12:21:44][INFO] ava_eval_helper.py:  298: mAP@0.5 = 0.17777 | macro-F1 = 0.07891 | macro-AUROC = 0.72412 | macro-recall = 0.06852
[05/07 12:21:44][INFO] logging.py:   98: json_stats: {"mode": "val", "cur_epoch": "45", "map": 0.17777, "f1_macro": 0.07891, "auroc_macro": 0.72412, "recall_macro": 0.06852, "gpu_mem": "16.96G", "RAM": "70.30/251.58G", "_type": "val_epoch"}
[05/07 12:21:44][INFO] ava_eval_helper.py:  469: AVA results wrote to /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/detections_val_45.csv
[05/07 12:21:44][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 12:21:44][INFO] meters.py:  327: Saved CSVs:
  per-class AP: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/ap_per_class_val_45.csv
  detections: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/detections_val_45.csv
[05/07 12:22:32][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "46/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71879, "dt_data": 0.00050, "dt_net": 0.71828, "mode": "train", "loss": 0.21175, "lr": 0.00000}
[05/07 12:22:39][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "46/60", "cur_iter": "20", "eta": "0:00:43", "dt": 0.73278, "dt_data": 0.00042, "dt_net": 0.73236, "mode": "train", "loss": 0.21175, "lr": 0.00000}
[05/07 12:22:47][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "46/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.74476, "dt_data": 0.00050, "dt_net": 0.74425, "mode": "train", "loss": 0.21087, "lr": 0.00000}
[05/07 12:22:54][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "46/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75254, "dt_data": 0.00048, "dt_net": 0.75206, "mode": "train", "loss": 0.20964, "lr": 0.00000}
[05/07 12:23:02][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "46/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.74787, "dt_data": 0.00040, "dt_net": 0.74746, "mode": "train", "loss": 0.19407, "lr": 0.00000}
[05/07 12:23:09][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "46/60", "cur_iter": "60", "eta": "0:00:14", "dt": 0.73972, "dt_data": 0.00042, "dt_net": 0.73929, "mode": "train", "loss": 0.19246, "lr": 0.00000}
[05/07 12:23:17][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "46/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.74109, "dt_data": 0.00022, "dt_net": 0.74087, "mode": "train", "loss": 0.18100, "lr": 0.00000}
[05/07 12:23:25][INFO] train_net.py:  669: Epoch 45 takes 100.77s. Epochs from 0 to 45 take 94.62s in average and 93.34s in median.
[05/07 12:23:25][INFO] train_net.py:  675: For epoch 45, each iteraction takes 1.28s in average. From epoch 0 to 45, each iteraction takes 1.20s in average.
[05/07 12:24:06][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "47/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71840, "dt_data": 0.00050, "dt_net": 0.71790, "mode": "train", "loss": 0.20849, "lr": 0.00000}
[05/07 12:24:14][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "47/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.73762, "dt_data": 0.00055, "dt_net": 0.73707, "mode": "train", "loss": 0.20733, "lr": 0.00000}
[05/07 12:24:21][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "47/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.74841, "dt_data": 0.00050, "dt_net": 0.74791, "mode": "train", "loss": 0.22281, "lr": 0.00000}
[05/07 12:24:29][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "47/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75099, "dt_data": 0.00038, "dt_net": 0.75061, "mode": "train", "loss": 0.21348, "lr": 0.00000}
[05/07 12:24:36][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "47/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.75424, "dt_data": 0.00041, "dt_net": 0.75382, "mode": "train", "loss": 0.20687, "lr": 0.00000}
[05/07 12:24:44][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "47/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.75702, "dt_data": 0.00046, "dt_net": 0.75656, "mode": "train", "loss": 0.22529, "lr": 0.00000}
[05/07 12:24:51][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "47/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.76017, "dt_data": 0.00022, "dt_net": 0.75994, "mode": "train", "loss": 0.20997, "lr": 0.00000}
[05/07 12:24:59][INFO] train_net.py:  669: Epoch 46 takes 94.35s. Epochs from 0 to 46 take 94.61s in average and 93.36s in median.
[05/07 12:24:59][INFO] train_net.py:  675: For epoch 46, each iteraction takes 1.19s in average. From epoch 0 to 46, each iteraction takes 1.20s in average.
[05/07 12:25:40][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "48/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71710, "dt_data": 0.00042, "dt_net": 0.71668, "mode": "train", "loss": 0.21879, "lr": 0.00000}
[05/07 12:25:47][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "48/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.74059, "dt_data": 0.00041, "dt_net": 0.74018, "mode": "train", "loss": 0.21423, "lr": 0.00000}
[05/07 12:25:54][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "48/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.74817, "dt_data": 0.00039, "dt_net": 0.74778, "mode": "train", "loss": 0.20855, "lr": 0.00000}
[05/07 12:26:02][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "48/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75378, "dt_data": 0.00036, "dt_net": 0.75343, "mode": "train", "loss": 0.18420, "lr": 0.00000}
[05/07 12:26:09][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "48/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.76259, "dt_data": 0.00057, "dt_net": 0.76202, "mode": "train", "loss": 0.19534, "lr": 0.00000}
[05/07 12:26:17][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "48/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.75692, "dt_data": 0.00047, "dt_net": 0.75644, "mode": "train", "loss": 0.17847, "lr": 0.00000}
[05/07 12:26:25][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "48/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.76094, "dt_data": 0.00023, "dt_net": 0.76071, "mode": "train", "loss": 0.19525, "lr": 0.00000}
[05/07 12:26:33][INFO] train_net.py:  669: Epoch 47 takes 93.33s. Epochs from 0 to 47 take 94.58s in average and 93.34s in median.
[05/07 12:26:33][INFO] train_net.py:  675: For epoch 47, each iteraction takes 1.18s in average. From epoch 0 to 47, each iteraction takes 1.20s in average.
[05/07 12:27:13][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "49/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.72275, "dt_data": 0.00038, "dt_net": 0.72236, "mode": "train", "loss": 0.20357, "lr": 0.00000}
[05/07 12:27:20][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "49/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.73948, "dt_data": 0.00039, "dt_net": 0.73909, "mode": "train", "loss": 0.22420, "lr": 0.00000}
[05/07 12:27:27][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "49/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.75146, "dt_data": 0.00040, "dt_net": 0.75105, "mode": "train", "loss": 0.20026, "lr": 0.00000}
[05/07 12:27:35][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "49/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75269, "dt_data": 0.00040, "dt_net": 0.75230, "mode": "train", "loss": 0.22092, "lr": 0.00000}
[05/07 12:27:42][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "49/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.73729, "dt_data": 0.00046, "dt_net": 0.73683, "mode": "train", "loss": 0.20119, "lr": 0.00000}
[05/07 12:27:50][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "49/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.75733, "dt_data": 0.00048, "dt_net": 0.75685, "mode": "train", "loss": 0.19688, "lr": 0.00000}
[05/07 12:27:57][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "49/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.75719, "dt_data": 0.00024, "dt_net": 0.75695, "mode": "train", "loss": 0.19335, "lr": 0.00000}
[05/07 12:28:05][INFO] train_net.py:  669: Epoch 48 takes 92.89s. Epochs from 0 to 48 take 94.55s in average and 93.33s in median.
[05/07 12:28:05][INFO] train_net.py:  675: For epoch 48, each iteraction takes 1.18s in average. From epoch 0 to 48, each iteraction takes 1.20s in average.
[05/07 12:28:46][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "50/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71603, "dt_data": 0.00035, "dt_net": 0.71568, "mode": "train", "loss": 0.21188, "lr": 0.00000}
[05/07 12:28:53][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "50/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.73990, "dt_data": 0.00047, "dt_net": 0.73942, "mode": "train", "loss": 0.22631, "lr": 0.00000}
[05/07 12:29:00][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "50/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.74968, "dt_data": 0.00041, "dt_net": 0.74927, "mode": "train", "loss": 0.19939, "lr": 0.00000}
[05/07 12:29:08][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "50/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75280, "dt_data": 0.00039, "dt_net": 0.75241, "mode": "train", "loss": 0.22444, "lr": 0.00000}
[05/07 12:29:15][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "50/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.75094, "dt_data": 0.00036, "dt_net": 0.75058, "mode": "train", "loss": 0.18220, "lr": 0.00000}
[05/07 12:29:23][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "50/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.75792, "dt_data": 0.00045, "dt_net": 0.75746, "mode": "train", "loss": 0.22671, "lr": 0.00000}
[05/07 12:29:31][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "50/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.75820, "dt_data": 0.00023, "dt_net": 0.75797, "mode": "train", "loss": 0.19888, "lr": 0.00000}
[05/07 12:29:39][INFO] train_net.py:  669: Epoch 49 takes 93.11s. Epochs from 0 to 49 take 94.52s in average and 93.32s in median.
[05/07 12:29:39][INFO] train_net.py:  675: For epoch 49, each iteraction takes 1.18s in average. From epoch 0 to 49, each iteraction takes 1.20s in average.
[05/07 12:30:17][INFO] logging.py:   98: json_stats: {"_type": "val_iter", "cur_epoch": "50/60", "cur_iter": "10", "eta": "0:00:01", "dt": 0.36278, "dt_data": 0.01202, "dt_net": 0.35076, "mode": "val"}
[05/07 12:30:18][INFO] ava_eval_helper.py:  204: Evaluating with 542 unique GT frames.
[05/07 12:30:18][INFO] ava_eval_helper.py:  208: Evaluating with 542 unique detection frames
[05/07 12:30:18][INFO] ava_eval_helper.py:  469: AVA results wrote to detections_latest.csv
[05/07 12:30:18][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 12:30:18][INFO] ava_eval_helper.py:  469: AVA results wrote to groundtruth_latest.csv
[05/07 12:30:18][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 12:30:21][INFO] object_detection_evaluation.py:  751: The following classes have no ground truth examples: [ 2  3  4  5 10 13 15 16 18 19 20 21 23 25 28 31 32 33 35 37 39 40 41 42
 44 49 50 51 52 53 54 55 56 57 63 64 67 68 70 71 72 73 75 77]
[05/07 12:30:21][INFO] ava_eval_helper.py:  298: mAP@0.5 = 0.17792 | macro-F1 = 0.07892 | macro-AUROC = 0.72397 | macro-recall = 0.06864
[05/07 12:30:21][INFO] logging.py:   98: json_stats: {"mode": "val", "cur_epoch": "50", "map": 0.17792, "f1_macro": 0.07892, "auroc_macro": 0.72397, "recall_macro": 0.06864, "gpu_mem": "16.96G", "RAM": "70.33/251.58G", "_type": "val_epoch"}
[05/07 12:30:21][INFO] ava_eval_helper.py:  469: AVA results wrote to /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/detections_val_50.csv
[05/07 12:30:21][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 12:30:21][INFO] meters.py:  327: Saved CSVs:
  per-class AP: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/ap_per_class_val_50.csv
  detections: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/detections_val_50.csv
[05/07 12:31:02][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "51/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71648, "dt_data": 0.00048, "dt_net": 0.71600, "mode": "train", "loss": 0.22214, "lr": 0.00000}
[05/07 12:31:09][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "51/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.73968, "dt_data": 0.00033, "dt_net": 0.73935, "mode": "train", "loss": 0.23061, "lr": 0.00000}
[05/07 12:31:17][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "51/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.74660, "dt_data": 0.00044, "dt_net": 0.74615, "mode": "train", "loss": 0.19510, "lr": 0.00000}
[05/07 12:31:24][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "51/60", "cur_iter": "40", "eta": "0:00:29", "dt": 0.74922, "dt_data": 0.00037, "dt_net": 0.74884, "mode": "train", "loss": 0.20167, "lr": 0.00000}
[05/07 12:31:32][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "51/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.75432, "dt_data": 0.00044, "dt_net": 0.75388, "mode": "train", "loss": 0.20853, "lr": 0.00000}
[05/07 12:31:39][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "51/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.76016, "dt_data": 0.00045, "dt_net": 0.75971, "mode": "train", "loss": 0.21037, "lr": 0.00000}
[05/07 12:31:47][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "51/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.75885, "dt_data": 0.00021, "dt_net": 0.75863, "mode": "train", "loss": 0.20972, "lr": 0.00000}
[05/07 12:31:55][INFO] train_net.py:  669: Epoch 50 takes 93.75s. Epochs from 0 to 50 take 94.50s in average and 93.33s in median.
[05/07 12:31:55][INFO] train_net.py:  675: For epoch 50, each iteraction takes 1.19s in average. From epoch 0 to 50, each iteraction takes 1.20s in average.
[05/07 12:32:34][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "52/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71926, "dt_data": 0.00050, "dt_net": 0.71876, "mode": "train", "loss": 0.19743, "lr": 0.00000}
[05/07 12:32:42][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "52/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.74306, "dt_data": 0.00050, "dt_net": 0.74256, "mode": "train", "loss": 0.22375, "lr": 0.00000}
[05/07 12:32:49][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "52/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.74967, "dt_data": 0.00038, "dt_net": 0.74929, "mode": "train", "loss": 0.23578, "lr": 0.00000}
[05/07 12:32:57][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "52/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75432, "dt_data": 0.00040, "dt_net": 0.75392, "mode": "train", "loss": 0.23513, "lr": 0.00000}
[05/07 12:33:04][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "52/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.75885, "dt_data": 0.00040, "dt_net": 0.75844, "mode": "train", "loss": 0.22628, "lr": 0.00000}
[05/07 12:33:12][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "52/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.76351, "dt_data": 0.00056, "dt_net": 0.76295, "mode": "train", "loss": 0.19317, "lr": 0.00000}
[05/07 12:33:20][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "52/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.76448, "dt_data": 0.00022, "dt_net": 0.76426, "mode": "train", "loss": 0.21056, "lr": 0.00000}
[05/07 12:33:28][INFO] train_net.py:  669: Epoch 51 takes 92.52s. Epochs from 0 to 51 take 94.47s in average and 93.32s in median.
[05/07 12:33:28][INFO] train_net.py:  675: For epoch 51, each iteraction takes 1.17s in average. From epoch 0 to 51, each iteraction takes 1.20s in average.
[05/07 12:34:07][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "53/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.72092, "dt_data": 0.00043, "dt_net": 0.72049, "mode": "train", "loss": 0.20315, "lr": 0.00000}
[05/07 12:34:14][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "53/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.74153, "dt_data": 0.00042, "dt_net": 0.74111, "mode": "train", "loss": 0.21792, "lr": 0.00000}
[05/07 12:34:22][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "53/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.74931, "dt_data": 0.00038, "dt_net": 0.74893, "mode": "train", "loss": 0.19706, "lr": 0.00000}
[05/07 12:34:29][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "53/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75504, "dt_data": 0.00037, "dt_net": 0.75467, "mode": "train", "loss": 0.20061, "lr": 0.00000}
[05/07 12:34:37][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "53/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.74999, "dt_data": 0.00035, "dt_net": 0.74964, "mode": "train", "loss": 0.21211, "lr": 0.00000}
[05/07 12:34:44][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "53/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.76157, "dt_data": 0.00048, "dt_net": 0.76109, "mode": "train", "loss": 0.18912, "lr": 0.00000}
[05/07 12:34:52][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "53/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.76338, "dt_data": 0.00022, "dt_net": 0.76316, "mode": "train", "loss": 0.24834, "lr": 0.00000}
[05/07 12:35:00][INFO] train_net.py:  669: Epoch 52 takes 92.58s. Epochs from 0 to 52 take 94.43s in average and 93.31s in median.
[05/07 12:35:00][INFO] train_net.py:  675: For epoch 52, each iteraction takes 1.17s in average. From epoch 0 to 52, each iteraction takes 1.20s in average.
[05/07 12:35:40][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "54/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71960, "dt_data": 0.00039, "dt_net": 0.71921, "mode": "train", "loss": 0.20404, "lr": 0.00000}
[05/07 12:35:48][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "54/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.73971, "dt_data": 0.00045, "dt_net": 0.73926, "mode": "train", "loss": 0.22280, "lr": 0.00000}
[05/07 12:35:55][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "54/60", "cur_iter": "30", "eta": "0:00:38", "dt": 0.76209, "dt_data": 0.00038, "dt_net": 0.76171, "mode": "train", "loss": 0.20830, "lr": 0.00000}
[05/07 12:36:03][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "54/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.76711, "dt_data": 0.00052, "dt_net": 0.76658, "mode": "train", "loss": 0.20555, "lr": 0.00000}
[05/07 12:36:10][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "54/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.76414, "dt_data": 0.00049, "dt_net": 0.76365, "mode": "train", "loss": 0.20212, "lr": 0.00000}
[05/07 12:36:18][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "54/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.76333, "dt_data": 0.00044, "dt_net": 0.76289, "mode": "train", "loss": 0.20014, "lr": 0.00000}
[05/07 12:36:25][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "54/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.76273, "dt_data": 0.00021, "dt_net": 0.76252, "mode": "train", "loss": 0.22001, "lr": 0.00000}
[05/07 12:36:33][INFO] train_net.py:  669: Epoch 53 takes 93.28s. Epochs from 0 to 53 take 94.41s in average and 93.31s in median.
[05/07 12:36:33][INFO] train_net.py:  675: For epoch 53, each iteraction takes 1.18s in average. From epoch 0 to 53, each iteraction takes 1.20s in average.
[05/07 12:37:13][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "55/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.72179, "dt_data": 0.00036, "dt_net": 0.72142, "mode": "train", "loss": 0.19707, "lr": 0.00000}
[05/07 12:37:20][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "55/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.74471, "dt_data": 0.00040, "dt_net": 0.74430, "mode": "train", "loss": 0.25197, "lr": 0.00000}
[05/07 12:37:28][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "55/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.75149, "dt_data": 0.00039, "dt_net": 0.75110, "mode": "train", "loss": 0.20070, "lr": 0.00000}
[05/07 12:37:35][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "55/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.76013, "dt_data": 0.00046, "dt_net": 0.75967, "mode": "train", "loss": 0.21095, "lr": 0.00000}
[05/07 12:37:43][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "55/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.75797, "dt_data": 0.00042, "dt_net": 0.75754, "mode": "train", "loss": 0.20935, "lr": 0.00000}
[05/07 12:37:50][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "55/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.76623, "dt_data": 0.00040, "dt_net": 0.76583, "mode": "train", "loss": 0.24969, "lr": 0.00000}
[05/07 12:37:58][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "55/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.77382, "dt_data": 0.00022, "dt_net": 0.77360, "mode": "train", "loss": 0.23820, "lr": 0.00000}
[05/07 12:38:06][INFO] train_net.py:  669: Epoch 54 takes 92.68s. Epochs from 0 to 54 take 94.38s in average and 93.30s in median.
[05/07 12:38:06][INFO] train_net.py:  675: For epoch 54, each iteraction takes 1.17s in average. From epoch 0 to 54, each iteraction takes 1.19s in average.
[05/07 12:38:45][INFO] logging.py:   98: json_stats: {"_type": "val_iter", "cur_epoch": "55/60", "cur_iter": "10", "eta": "0:00:01", "dt": 0.36137, "dt_data": 0.01208, "dt_net": 0.34929, "mode": "val"}
[05/07 12:38:46][INFO] ava_eval_helper.py:  204: Evaluating with 542 unique GT frames.
[05/07 12:38:46][INFO] ava_eval_helper.py:  208: Evaluating with 542 unique detection frames
[05/07 12:38:46][INFO] ava_eval_helper.py:  469: AVA results wrote to detections_latest.csv
[05/07 12:38:46][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 12:38:46][INFO] ava_eval_helper.py:  469: AVA results wrote to groundtruth_latest.csv
[05/07 12:38:46][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 12:38:49][INFO] object_detection_evaluation.py:  751: The following classes have no ground truth examples: [ 2  3  4  5 10 13 15 16 18 19 20 21 23 25 28 31 32 33 35 37 39 40 41 42
 44 49 50 51 52 53 54 55 56 57 63 64 67 68 70 71 72 73 75 77]
[05/07 12:38:49][INFO] ava_eval_helper.py:  298: mAP@0.5 = 0.17789 | macro-F1 = 0.07892 | macro-AUROC = 0.72400 | macro-recall = 0.06864
[05/07 12:38:49][INFO] logging.py:   98: json_stats: {"mode": "val", "cur_epoch": "55", "map": 0.17789, "f1_macro": 0.07892, "auroc_macro": 0.72400, "recall_macro": 0.06864, "gpu_mem": "16.96G", "RAM": "70.34/251.58G", "_type": "val_epoch"}
[05/07 12:38:49][INFO] ava_eval_helper.py:  469: AVA results wrote to /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/detections_val_55.csv
[05/07 12:38:49][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 12:38:49][INFO] meters.py:  327: Saved CSVs:
  per-class AP: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/ap_per_class_val_55.csv
  detections: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/detections_val_55.csv
[05/07 12:39:33][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "56/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71838, "dt_data": 0.00038, "dt_net": 0.71800, "mode": "train", "loss": 0.21124, "lr": 0.00000}
[05/07 12:39:40][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "56/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.73865, "dt_data": 0.00036, "dt_net": 0.73829, "mode": "train", "loss": 0.20045, "lr": 0.00000}
[05/07 12:39:48][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "56/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.74671, "dt_data": 0.00061, "dt_net": 0.74610, "mode": "train", "loss": 0.24060, "lr": 0.00000}
[05/07 12:39:55][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "56/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75325, "dt_data": 0.00049, "dt_net": 0.75276, "mode": "train", "loss": 0.21862, "lr": 0.00000}
[05/07 12:40:03][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "56/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.75625, "dt_data": 0.00037, "dt_net": 0.75588, "mode": "train", "loss": 0.21953, "lr": 0.00000}
[05/07 12:40:10][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "56/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.75786, "dt_data": 0.00041, "dt_net": 0.75745, "mode": "train", "loss": 0.20729, "lr": 0.00000}
[05/07 12:40:18][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "56/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.76052, "dt_data": 0.00022, "dt_net": 0.76029, "mode": "train", "loss": 0.20959, "lr": 0.00000}
[05/07 12:40:26][INFO] train_net.py:  669: Epoch 55 takes 96.43s. Epochs from 0 to 55 take 94.42s in average and 93.31s in median.
[05/07 12:40:26][INFO] train_net.py:  675: For epoch 55, each iteraction takes 1.22s in average. From epoch 0 to 55, each iteraction takes 1.20s in average.
[05/07 12:41:06][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "57/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71751, "dt_data": 0.00044, "dt_net": 0.71707, "mode": "train", "loss": 0.20486, "lr": 0.00000}
[05/07 12:41:14][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "57/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.73856, "dt_data": 0.00045, "dt_net": 0.73810, "mode": "train", "loss": 0.23772, "lr": 0.00000}
[05/07 12:41:21][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "57/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.75012, "dt_data": 0.00041, "dt_net": 0.74970, "mode": "train", "loss": 0.17780, "lr": 0.00000}
[05/07 12:41:29][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "57/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75926, "dt_data": 0.00050, "dt_net": 0.75876, "mode": "train", "loss": 0.20408, "lr": 0.00000}
[05/07 12:41:36][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "57/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.74262, "dt_data": 0.00033, "dt_net": 0.74229, "mode": "train", "loss": 0.21494, "lr": 0.00000}
[05/07 12:41:44][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "57/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.75383, "dt_data": 0.00043, "dt_net": 0.75340, "mode": "train", "loss": 0.23284, "lr": 0.00000}
[05/07 12:41:51][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "57/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.75941, "dt_data": 0.00020, "dt_net": 0.75921, "mode": "train", "loss": 0.23783, "lr": 0.00000}
[05/07 12:41:59][INFO] train_net.py:  669: Epoch 56 takes 93.48s. Epochs from 0 to 56 take 94.40s in average and 93.31s in median.
[05/07 12:41:59][INFO] train_net.py:  675: For epoch 56, each iteraction takes 1.18s in average. From epoch 0 to 56, each iteraction takes 1.19s in average.
[05/07 12:42:39][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "58/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71873, "dt_data": 0.00048, "dt_net": 0.71824, "mode": "train", "loss": 0.21385, "lr": 0.00000}
[05/07 12:42:46][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "58/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.74170, "dt_data": 0.00037, "dt_net": 0.74133, "mode": "train", "loss": 0.22186, "lr": 0.00000}
[05/07 12:42:54][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "58/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.75223, "dt_data": 0.00043, "dt_net": 0.75180, "mode": "train", "loss": 0.22817, "lr": 0.00000}
[05/07 12:43:01][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "58/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75193, "dt_data": 0.00037, "dt_net": 0.75155, "mode": "train", "loss": 0.24553, "lr": 0.00000}
[05/07 12:43:09][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "58/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.75249, "dt_data": 0.00042, "dt_net": 0.75206, "mode": "train", "loss": 0.22825, "lr": 0.00000}
[05/07 12:43:16][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "58/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.76174, "dt_data": 0.00047, "dt_net": 0.76128, "mode": "train", "loss": 0.20435, "lr": 0.00000}
[05/07 12:43:24][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "58/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.75536, "dt_data": 0.00020, "dt_net": 0.75516, "mode": "train", "loss": 0.19587, "lr": 0.00000}
[05/07 12:43:32][INFO] train_net.py:  669: Epoch 57 takes 92.69s. Epochs from 0 to 57 take 94.37s in average and 93.31s in median.
[05/07 12:43:32][INFO] train_net.py:  675: For epoch 57, each iteraction takes 1.17s in average. From epoch 0 to 57, each iteraction takes 1.19s in average.
[05/07 12:44:12][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "59/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71912, "dt_data": 0.00039, "dt_net": 0.71873, "mode": "train", "loss": 0.19837, "lr": 0.00000}
[05/07 12:44:20][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "59/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.74174, "dt_data": 0.00038, "dt_net": 0.74136, "mode": "train", "loss": 0.21207, "lr": 0.00000}
[05/07 12:44:27][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "59/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.74862, "dt_data": 0.00046, "dt_net": 0.74816, "mode": "train", "loss": 0.21068, "lr": 0.00000}
[05/07 12:44:35][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "59/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75074, "dt_data": 0.00033, "dt_net": 0.75041, "mode": "train", "loss": 0.22121, "lr": 0.00000}
[05/07 12:44:42][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "59/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.74539, "dt_data": 0.00043, "dt_net": 0.74496, "mode": "train", "loss": 0.21583, "lr": 0.00000}
[05/07 12:44:50][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "59/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.75558, "dt_data": 0.00044, "dt_net": 0.75514, "mode": "train", "loss": 0.23230, "lr": 0.00000}
[05/07 12:44:57][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "59/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.75198, "dt_data": 0.00024, "dt_net": 0.75174, "mode": "train", "loss": 0.20293, "lr": 0.00000}
[05/07 12:45:05][INFO] train_net.py:  669: Epoch 58 takes 93.25s. Epochs from 0 to 58 take 94.35s in average and 93.30s in median.
[05/07 12:45:05][INFO] train_net.py:  675: For epoch 58, each iteraction takes 1.18s in average. From epoch 0 to 58, each iteraction takes 1.19s in average.
[05/07 12:45:45][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "60/60", "cur_iter": "10", "eta": "0:00:50", "dt": 0.71891, "dt_data": 0.00052, "dt_net": 0.71839, "mode": "train", "loss": 0.20457, "lr": 0.00000}
[05/07 12:45:53][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "60/60", "cur_iter": "20", "eta": "0:00:44", "dt": 0.73688, "dt_data": 0.00042, "dt_net": 0.73646, "mode": "train", "loss": 0.20711, "lr": 0.00000}
[05/07 12:46:00][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "60/60", "cur_iter": "30", "eta": "0:00:37", "dt": 0.74817, "dt_data": 0.00047, "dt_net": 0.74770, "mode": "train", "loss": 0.19826, "lr": 0.00000}
[05/07 12:46:08][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "60/60", "cur_iter": "40", "eta": "0:00:30", "dt": 0.75605, "dt_data": 0.00044, "dt_net": 0.75561, "mode": "train", "loss": 0.22194, "lr": 0.00000}
[05/07 12:46:15][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "60/60", "cur_iter": "50", "eta": "0:00:22", "dt": 0.76020, "dt_data": 0.00041, "dt_net": 0.75978, "mode": "train", "loss": 0.18617, "lr": 0.00000}
[05/07 12:46:23][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "60/60", "cur_iter": "60", "eta": "0:00:15", "dt": 0.75857, "dt_data": 0.00046, "dt_net": 0.75811, "mode": "train", "loss": 0.21285, "lr": 0.00000}
[05/07 12:46:30][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "60/60", "cur_iter": "70", "eta": "0:00:07", "dt": 0.76065, "dt_data": 0.00023, "dt_net": 0.76042, "mode": "train", "loss": 0.19744, "lr": 0.00000}
[05/07 12:46:39][INFO] train_net.py:  669: Epoch 59 takes 93.37s. Epochs from 0 to 59 take 94.33s in average and 93.31s in median.
[05/07 12:46:39][INFO] train_net.py:  675: For epoch 59, each iteraction takes 1.18s in average. From epoch 0 to 59, each iteraction takes 1.19s in average.
[05/07 12:47:17][INFO] logging.py:   98: json_stats: {"_type": "val_iter", "cur_epoch": "60/60", "cur_iter": "10", "eta": "0:00:01", "dt": 0.36096, "dt_data": 0.01206, "dt_net": 0.34889, "mode": "val"}
[05/07 12:47:18][INFO] ava_eval_helper.py:  204: Evaluating with 542 unique GT frames.
[05/07 12:47:18][INFO] ava_eval_helper.py:  208: Evaluating with 542 unique detection frames
[05/07 12:47:18][INFO] ava_eval_helper.py:  469: AVA results wrote to detections_latest.csv
[05/07 12:47:18][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 12:47:18][INFO] ava_eval_helper.py:  469: AVA results wrote to groundtruth_latest.csv
[05/07 12:47:18][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 12:47:21][INFO] object_detection_evaluation.py:  751: The following classes have no ground truth examples: [ 2  3  4  5 10 13 15 16 18 19 20 21 23 25 28 31 32 33 35 37 39 40 41 42
 44 49 50 51 52 53 54 55 56 57 63 64 67 68 70 71 72 73 75 77]
[05/07 12:47:21][INFO] ava_eval_helper.py:  298: mAP@0.5 = 0.17789 | macro-F1 = 0.07892 | macro-AUROC = 0.72396 | macro-recall = 0.06864
[05/07 12:47:21][INFO] logging.py:   98: json_stats: {"mode": "val", "cur_epoch": "60", "map": 0.17789, "f1_macro": 0.07892, "auroc_macro": 0.72396, "recall_macro": 0.06864, "gpu_mem": "16.96G", "RAM": "70.67/251.58G", "_type": "val_epoch"}
[05/07 12:47:21][INFO] ava_eval_helper.py:  469: AVA results wrote to /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/detections_val_60.csv
[05/07 12:47:21][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 12:47:21][INFO] meters.py:  327: Saved CSVs:
  per-class AP: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/ap_per_class_val_60.csv
  detections: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/detections_val_60.csv
[05/07 12:47:21][INFO] train_net.py:  757: training done: _p36.34_f70.80 _t1.56_m16.96 _a99.82 Top5 Acc: 0.00 MEM: 16.96 f: 70.8036
[05/07 12:49:37][INFO] test_net.py:  188: Test with config:
[05/07 12:49:37][INFO] test_net.py:  189: AUG:
  AA_TYPE: rand-m7-n4-mstd0.5-inc1
  COLOR_JITTER: 0.4
  ENABLE: True
  GEN_MASK_LOADER: False
  INTERPOLATION: bicubic
  MASK_FRAMES: False
  MASK_RATIO: 0.0
  MASK_TUBE: False
  MASK_WINDOW_SIZE: [8, 7, 7]
  MAX_MASK_PATCHES_PER_BLOCK: None
  NUM_SAMPLE: 2
  RE_COUNT: 1
  RE_MODE: pixel
  RE_PROB: 0.25
  RE_SPLIT: False
AVA:
  ANNOTATION_DIR: ../ava/annotations
  BGR: False
  DETECTION_SCORE_THRESH: 0.0
  EXCLUSION_FILE: ava_val_excluded_timestamps_v2.2.csv
  FRAME_DIR: ../ava/frames
  FRAME_LIST_DIR: ../ava/frame_lists
  FULL_TEST_ON_VAL: True
  GROUNDTRUTH_FILE: ava_test_gt.csv
  IMG_PROC_BACKEND: cv2
  LABEL_MAP_FILE: label_map.pbtxt
  TEST_FORCE_FLIP: False
  TEST_LISTS: ['test.csv']
  TEST_PREDICT_BOX_LISTS: ['ava_test_predicted_boxes.csv']
  TRAIN_GT_BOX_LISTS: ['ava_train.csv']
  TRAIN_LISTS: ['train.csv']
  TRAIN_PCA_JITTER_ONLY: True
  TRAIN_PREDICT_BOX_LISTS: []
  TRAIN_USE_COLOR_AUGMENTATION: False
BENCHMARK:
  LOG_PERIOD: 100
  NUM_EPOCHS: 5
  SHUFFLE: True
BN:
  GLOBAL_SYNC: False
  NORM_TYPE: batchnorm
  NUM_BATCHES_PRECISE: 200
  NUM_SPLITS: 1
  NUM_SYNC_DEVICES: 1
  USE_PRECISE_STATS: False
  WEIGHT_DECAY: 0.0
CONTRASTIVE:
  BN_MLP: False
  BN_SYNC_MLP: False
  DELTA_CLIPS_MAX: inf
  DELTA_CLIPS_MIN: -inf
  DIM: 128
  INTERP_MEMORY: False
  KNN_ON: True
  LENGTH: 239975
  LOCAL_SHUFFLE_BN: True
  MEM_TYPE: 1d
  MLP_DIM: 2048
  MOCO_MULTI_VIEW_QUEUE: False
  MOMENTUM: 0.5
  MOMENTUM_ANNEALING: False
  NUM_CLASSES_DOWNSTREAM: 400
  NUM_MLP_LAYERS: 1
  PREDICTOR_DEPTHS: []
  QUEUE_LEN: 65536
  SEQUENTIAL: False
  SIMCLR_DIST_ON: True
  SWAV_QEUE_LEN: 0
  T: 0.07
  TYPE: mem
DATA:
  COLOR_RND_GRAYSCALE: 0.0
  DECODING_BACKEND: torchvision
  DECODING_SHORT_SIZE: 256
  DUMMY_LOAD: False
  ENSEMBLE_METHOD: sum
  IN22K_TRAINVAL: False
  IN22k_VAL_IN1K: 
  INPUT_CHANNEL_NUM: [3]
  INV_UNIFORM_SAMPLE: False
  IN_VAL_CROP_RATIO: 0.875
  LOADER_CHUNK_OVERALL_SIZE: 0
  LOADER_CHUNK_SIZE: 0
  MEAN: [0.45, 0.45, 0.45]
  MULTI_LABEL: False
  NUM_FRAMES: 16
  PATH_LABEL_SEPARATOR:  
  PATH_PREFIX: 
  PATH_TO_DATA_DIR: ../ava
  PATH_TO_PRELOAD_IMDB: 
  RANDOM_FLIP: True
  REVERSE_INPUT_CHANNEL: False
  SAMPLING_RATE: 4
  SKIP_ROWS: 0
  SSL_BLUR_SIGMA_MAX: [0.0, 2.0]
  SSL_BLUR_SIGMA_MIN: [0.0, 0.1]
  SSL_COLOR_BRI_CON_SAT: [0.4, 0.4, 0.4]
  SSL_COLOR_HUE: 0.1
  SSL_COLOR_JITTER: False
  SSL_MOCOV2_AUG: False
  STD: [0.225, 0.225, 0.225]
  TARGET_FPS: 30
  TEST_CROP_SIZE: 224
  TIME_DIFF_PROB: 0.0
  TRAIN_CROP_NUM_SPATIAL: 1
  TRAIN_CROP_NUM_TEMPORAL: 1
  TRAIN_CROP_SIZE: 224
  TRAIN_JITTER_ASPECT_RELATIVE: [0.75, 1.3333]
  TRAIN_JITTER_FPS: 0.0
  TRAIN_JITTER_MOTION_SHIFT: False
  TRAIN_JITTER_SCALES: [256, 320]
  TRAIN_JITTER_SCALES_RELATIVE: [0.08, 1.0]
  TRAIN_PCA_EIGVAL: [0.225, 0.224, 0.229]
  TRAIN_PCA_EIGVEC: [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]]
  USE_OFFSET_SAMPLING: True
DATA_LOADER:
  ENABLE_MULTI_THREAD_DECODE: False
  NUM_WORKERS: 8
  PIN_MEMORY: True
DEMO:
  BUFFER_SIZE: 0
  CLIP_VIS_SIZE: 10
  COMMON_CLASS_NAMES: ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)']
  COMMON_CLASS_THRES: 0.7
  DETECTRON2_CFG: COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml
  DETECTRON2_THRESH: 0.9
  DETECTRON2_WEIGHTS: detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
  DISPLAY_HEIGHT: 0
  DISPLAY_WIDTH: 0
  ENABLE: False
  FPS: 30
  GT_BOXES: 
  INPUT_FORMAT: BGR
  INPUT_VIDEO: 
  LABEL_FILE_PATH: 
  NUM_CLIPS_SKIP: 0
  NUM_VIS_INSTANCES: 2
  OUTPUT_FILE: 
  OUTPUT_FPS: -1
  PREDS_BOXES: 
  SLOWMO: 1
  STARTING_SECOND: 900
  THREAD_ENABLE: False
  UNCOMMON_CLASS_THRES: 0.3
  VIS_MODE: thres
  WEBCAM: -1
DETECTION:
  ALIGNED: True
  ENABLE: True
  ROI_XFORM_RESOLUTION: 7
  SPATIAL_SCALE_FACTOR: 16
DIST_BACKEND: nccl
LOG_MODEL_INFO: True
LOG_PERIOD: 10
MASK:
  DECODER_DEPTH: 0
  DECODER_EMBED_DIM: 512
  DECODER_SEP_POS_EMBED: False
  DEC_KV_KERNEL: []
  DEC_KV_STRIDE: []
  ENABLE: False
  HEAD_TYPE: separate
  MAE_ON: False
  MAE_RND_MASK: False
  NORM_PRED_PIXEL: True
  PER_FRAME_MASKING: False
  PRED_HOG: False
  PRETRAIN_DEPTH: [15]
  SCALE_INIT_BY_DEPTH: False
  TIME_STRIDE_LOSS: True
MIXUP:
  ALPHA: 0.8
  CUTMIX_ALPHA: 1.0
  ENABLE: False
  LABEL_SMOOTH_VALUE: 0.1
  PROB: 1.0
  SWITCH_PROB: 0.5
MODEL:
  ACT_CHECKPOINT: False
  ARCH: mvit
  DETACH_FINAL_FC: False
  DROPCONNECT_RATE: 0.0
  DROPOUT_RATE: 0.5
  FC_INIT_STD: 0.01
  FP16_ALLREDUCE: False
  FROZEN_BN: False
  HEAD_ACT: none
  LOSS_FUNC: bce_logit
  MODEL_NAME: MViT
  MULTI_PATHWAY_ARCH: ['slowfast']
  NUM_CLASSES: 50
  SINGLE_PATHWAY_ARCH: ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'maskmvit']
MULTIGRID:
  BN_BASE_SIZE: 8
  DEFAULT_B: 0
  DEFAULT_S: 0
  DEFAULT_T: 0
  EPOCH_FACTOR: 1.5
  EVAL_FREQ: 3
  LONG_CYCLE: False
  LONG_CYCLE_FACTORS: [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)]
  LONG_CYCLE_SAMPLING_RATE: 0
  SHORT_CYCLE: False
  SHORT_CYCLE_FACTORS: [0.5, 0.7071067811865476]
MVIT:
  CLS_EMBED_ON: True
  DEPTH: 16
  DIM_MUL: [[1, 2.0], [3, 2.0], [14, 2.0]]
  DIM_MUL_IN_ATT: False
  DROPOUT_RATE: 0.0
  DROPPATH_RATE: 0.2
  EMBED_DIM: 96
  HEAD_INIT_SCALE: 1.0
  HEAD_MUL: [[1, 2.0], [3, 2.0], [14, 2.0]]
  LAYER_SCALE_INIT_VALUE: 0.0
  MLP_RATIO: 4.0
  MODE: conv
  NORM: layernorm
  NORM_STEM: False
  NUM_HEADS: 1
  PATCH_2D: False
  PATCH_KERNEL: [3, 7, 7]
  PATCH_PADDING: [1, 3, 3]
  PATCH_STRIDE: [2, 4, 4]
  POOL_FIRST: False
  POOL_KVQ_KERNEL: [3, 3, 3]
  POOL_KV_STRIDE: []
  POOL_KV_STRIDE_ADAPTIVE: [1, 8, 8]
  POOL_Q_STRIDE: [[1, 1, 2, 2], [3, 1, 2, 2], [14, 1, 2, 2]]
  QKV_BIAS: True
  REL_POS_SPATIAL: False
  REL_POS_TEMPORAL: False
  REL_POS_ZERO_INIT: False
  RESIDUAL_POOLING: False
  REV:
    BUFFER_LAYERS: []
    ENABLE: False
    PRE_Q_FUSION: avg
    RESPATH_FUSE: concat
    RES_PATH: conv
  SEPARATE_QKV: False
  SEP_POS_EMBED: True
  USE_ABS_POS: True
  USE_FIXED_SINCOS_POS: False
  USE_MEAN_POOLING: False
  ZERO_DECAY_POS_CLS: False
NONLOCAL:
  GROUP: [[1], [1], [1], [1]]
  INSTANTIATION: dot_product
  LOCATION: [[[]], [[]], [[]], [[]]]
  POOL: [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]
NUM_GPUS: 3
NUM_SHARDS: 1
OUTPUT_DIR: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4
RESNET:
  DEPTH: 50
  INPLACE_RELU: True
  NUM_BLOCK_TEMP_KERNEL: [[3], [4], [6], [3]]
  NUM_GROUPS: 1
  SPATIAL_DILATIONS: [[1], [1], [1], [1]]
  SPATIAL_STRIDES: [[1], [2], [2], [2]]
  STRIDE_1X1: False
  TRANS_FUNC: bottleneck_transform
  WIDTH_PER_GROUP: 64
  ZERO_INIT_FINAL_BN: False
  ZERO_INIT_FINAL_CONV: False
RNG_SEED: 0
SHARD_ID: 0
SLOWFAST:
  ALPHA: 8
  BETA_INV: 8
  FUSION_CONV_CHANNEL_RATIO: 2
  FUSION_KERNEL_SZ: 5
SOLVER:
  BASE_LR: 0.0001
  BASE_LR_SCALE_NUM_SHARDS: False
  BETAS: (0.9, 0.999)
  CLIP_GRAD_L2NORM: 1.0
  CLIP_GRAD_VAL: None
  COSINE_AFTER_WARMUP: False
  COSINE_END_LR: 0.0
  DAMPENING: 0.0
  GAMMA: 0.1
  LARS_ON: False
  LAYER_DECAY: 1.0
  LRS: [1, 0.1, 0.01, 0.001, 0.0001]
  LR_POLICY: steps_with_relative_lrs
  MAX_EPOCH: 60
  MOMENTUM: 0.9
  NESTEROV: True
  OPTIMIZING_METHOD: adamw
  STEPS: [0, 20, 30, 40, 50]
  STEP_SIZE: 1
  WARMUP_EPOCHS: 5.0
  WARMUP_FACTOR: 0.1
  WARMUP_START_LR: 1e-06
  WEIGHT_DECAY: 0.05
  ZERO_WD_1D_PARAM: False
TASK: 
TENSORBOARD:
  CATEGORIES_PATH: 
  CLASS_NAMES_PATH: 
  CONFUSION_MATRIX:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
  ENABLE: False
  HISTOGRAM:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
    TOPK: 10
  LOG_DIR: 
  MODEL_VIS:
    ACTIVATIONS: False
    COLORMAP: Pastel2
    ENABLE: False
    GRAD_CAM:
      COLORMAP: viridis
      ENABLE: True
      LAYER_LIST: []
      USE_TRUE_LABEL: False
    INPUT_VIDEO: False
    LAYER_LIST: []
    MODEL_WEIGHTS: False
    TOPK_PREDS: 1
  PREDICTIONS_PATH: 
  WRONG_PRED_VIS:
    ENABLE: False
    SUBSET_PATH: 
    TAG: Incorrectly classified videos.
TEST:
  BATCH_SIZE: 3
  CHECKPOINT_FILE_PATH: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/checkpoints/checkpoint_epoch_00050.pyth
  CHECKPOINT_TYPE: pytorch
  DATASET: ava
  ENABLE: True
  NUM_ENSEMBLE_VIEWS: 10
  NUM_SPATIAL_CROPS: 1
  NUM_TEMPORAL_CLIPS: [10]
  SAVE_RESULTS_PATH: 
TRAIN:
  AUTO_RESUME: True
  BATCH_SIZE: 48
  CHECKPOINT_CLEAR_NAME_PATTERN: ()
  CHECKPOINT_EPOCH_RESET: True
  CHECKPOINT_FILE_PATH: /home/lqi/lqi_temp/trainingspace/pretrained_models/MVIT_B_16x4.pyth
  CHECKPOINT_INFLATE: False
  CHECKPOINT_IN_INIT: False
  CHECKPOINT_PERIOD: 5
  CHECKPOINT_TYPE: pytorch
  DATASET: ava
  ENABLE: False
  EVAL_PERIOD: 5
  KILL_LOSS_EXPLOSION_FACTOR: 0.0
  MIXED_PRECISION: True
VIS_MASK:
  ENABLE: False
X3D:
  BN_LIN5: False
  BOTTLENECK_FACTOR: 1.0
  CHANNELWISE_3x3x3: True
  DEPTH_FACTOR: 1.0
  DIM_C1: 12
  DIM_C5: 2048
  SCALE_RES2: False
  WIDTH_FACTOR: 1.0
[05/07 12:49:39][INFO] misc.py:  186: Model:
DistributedDataParallel(
  (module): MViT(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
    )
    (blocks): ModuleList(
      (0): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=384, out_features=192, bias=True)
        )
        (proj): Linear(in_features=96, out_features=192, bias=True)
      )
      (1): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (2): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=384, bias=True)
        )
        (proj): Linear(in_features=192, out_features=384, bias=True)
      )
      (3): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (4-12): 9 x MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (13): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=768, bias=True)
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
      )
      (14): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (15): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (head): ResNetRoIHead(
      (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
      (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=768, out_features=50, bias=True)
      (act): Identity()
    )
  )
)
[05/07 12:49:39][INFO] misc.py:  188: Params: 36,341,522
[05/07 12:49:39][INFO] misc.py:  189: Mem: 0.2725391387939453 MB
[05/07 12:49:39][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat encountered 1 time(s)
[05/07 12:49:39][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[05/07 12:49:39][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 33 time(s)
[05/07 12:49:39][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 1 time(s)
[05/07 12:49:39][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 130 time(s)
[05/07 12:49:39][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/07 12:49:39][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/07 12:49:39][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/07 12:49:39][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/07 12:49:39][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/07 12:49:39][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/07 12:49:39][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/07 12:49:39][INFO] misc.py:  191: Flops: 70.803616128 G
[05/07 12:49:40][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat encountered 1 time(s)
[05/07 12:49:40][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[05/07 12:49:40][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 33 time(s)
[05/07 12:49:40][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 1 time(s)
[05/07 12:49:40][WARNING] jit_analysis.py:  499: Unsupported operator aten::layer_norm encountered 68 time(s)
[05/07 12:49:40][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 130 time(s)
[05/07 12:49:40][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/07 12:49:40][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/07 12:49:40][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/07 12:49:40][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/07 12:49:40][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/07 12:49:40][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/07 12:49:40][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/07 12:49:40][INFO] misc.py:  192: Activations: 239.822315 M
[05/07 12:49:40][INFO] misc.py:  197: nvidia-smi
[05/07 12:49:40][INFO] misc.py:  186: Model:
DistributedDataParallel(
  (module): MViT(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
    )
    (blocks): ModuleList(
      (0): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=384, out_features=192, bias=True)
        )
        (proj): Linear(in_features=96, out_features=192, bias=True)
      )
      (1): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (2): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=384, bias=True)
        )
        (proj): Linear(in_features=192, out_features=384, bias=True)
      )
      (3): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (4-12): 9 x MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (13): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=768, bias=True)
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
      )
      (14): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (15): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (head): ResNetRoIHead(
      (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
      (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=768, out_features=50, bias=True)
      (act): Identity()
    )
  )
)
[05/07 12:49:40][INFO] misc.py:  188: Params: 36,341,522
[05/07 12:49:40][INFO] misc.py:  189: Mem: 1.554469108581543 MB
[05/07 12:49:41][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat encountered 1 time(s)
[05/07 12:49:41][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[05/07 12:49:41][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 33 time(s)
[05/07 12:49:41][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 1 time(s)
[05/07 12:49:41][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 130 time(s)
[05/07 12:49:41][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/07 12:49:41][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/07 12:49:41][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/07 12:49:41][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/07 12:49:41][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/07 12:49:41][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/07 12:49:41][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/07 12:49:41][INFO] misc.py:  191: Flops: 70.803616128 G
[05/07 12:49:41][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat encountered 1 time(s)
[05/07 12:49:41][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[05/07 12:49:41][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 33 time(s)
[05/07 12:49:41][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 1 time(s)
[05/07 12:49:41][WARNING] jit_analysis.py:  499: Unsupported operator aten::layer_norm encountered 68 time(s)
[05/07 12:49:41][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 130 time(s)
[05/07 12:49:41][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/07 12:49:41][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/07 12:49:41][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/07 12:49:41][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/07 12:49:41][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/07 12:49:41][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/07 12:49:41][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/07 12:49:41][INFO] misc.py:  192: Activations: 239.822315 M
[05/07 12:49:41][INFO] misc.py:  197: nvidia-smi
[05/07 12:49:42][INFO] checkpoint.py:  213: Loading network weights from /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/checkpoints/checkpoint_epoch_00050.pyth.
[05/07 12:49:42][INFO] ava_helper.py:   58: Finished loading image paths from: ../ava/frame_lists/test.csv
[05/07 12:49:42][INFO] ava_helper.py:  139: Finished loading annotations from: ../ava/annotations/ava_test_predicted_boxes.csv
[05/07 12:49:42][INFO] ava_helper.py:  140: Detection threshold: 0.0
[05/07 12:49:42][INFO] ava_helper.py:  141: Number of unique boxes: 1136
[05/07 12:49:42][INFO] ava_helper.py:  142: Number of annotations: 0
[05/07 12:49:42][INFO] ava_helper.py:  185: 1091 keyframes used.
[05/07 12:49:42][INFO] ava_dataset.py:  130: === AVA dataset summary ===
[05/07 12:49:42][INFO] ava_dataset.py:  131: Split: test
[05/07 12:49:42][INFO] ava_dataset.py:  132: Number of videos: 953
[05/07 12:49:42][INFO] ava_dataset.py:  136: Number of frames: 85775
[05/07 12:49:42][INFO] ava_dataset.py:  137: Number of key frames: 1091
[05/07 12:49:42][INFO] ava_dataset.py:  138: Number of boxes: 1136.
[05/07 12:49:42][INFO] test_net.py:  215: Testing model for 364 iterations
[05/07 12:49:42][INFO] ava_helper.py:   58: Finished loading image paths from: ../ava/frame_lists/test.csv
[05/07 12:50:12][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "10", "eta": "0:00:29", "dt": 0.08303, "dt_data": 0.00215, "dt_net": 0.08087, "mode": "test"}
[05/07 12:50:13][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "20", "eta": "0:00:27", "dt": 0.07933, "dt_data": 0.00166, "dt_net": 0.07767, "mode": "test"}
[05/07 12:50:13][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "30", "eta": "0:00:33", "dt": 0.10123, "dt_data": 0.00222, "dt_net": 0.09900, "mode": "test"}
[05/07 12:50:14][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "40", "eta": "0:00:26", "dt": 0.08065, "dt_data": 0.00218, "dt_net": 0.07847, "mode": "test"}
[05/07 12:50:15][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "50", "eta": "0:00:25", "dt": 0.08105, "dt_data": 0.00209, "dt_net": 0.07896, "mode": "test"}
[05/07 12:50:16][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "60", "eta": "0:00:24", "dt": 0.08068, "dt_data": 0.00205, "dt_net": 0.07863, "mode": "test"}
[05/07 12:50:16][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "70", "eta": "0:00:23", "dt": 0.07982, "dt_data": 0.00181, "dt_net": 0.07801, "mode": "test"}
[05/07 12:50:17][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "80", "eta": "0:00:15", "dt": 0.05503, "dt_data": 0.00156, "dt_net": 0.05348, "mode": "test"}
[05/07 12:50:18][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "90", "eta": "0:00:22", "dt": 0.08010, "dt_data": 0.00183, "dt_net": 0.07826, "mode": "test"}
[05/07 12:50:19][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "100", "eta": "0:00:21", "dt": 0.08150, "dt_data": 0.00171, "dt_net": 0.07978, "mode": "test"}
[05/07 12:50:20][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "110", "eta": "0:00:20", "dt": 0.08204, "dt_data": 0.00184, "dt_net": 0.08020, "mode": "test"}
[05/07 12:50:20][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "120", "eta": "0:00:20", "dt": 0.08176, "dt_data": 0.00172, "dt_net": 0.08004, "mode": "test"}
[05/07 12:50:21][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "130", "eta": "0:00:13", "dt": 0.05569, "dt_data": 0.00173, "dt_net": 0.05395, "mode": "test"}
[05/07 12:50:22][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "140", "eta": "0:00:18", "dt": 0.08200, "dt_data": 0.00185, "dt_net": 0.08014, "mode": "test"}
[05/07 12:50:23][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "150", "eta": "0:00:17", "dt": 0.08159, "dt_data": 0.00209, "dt_net": 0.07950, "mode": "test"}
[05/07 12:50:23][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "160", "eta": "0:00:16", "dt": 0.08178, "dt_data": 0.00158, "dt_net": 0.08020, "mode": "test"}
[05/07 12:50:24][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "170", "eta": "0:00:15", "dt": 0.08193, "dt_data": 0.00191, "dt_net": 0.08001, "mode": "test"}
[05/07 12:50:25][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "180", "eta": "0:00:15", "dt": 0.08267, "dt_data": 0.00171, "dt_net": 0.08096, "mode": "test"}
[05/07 12:50:26][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "190", "eta": "0:00:14", "dt": 0.08243, "dt_data": 0.00224, "dt_net": 0.08019, "mode": "test"}
[05/07 12:50:26][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "200", "eta": "0:00:09", "dt": 0.05685, "dt_data": 0.00196, "dt_net": 0.05489, "mode": "test"}
[05/07 12:50:27][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "210", "eta": "0:00:12", "dt": 0.08065, "dt_data": 0.00235, "dt_net": 0.07830, "mode": "test"}
[05/07 12:50:28][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "220", "eta": "0:00:12", "dt": 0.08388, "dt_data": 0.00168, "dt_net": 0.08219, "mode": "test"}
[05/07 12:50:29][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "230", "eta": "0:00:11", "dt": 0.08212, "dt_data": 0.00244, "dt_net": 0.07967, "mode": "test"}
[05/07 12:50:29][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "240", "eta": "0:00:10", "dt": 0.08203, "dt_data": 0.00226, "dt_net": 0.07976, "mode": "test"}
[05/07 12:50:30][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "250", "eta": "0:00:09", "dt": 0.08132, "dt_data": 0.00177, "dt_net": 0.07955, "mode": "test"}
[05/07 12:50:31][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "260", "eta": "0:00:08", "dt": 0.08163, "dt_data": 0.00223, "dt_net": 0.07939, "mode": "test"}
[05/07 12:50:32][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "270", "eta": "0:00:07", "dt": 0.08326, "dt_data": 0.00179, "dt_net": 0.08147, "mode": "test"}
[05/07 12:50:32][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "280", "eta": "0:00:06", "dt": 0.08084, "dt_data": 0.00187, "dt_net": 0.07896, "mode": "test"}
[05/07 12:50:33][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "290", "eta": "0:00:06", "dt": 0.08286, "dt_data": 0.00197, "dt_net": 0.08089, "mode": "test"}
[05/07 12:50:34][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "300", "eta": "0:00:03", "dt": 0.05766, "dt_data": 0.00171, "dt_net": 0.05595, "mode": "test"}
[05/07 12:50:35][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "310", "eta": "0:00:03", "dt": 0.05563, "dt_data": 0.00181, "dt_net": 0.05381, "mode": "test"}
[05/07 12:50:35][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "320", "eta": "0:00:03", "dt": 0.08363, "dt_data": 0.00186, "dt_net": 0.08177, "mode": "test"}
[05/07 12:50:36][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "330", "eta": "0:00:02", "dt": 0.08417, "dt_data": 0.00176, "dt_net": 0.08241, "mode": "test"}
[05/07 12:50:37][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "340", "eta": "0:00:02", "dt": 0.08675, "dt_data": 0.00206, "dt_net": 0.08468, "mode": "test"}
[05/07 12:50:38][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "350", "eta": "0:00:00", "dt": 0.05674, "dt_data": 0.00149, "dt_net": 0.05525, "mode": "test"}
[05/07 12:50:38][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "360", "eta": "0:00:00", "dt": 0.05560, "dt_data": 0.00148, "dt_net": 0.05413, "mode": "test"}
[05/07 12:50:40][INFO] ava_eval_helper.py:  204: Evaluating with 1091 unique GT frames.
[05/07 12:50:40][INFO] ava_eval_helper.py:  208: Evaluating with 1091 unique detection frames
[05/07 12:50:40][INFO] ava_eval_helper.py:  469: AVA results wrote to detections_latest.csv
[05/07 12:50:40][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 12:50:40][INFO] ava_eval_helper.py:  469: AVA results wrote to groundtruth_latest.csv
[05/07 12:50:40][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 12:50:46][INFO] object_detection_evaluation.py:  751: The following classes have no ground truth examples: [ 2  4  9 13 15 16 18 19 20 21 23 25 31 32 33 35 37 39 40 41 42 44 49 50
 51 52 53 54 55 58 63 67 68 71 72 73 75 76 77]
[05/07 12:50:46][INFO] ava_eval_helper.py:  298: mAP@0.5 = 0.12856 | macro-F1 = 0.05539 | macro-AUROC = 0.74626 | macro-recall = 0.04662
[05/07 12:50:46][INFO] logging.py:   98: json_stats: {"mode": "test", "map": 0.12856, "f1_macro": 0.05539, "auroc_macro": 0.74626, "recall_macro": 0.04662}
[05/07 12:50:46][INFO] ava_eval_helper.py:  469: AVA results wrote to /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/detections_test.csv
[05/07 12:50:46][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 12:50:46][INFO] meters.py:  327: Saved CSVs:
  per-class AP: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/ap_per_class_test.csv
  detections: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/detections_test.csv
[05/07 12:50:46][INFO] test_net.py:  256: Finalized testing with 10 temporal clips and 1 spatial crops
[05/07 12:50:46][INFO] test_net.py:  275: _p36.34_f70.80_10a12.86 Top5 Acc: 12.86 MEM: 1.55 f: 70.8036
[05/07 12:50:46][INFO] test_net.py:  276: _p36.34_f70.80_10a12.86
[05/07 12:52:24][INFO] test_net.py:  188: Test with config:
[05/07 12:52:24][INFO] test_net.py:  189: AUG:
  AA_TYPE: rand-m7-n4-mstd0.5-inc1
  COLOR_JITTER: 0.4
  ENABLE: True
  GEN_MASK_LOADER: False
  INTERPOLATION: bicubic
  MASK_FRAMES: False
  MASK_RATIO: 0.0
  MASK_TUBE: False
  MASK_WINDOW_SIZE: [8, 7, 7]
  MAX_MASK_PATCHES_PER_BLOCK: None
  NUM_SAMPLE: 2
  RE_COUNT: 1
  RE_MODE: pixel
  RE_PROB: 0.25
  RE_SPLIT: False
AVA:
  ANNOTATION_DIR: ../ava/annotations
  BGR: False
  DETECTION_SCORE_THRESH: 0.0
  EXCLUSION_FILE: ava_val_excluded_timestamps_v2.2.csv
  FRAME_DIR: ../ava/frames
  FRAME_LIST_DIR: ../ava/frame_lists
  FULL_TEST_ON_VAL: True
  GROUNDTRUTH_FILE: ava_test_gt.csv
  IMG_PROC_BACKEND: cv2
  LABEL_MAP_FILE: label_map.pbtxt
  TEST_FORCE_FLIP: False
  TEST_LISTS: ['test.csv']
  TEST_PREDICT_BOX_LISTS: ['ava_test_predicted_boxes.csv']
  TRAIN_GT_BOX_LISTS: ['ava_train.csv']
  TRAIN_LISTS: ['train.csv']
  TRAIN_PCA_JITTER_ONLY: True
  TRAIN_PREDICT_BOX_LISTS: []
  TRAIN_USE_COLOR_AUGMENTATION: False
BENCHMARK:
  LOG_PERIOD: 100
  NUM_EPOCHS: 5
  SHUFFLE: True
BN:
  GLOBAL_SYNC: False
  NORM_TYPE: batchnorm
  NUM_BATCHES_PRECISE: 200
  NUM_SPLITS: 1
  NUM_SYNC_DEVICES: 1
  USE_PRECISE_STATS: False
  WEIGHT_DECAY: 0.0
CONTRASTIVE:
  BN_MLP: False
  BN_SYNC_MLP: False
  DELTA_CLIPS_MAX: inf
  DELTA_CLIPS_MIN: -inf
  DIM: 128
  INTERP_MEMORY: False
  KNN_ON: True
  LENGTH: 239975
  LOCAL_SHUFFLE_BN: True
  MEM_TYPE: 1d
  MLP_DIM: 2048
  MOCO_MULTI_VIEW_QUEUE: False
  MOMENTUM: 0.5
  MOMENTUM_ANNEALING: False
  NUM_CLASSES_DOWNSTREAM: 400
  NUM_MLP_LAYERS: 1
  PREDICTOR_DEPTHS: []
  QUEUE_LEN: 65536
  SEQUENTIAL: False
  SIMCLR_DIST_ON: True
  SWAV_QEUE_LEN: 0
  T: 0.07
  TYPE: mem
DATA:
  COLOR_RND_GRAYSCALE: 0.0
  DECODING_BACKEND: torchvision
  DECODING_SHORT_SIZE: 256
  DUMMY_LOAD: False
  ENSEMBLE_METHOD: sum
  IN22K_TRAINVAL: False
  IN22k_VAL_IN1K: 
  INPUT_CHANNEL_NUM: [3]
  INV_UNIFORM_SAMPLE: False
  IN_VAL_CROP_RATIO: 0.875
  LOADER_CHUNK_OVERALL_SIZE: 0
  LOADER_CHUNK_SIZE: 0
  MEAN: [0.45, 0.45, 0.45]
  MULTI_LABEL: False
  NUM_FRAMES: 16
  PATH_LABEL_SEPARATOR:  
  PATH_PREFIX: 
  PATH_TO_DATA_DIR: ../ava
  PATH_TO_PRELOAD_IMDB: 
  RANDOM_FLIP: True
  REVERSE_INPUT_CHANNEL: False
  SAMPLING_RATE: 4
  SKIP_ROWS: 0
  SSL_BLUR_SIGMA_MAX: [0.0, 2.0]
  SSL_BLUR_SIGMA_MIN: [0.0, 0.1]
  SSL_COLOR_BRI_CON_SAT: [0.4, 0.4, 0.4]
  SSL_COLOR_HUE: 0.1
  SSL_COLOR_JITTER: False
  SSL_MOCOV2_AUG: False
  STD: [0.225, 0.225, 0.225]
  TARGET_FPS: 30
  TEST_CROP_SIZE: 224
  TIME_DIFF_PROB: 0.0
  TRAIN_CROP_NUM_SPATIAL: 1
  TRAIN_CROP_NUM_TEMPORAL: 1
  TRAIN_CROP_SIZE: 224
  TRAIN_JITTER_ASPECT_RELATIVE: [0.75, 1.3333]
  TRAIN_JITTER_FPS: 0.0
  TRAIN_JITTER_MOTION_SHIFT: False
  TRAIN_JITTER_SCALES: [256, 320]
  TRAIN_JITTER_SCALES_RELATIVE: [0.08, 1.0]
  TRAIN_PCA_EIGVAL: [0.225, 0.224, 0.229]
  TRAIN_PCA_EIGVEC: [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]]
  USE_OFFSET_SAMPLING: True
DATA_LOADER:
  ENABLE_MULTI_THREAD_DECODE: False
  NUM_WORKERS: 8
  PIN_MEMORY: True
DEMO:
  BUFFER_SIZE: 0
  CLIP_VIS_SIZE: 10
  COMMON_CLASS_NAMES: ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)']
  COMMON_CLASS_THRES: 0.7
  DETECTRON2_CFG: COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml
  DETECTRON2_THRESH: 0.9
  DETECTRON2_WEIGHTS: detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
  DISPLAY_HEIGHT: 0
  DISPLAY_WIDTH: 0
  ENABLE: False
  FPS: 30
  GT_BOXES: 
  INPUT_FORMAT: BGR
  INPUT_VIDEO: 
  LABEL_FILE_PATH: 
  NUM_CLIPS_SKIP: 0
  NUM_VIS_INSTANCES: 2
  OUTPUT_FILE: 
  OUTPUT_FPS: -1
  PREDS_BOXES: 
  SLOWMO: 1
  STARTING_SECOND: 900
  THREAD_ENABLE: False
  UNCOMMON_CLASS_THRES: 0.3
  VIS_MODE: thres
  WEBCAM: -1
DETECTION:
  ALIGNED: True
  ENABLE: True
  ROI_XFORM_RESOLUTION: 7
  SPATIAL_SCALE_FACTOR: 16
DIST_BACKEND: nccl
LOG_MODEL_INFO: True
LOG_PERIOD: 10
MASK:
  DECODER_DEPTH: 0
  DECODER_EMBED_DIM: 512
  DECODER_SEP_POS_EMBED: False
  DEC_KV_KERNEL: []
  DEC_KV_STRIDE: []
  ENABLE: False
  HEAD_TYPE: separate
  MAE_ON: False
  MAE_RND_MASK: False
  NORM_PRED_PIXEL: True
  PER_FRAME_MASKING: False
  PRED_HOG: False
  PRETRAIN_DEPTH: [15]
  SCALE_INIT_BY_DEPTH: False
  TIME_STRIDE_LOSS: True
MIXUP:
  ALPHA: 0.8
  CUTMIX_ALPHA: 1.0
  ENABLE: False
  LABEL_SMOOTH_VALUE: 0.1
  PROB: 1.0
  SWITCH_PROB: 0.5
MODEL:
  ACT_CHECKPOINT: False
  ARCH: mvit
  DETACH_FINAL_FC: False
  DROPCONNECT_RATE: 0.0
  DROPOUT_RATE: 0.5
  FC_INIT_STD: 0.01
  FP16_ALLREDUCE: False
  FROZEN_BN: False
  HEAD_ACT: none
  LOSS_FUNC: bce_logit
  MODEL_NAME: MViT
  MULTI_PATHWAY_ARCH: ['slowfast']
  NUM_CLASSES: 50
  SINGLE_PATHWAY_ARCH: ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'maskmvit']
MULTIGRID:
  BN_BASE_SIZE: 8
  DEFAULT_B: 0
  DEFAULT_S: 0
  DEFAULT_T: 0
  EPOCH_FACTOR: 1.5
  EVAL_FREQ: 3
  LONG_CYCLE: False
  LONG_CYCLE_FACTORS: [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)]
  LONG_CYCLE_SAMPLING_RATE: 0
  SHORT_CYCLE: False
  SHORT_CYCLE_FACTORS: [0.5, 0.7071067811865476]
MVIT:
  CLS_EMBED_ON: True
  DEPTH: 16
  DIM_MUL: [[1, 2.0], [3, 2.0], [14, 2.0]]
  DIM_MUL_IN_ATT: False
  DROPOUT_RATE: 0.0
  DROPPATH_RATE: 0.2
  EMBED_DIM: 96
  HEAD_INIT_SCALE: 1.0
  HEAD_MUL: [[1, 2.0], [3, 2.0], [14, 2.0]]
  LAYER_SCALE_INIT_VALUE: 0.0
  MLP_RATIO: 4.0
  MODE: conv
  NORM: layernorm
  NORM_STEM: False
  NUM_HEADS: 1
  PATCH_2D: False
  PATCH_KERNEL: [3, 7, 7]
  PATCH_PADDING: [1, 3, 3]
  PATCH_STRIDE: [2, 4, 4]
  POOL_FIRST: False
  POOL_KVQ_KERNEL: [3, 3, 3]
  POOL_KV_STRIDE: []
  POOL_KV_STRIDE_ADAPTIVE: [1, 8, 8]
  POOL_Q_STRIDE: [[1, 1, 2, 2], [3, 1, 2, 2], [14, 1, 2, 2]]
  QKV_BIAS: True
  REL_POS_SPATIAL: False
  REL_POS_TEMPORAL: False
  REL_POS_ZERO_INIT: False
  RESIDUAL_POOLING: False
  REV:
    BUFFER_LAYERS: []
    ENABLE: False
    PRE_Q_FUSION: avg
    RESPATH_FUSE: concat
    RES_PATH: conv
  SEPARATE_QKV: False
  SEP_POS_EMBED: True
  USE_ABS_POS: True
  USE_FIXED_SINCOS_POS: False
  USE_MEAN_POOLING: False
  ZERO_DECAY_POS_CLS: False
NONLOCAL:
  GROUP: [[1], [1], [1], [1]]
  INSTANTIATION: dot_product
  LOCATION: [[[]], [[]], [[]], [[]]]
  POOL: [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]
NUM_GPUS: 3
NUM_SHARDS: 1
OUTPUT_DIR: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4
RESNET:
  DEPTH: 50
  INPLACE_RELU: True
  NUM_BLOCK_TEMP_KERNEL: [[3], [4], [6], [3]]
  NUM_GROUPS: 1
  SPATIAL_DILATIONS: [[1], [1], [1], [1]]
  SPATIAL_STRIDES: [[1], [2], [2], [2]]
  STRIDE_1X1: False
  TRANS_FUNC: bottleneck_transform
  WIDTH_PER_GROUP: 64
  ZERO_INIT_FINAL_BN: False
  ZERO_INIT_FINAL_CONV: False
RNG_SEED: 0
SHARD_ID: 0
SLOWFAST:
  ALPHA: 8
  BETA_INV: 8
  FUSION_CONV_CHANNEL_RATIO: 2
  FUSION_KERNEL_SZ: 5
SOLVER:
  BASE_LR: 0.0001
  BASE_LR_SCALE_NUM_SHARDS: False
  BETAS: (0.9, 0.999)
  CLIP_GRAD_L2NORM: 1.0
  CLIP_GRAD_VAL: None
  COSINE_AFTER_WARMUP: False
  COSINE_END_LR: 0.0
  DAMPENING: 0.0
  GAMMA: 0.1
  LARS_ON: False
  LAYER_DECAY: 1.0
  LRS: [1, 0.1, 0.01, 0.001, 0.0001]
  LR_POLICY: steps_with_relative_lrs
  MAX_EPOCH: 60
  MOMENTUM: 0.9
  NESTEROV: True
  OPTIMIZING_METHOD: adamw
  STEPS: [0, 20, 30, 40, 50]
  STEP_SIZE: 1
  WARMUP_EPOCHS: 5.0
  WARMUP_FACTOR: 0.1
  WARMUP_START_LR: 1e-06
  WEIGHT_DECAY: 0.05
  ZERO_WD_1D_PARAM: False
TASK: 
TENSORBOARD:
  CATEGORIES_PATH: 
  CLASS_NAMES_PATH: 
  CONFUSION_MATRIX:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
  ENABLE: False
  HISTOGRAM:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
    TOPK: 10
  LOG_DIR: 
  MODEL_VIS:
    ACTIVATIONS: False
    COLORMAP: Pastel2
    ENABLE: False
    GRAD_CAM:
      COLORMAP: viridis
      ENABLE: True
      LAYER_LIST: []
      USE_TRUE_LABEL: False
    INPUT_VIDEO: False
    LAYER_LIST: []
    MODEL_WEIGHTS: False
    TOPK_PREDS: 1
  PREDICTIONS_PATH: 
  WRONG_PRED_VIS:
    ENABLE: False
    SUBSET_PATH: 
    TAG: Incorrectly classified videos.
TEST:
  BATCH_SIZE: 3
  CHECKPOINT_FILE_PATH: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/checkpoints/checkpoint_epoch_00040.pyth
  CHECKPOINT_TYPE: pytorch
  DATASET: ava
  ENABLE: True
  NUM_ENSEMBLE_VIEWS: 10
  NUM_SPATIAL_CROPS: 1
  NUM_TEMPORAL_CLIPS: [10]
  SAVE_RESULTS_PATH: 
TRAIN:
  AUTO_RESUME: True
  BATCH_SIZE: 48
  CHECKPOINT_CLEAR_NAME_PATTERN: ()
  CHECKPOINT_EPOCH_RESET: True
  CHECKPOINT_FILE_PATH: /home/lqi/lqi_temp/trainingspace/pretrained_models/MVIT_B_16x4.pyth
  CHECKPOINT_INFLATE: False
  CHECKPOINT_IN_INIT: False
  CHECKPOINT_PERIOD: 5
  CHECKPOINT_TYPE: pytorch
  DATASET: ava
  ENABLE: False
  EVAL_PERIOD: 5
  KILL_LOSS_EXPLOSION_FACTOR: 0.0
  MIXED_PRECISION: True
VIS_MASK:
  ENABLE: False
X3D:
  BN_LIN5: False
  BOTTLENECK_FACTOR: 1.0
  CHANNELWISE_3x3x3: True
  DEPTH_FACTOR: 1.0
  DIM_C1: 12
  DIM_C5: 2048
  SCALE_RES2: False
  WIDTH_FACTOR: 1.0
[05/07 12:52:26][INFO] misc.py:  186: Model:
DistributedDataParallel(
  (module): MViT(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
    )
    (blocks): ModuleList(
      (0): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=384, out_features=192, bias=True)
        )
        (proj): Linear(in_features=96, out_features=192, bias=True)
      )
      (1): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (2): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=384, bias=True)
        )
        (proj): Linear(in_features=192, out_features=384, bias=True)
      )
      (3): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (4-12): 9 x MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (13): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=768, bias=True)
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
      )
      (14): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (15): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (head): ResNetRoIHead(
      (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
      (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=768, out_features=50, bias=True)
      (act): Identity()
    )
  )
)
[05/07 12:52:26][INFO] misc.py:  188: Params: 36,341,522
[05/07 12:52:26][INFO] misc.py:  189: Mem: 0.2725391387939453 MB
[05/07 12:52:27][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat encountered 1 time(s)
[05/07 12:52:27][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[05/07 12:52:27][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 33 time(s)
[05/07 12:52:27][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 1 time(s)
[05/07 12:52:27][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 130 time(s)
[05/07 12:52:27][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/07 12:52:27][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/07 12:52:27][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/07 12:52:27][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/07 12:52:27][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/07 12:52:27][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/07 12:52:27][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/07 12:52:27][INFO] misc.py:  191: Flops: 70.803616128 G
[05/07 12:52:27][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat encountered 1 time(s)
[05/07 12:52:27][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[05/07 12:52:27][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 33 time(s)
[05/07 12:52:27][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 1 time(s)
[05/07 12:52:27][WARNING] jit_analysis.py:  499: Unsupported operator aten::layer_norm encountered 68 time(s)
[05/07 12:52:27][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 130 time(s)
[05/07 12:52:27][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/07 12:52:27][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/07 12:52:27][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/07 12:52:27][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/07 12:52:27][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/07 12:52:27][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/07 12:52:27][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/07 12:52:27][INFO] misc.py:  192: Activations: 239.822315 M
[05/07 12:52:27][INFO] misc.py:  197: nvidia-smi
[05/07 12:52:28][INFO] misc.py:  186: Model:
DistributedDataParallel(
  (module): MViT(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
    )
    (blocks): ModuleList(
      (0): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=384, out_features=192, bias=True)
        )
        (proj): Linear(in_features=96, out_features=192, bias=True)
      )
      (1): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (2): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=384, bias=True)
        )
        (proj): Linear(in_features=192, out_features=384, bias=True)
      )
      (3): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (4-12): 9 x MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (13): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=768, bias=True)
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
      )
      (14): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (15): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (head): ResNetRoIHead(
      (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
      (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=768, out_features=50, bias=True)
      (act): Identity()
    )
  )
)
[05/07 12:52:28][INFO] misc.py:  188: Params: 36,341,522
[05/07 12:52:28][INFO] misc.py:  189: Mem: 1.554469108581543 MB
[05/07 12:52:28][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat encountered 1 time(s)
[05/07 12:52:28][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[05/07 12:52:28][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 33 time(s)
[05/07 12:52:28][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 1 time(s)
[05/07 12:52:28][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 130 time(s)
[05/07 12:52:28][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/07 12:52:28][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/07 12:52:28][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/07 12:52:28][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/07 12:52:28][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/07 12:52:28][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/07 12:52:28][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/07 12:52:28][INFO] misc.py:  191: Flops: 70.803616128 G
[05/07 12:52:29][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat encountered 1 time(s)
[05/07 12:52:29][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[05/07 12:52:29][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 33 time(s)
[05/07 12:52:29][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 1 time(s)
[05/07 12:52:29][WARNING] jit_analysis.py:  499: Unsupported operator aten::layer_norm encountered 68 time(s)
[05/07 12:52:29][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 130 time(s)
[05/07 12:52:29][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/07 12:52:29][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/07 12:52:29][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/07 12:52:29][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/07 12:52:29][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/07 12:52:29][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/07 12:52:29][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/07 12:52:29][INFO] misc.py:  192: Activations: 239.822315 M
[05/07 12:52:29][INFO] misc.py:  197: nvidia-smi
[05/07 12:52:29][INFO] checkpoint.py:  213: Loading network weights from /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/checkpoints/checkpoint_epoch_00040.pyth.
[05/07 12:52:30][INFO] ava_helper.py:   58: Finished loading image paths from: ../ava/frame_lists/test.csv
[05/07 12:52:30][INFO] ava_helper.py:  139: Finished loading annotations from: ../ava/annotations/ava_test_predicted_boxes.csv
[05/07 12:52:30][INFO] ava_helper.py:  140: Detection threshold: 0.0
[05/07 12:52:30][INFO] ava_helper.py:  141: Number of unique boxes: 1136
[05/07 12:52:30][INFO] ava_helper.py:  142: Number of annotations: 0
[05/07 12:52:30][INFO] ava_helper.py:  185: 1091 keyframes used.
[05/07 12:52:30][INFO] ava_dataset.py:  130: === AVA dataset summary ===
[05/07 12:52:30][INFO] ava_dataset.py:  131: Split: test
[05/07 12:52:30][INFO] ava_dataset.py:  132: Number of videos: 953
[05/07 12:52:30][INFO] ava_dataset.py:  136: Number of frames: 85775
[05/07 12:52:30][INFO] ava_dataset.py:  137: Number of key frames: 1091
[05/07 12:52:30][INFO] ava_dataset.py:  138: Number of boxes: 1136.
[05/07 12:52:30][INFO] test_net.py:  215: Testing model for 364 iterations
[05/07 12:52:30][INFO] ava_helper.py:   58: Finished loading image paths from: ../ava/frame_lists/test.csv
[05/07 12:53:00][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "10", "eta": "0:00:29", "dt": 0.08224, "dt_data": 0.00202, "dt_net": 0.08022, "mode": "test"}
[05/07 12:53:00][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "20", "eta": "0:00:27", "dt": 0.08037, "dt_data": 0.00168, "dt_net": 0.07869, "mode": "test"}
[05/07 12:53:01][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "30", "eta": "0:00:34", "dt": 0.10207, "dt_data": 0.00224, "dt_net": 0.09983, "mode": "test"}
[05/07 12:53:02][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "40", "eta": "0:00:26", "dt": 0.08041, "dt_data": 0.00231, "dt_net": 0.07810, "mode": "test"}
[05/07 12:53:03][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "50", "eta": "0:00:26", "dt": 0.08355, "dt_data": 0.00234, "dt_net": 0.08121, "mode": "test"}
[05/07 12:53:03][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "60", "eta": "0:00:24", "dt": 0.08114, "dt_data": 0.00180, "dt_net": 0.07934, "mode": "test"}
[05/07 12:53:04][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "70", "eta": "0:00:23", "dt": 0.08019, "dt_data": 0.00179, "dt_net": 0.07840, "mode": "test"}
[05/07 12:53:05][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "80", "eta": "0:00:15", "dt": 0.05419, "dt_data": 0.00185, "dt_net": 0.05233, "mode": "test"}
[05/07 12:53:06][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "90", "eta": "0:00:22", "dt": 0.08121, "dt_data": 0.00182, "dt_net": 0.07939, "mode": "test"}
[05/07 12:53:07][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "100", "eta": "0:00:21", "dt": 0.08119, "dt_data": 0.00176, "dt_net": 0.07942, "mode": "test"}
[05/07 12:53:07][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "110", "eta": "0:00:21", "dt": 0.08240, "dt_data": 0.00178, "dt_net": 0.08062, "mode": "test"}
[05/07 12:53:08][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "120", "eta": "0:00:20", "dt": 0.08170, "dt_data": 0.00200, "dt_net": 0.07970, "mode": "test"}
[05/07 12:53:09][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "130", "eta": "0:00:13", "dt": 0.05544, "dt_data": 0.00173, "dt_net": 0.05371, "mode": "test"}
[05/07 12:53:10][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "140", "eta": "0:00:18", "dt": 0.08221, "dt_data": 0.00192, "dt_net": 0.08028, "mode": "test"}
[05/07 12:53:10][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "150", "eta": "0:00:17", "dt": 0.08064, "dt_data": 0.00238, "dt_net": 0.07826, "mode": "test"}
[05/07 12:53:11][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "160", "eta": "0:00:16", "dt": 0.08111, "dt_data": 0.00177, "dt_net": 0.07934, "mode": "test"}
[05/07 12:53:12][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "170", "eta": "0:00:16", "dt": 0.08374, "dt_data": 0.00183, "dt_net": 0.08191, "mode": "test"}
[05/07 12:53:13][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "180", "eta": "0:00:15", "dt": 0.08195, "dt_data": 0.00200, "dt_net": 0.07995, "mode": "test"}
[05/07 12:53:13][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "190", "eta": "0:00:14", "dt": 0.08274, "dt_data": 0.00233, "dt_net": 0.08040, "mode": "test"}
[05/07 12:53:14][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "200", "eta": "0:00:09", "dt": 0.05699, "dt_data": 0.00179, "dt_net": 0.05520, "mode": "test"}
[05/07 12:53:15][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "210", "eta": "0:00:12", "dt": 0.08313, "dt_data": 0.00236, "dt_net": 0.08076, "mode": "test"}
[05/07 12:53:16][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "220", "eta": "0:00:12", "dt": 0.08402, "dt_data": 0.00169, "dt_net": 0.08232, "mode": "test"}
[05/07 12:53:16][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "230", "eta": "0:00:11", "dt": 0.08345, "dt_data": 0.00208, "dt_net": 0.08137, "mode": "test"}
[05/07 12:53:17][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "240", "eta": "0:00:10", "dt": 0.08264, "dt_data": 0.00221, "dt_net": 0.08042, "mode": "test"}
[05/07 12:53:18][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "250", "eta": "0:00:09", "dt": 0.08287, "dt_data": 0.00162, "dt_net": 0.08125, "mode": "test"}
[05/07 12:53:19][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "260", "eta": "0:00:08", "dt": 0.08146, "dt_data": 0.00222, "dt_net": 0.07924, "mode": "test"}
[05/07 12:53:19][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "270", "eta": "0:00:07", "dt": 0.08280, "dt_data": 0.00149, "dt_net": 0.08131, "mode": "test"}
[05/07 12:53:20][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "280", "eta": "0:00:06", "dt": 0.08137, "dt_data": 0.00170, "dt_net": 0.07966, "mode": "test"}
[05/07 12:53:21][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "290", "eta": "0:00:06", "dt": 0.08183, "dt_data": 0.00157, "dt_net": 0.08025, "mode": "test"}
[05/07 12:53:22][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "300", "eta": "0:00:03", "dt": 0.05776, "dt_data": 0.00163, "dt_net": 0.05612, "mode": "test"}
[05/07 12:53:22][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "310", "eta": "0:00:03", "dt": 0.05498, "dt_data": 0.00181, "dt_net": 0.05317, "mode": "test"}
[05/07 12:53:23][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "320", "eta": "0:00:03", "dt": 0.08344, "dt_data": 0.00186, "dt_net": 0.08158, "mode": "test"}
[05/07 12:53:24][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "330", "eta": "0:00:03", "dt": 0.08829, "dt_data": 0.00173, "dt_net": 0.08656, "mode": "test"}
[05/07 12:53:25][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "340", "eta": "0:00:02", "dt": 0.08511, "dt_data": 0.00191, "dt_net": 0.08319, "mode": "test"}
[05/07 12:53:25][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "350", "eta": "0:00:00", "dt": 0.05684, "dt_data": 0.00155, "dt_net": 0.05529, "mode": "test"}
[05/07 12:53:26][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "360", "eta": "0:00:00", "dt": 0.05665, "dt_data": 0.00144, "dt_net": 0.05520, "mode": "test"}
[05/07 12:53:27][INFO] ava_eval_helper.py:  204: Evaluating with 1091 unique GT frames.
[05/07 12:53:27][INFO] ava_eval_helper.py:  208: Evaluating with 1091 unique detection frames
[05/07 12:53:27][INFO] ava_eval_helper.py:  469: AVA results wrote to detections_latest.csv
[05/07 12:53:27][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 12:53:27][INFO] ava_eval_helper.py:  469: AVA results wrote to groundtruth_latest.csv
[05/07 12:53:27][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 12:53:34][INFO] object_detection_evaluation.py:  751: The following classes have no ground truth examples: [ 2  4  9 13 15 16 18 19 20 21 23 25 31 32 33 35 37 39 40 41 42 44 49 50
 51 52 53 54 55 58 63 67 68 71 72 73 75 76 77]
[05/07 12:53:34][INFO] ava_eval_helper.py:  298: mAP@0.5 = 0.12393 | macro-F1 = 0.05530 | macro-AUROC = 0.74646 | macro-recall = 0.04641
[05/07 12:53:34][INFO] logging.py:   98: json_stats: {"mode": "test", "map": 0.12393, "f1_macro": 0.05530, "auroc_macro": 0.74646, "recall_macro": 0.04641}
[05/07 12:53:34][INFO] ava_eval_helper.py:  469: AVA results wrote to /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/detections_test.csv
[05/07 12:53:34][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 12:53:34][INFO] meters.py:  327: Saved CSVs:
  per-class AP: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/ap_per_class_test.csv
  detections: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/detections_test.csv
[05/07 12:53:34][INFO] test_net.py:  256: Finalized testing with 10 temporal clips and 1 spatial crops
[05/07 12:53:34][INFO] test_net.py:  275: _p36.34_f70.80_10a12.39 Top5 Acc: 12.39 MEM: 1.55 f: 70.8036
[05/07 12:53:34][INFO] test_net.py:  276: _p36.34_f70.80_10a12.39
[05/07 12:56:04][INFO] test_net.py:  188: Test with config:
[05/07 12:56:04][INFO] test_net.py:  189: AUG:
  AA_TYPE: rand-m7-n4-mstd0.5-inc1
  COLOR_JITTER: 0.4
  ENABLE: True
  GEN_MASK_LOADER: False
  INTERPOLATION: bicubic
  MASK_FRAMES: False
  MASK_RATIO: 0.0
  MASK_TUBE: False
  MASK_WINDOW_SIZE: [8, 7, 7]
  MAX_MASK_PATCHES_PER_BLOCK: None
  NUM_SAMPLE: 2
  RE_COUNT: 1
  RE_MODE: pixel
  RE_PROB: 0.25
  RE_SPLIT: False
AVA:
  ANNOTATION_DIR: ../ava/annotations
  BGR: False
  DETECTION_SCORE_THRESH: 0.0
  EXCLUSION_FILE: ava_val_excluded_timestamps_v2.2.csv
  FRAME_DIR: ../ava/frames
  FRAME_LIST_DIR: ../ava/frame_lists
  FULL_TEST_ON_VAL: True
  GROUNDTRUTH_FILE: ava_test_gt.csv
  IMG_PROC_BACKEND: cv2
  LABEL_MAP_FILE: label_map.pbtxt
  TEST_FORCE_FLIP: False
  TEST_LISTS: ['test.csv']
  TEST_PREDICT_BOX_LISTS: ['ava_test_predicted_boxes.csv']
  TRAIN_GT_BOX_LISTS: ['ava_train.csv']
  TRAIN_LISTS: ['train.csv']
  TRAIN_PCA_JITTER_ONLY: True
  TRAIN_PREDICT_BOX_LISTS: []
  TRAIN_USE_COLOR_AUGMENTATION: False
BENCHMARK:
  LOG_PERIOD: 100
  NUM_EPOCHS: 5
  SHUFFLE: True
BN:
  GLOBAL_SYNC: False
  NORM_TYPE: batchnorm
  NUM_BATCHES_PRECISE: 200
  NUM_SPLITS: 1
  NUM_SYNC_DEVICES: 1
  USE_PRECISE_STATS: False
  WEIGHT_DECAY: 0.0
CONTRASTIVE:
  BN_MLP: False
  BN_SYNC_MLP: False
  DELTA_CLIPS_MAX: inf
  DELTA_CLIPS_MIN: -inf
  DIM: 128
  INTERP_MEMORY: False
  KNN_ON: True
  LENGTH: 239975
  LOCAL_SHUFFLE_BN: True
  MEM_TYPE: 1d
  MLP_DIM: 2048
  MOCO_MULTI_VIEW_QUEUE: False
  MOMENTUM: 0.5
  MOMENTUM_ANNEALING: False
  NUM_CLASSES_DOWNSTREAM: 400
  NUM_MLP_LAYERS: 1
  PREDICTOR_DEPTHS: []
  QUEUE_LEN: 65536
  SEQUENTIAL: False
  SIMCLR_DIST_ON: True
  SWAV_QEUE_LEN: 0
  T: 0.07
  TYPE: mem
DATA:
  COLOR_RND_GRAYSCALE: 0.0
  DECODING_BACKEND: torchvision
  DECODING_SHORT_SIZE: 256
  DUMMY_LOAD: False
  ENSEMBLE_METHOD: sum
  IN22K_TRAINVAL: False
  IN22k_VAL_IN1K: 
  INPUT_CHANNEL_NUM: [3]
  INV_UNIFORM_SAMPLE: False
  IN_VAL_CROP_RATIO: 0.875
  LOADER_CHUNK_OVERALL_SIZE: 0
  LOADER_CHUNK_SIZE: 0
  MEAN: [0.45, 0.45, 0.45]
  MULTI_LABEL: False
  NUM_FRAMES: 16
  PATH_LABEL_SEPARATOR:  
  PATH_PREFIX: 
  PATH_TO_DATA_DIR: ../ava
  PATH_TO_PRELOAD_IMDB: 
  RANDOM_FLIP: True
  REVERSE_INPUT_CHANNEL: False
  SAMPLING_RATE: 4
  SKIP_ROWS: 0
  SSL_BLUR_SIGMA_MAX: [0.0, 2.0]
  SSL_BLUR_SIGMA_MIN: [0.0, 0.1]
  SSL_COLOR_BRI_CON_SAT: [0.4, 0.4, 0.4]
  SSL_COLOR_HUE: 0.1
  SSL_COLOR_JITTER: False
  SSL_MOCOV2_AUG: False
  STD: [0.225, 0.225, 0.225]
  TARGET_FPS: 30
  TEST_CROP_SIZE: 224
  TIME_DIFF_PROB: 0.0
  TRAIN_CROP_NUM_SPATIAL: 1
  TRAIN_CROP_NUM_TEMPORAL: 1
  TRAIN_CROP_SIZE: 224
  TRAIN_JITTER_ASPECT_RELATIVE: [0.75, 1.3333]
  TRAIN_JITTER_FPS: 0.0
  TRAIN_JITTER_MOTION_SHIFT: False
  TRAIN_JITTER_SCALES: [256, 320]
  TRAIN_JITTER_SCALES_RELATIVE: [0.08, 1.0]
  TRAIN_PCA_EIGVAL: [0.225, 0.224, 0.229]
  TRAIN_PCA_EIGVEC: [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]]
  USE_OFFSET_SAMPLING: True
DATA_LOADER:
  ENABLE_MULTI_THREAD_DECODE: False
  NUM_WORKERS: 8
  PIN_MEMORY: True
DEMO:
  BUFFER_SIZE: 0
  CLIP_VIS_SIZE: 10
  COMMON_CLASS_NAMES: ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)']
  COMMON_CLASS_THRES: 0.7
  DETECTRON2_CFG: COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml
  DETECTRON2_THRESH: 0.9
  DETECTRON2_WEIGHTS: detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
  DISPLAY_HEIGHT: 0
  DISPLAY_WIDTH: 0
  ENABLE: False
  FPS: 30
  GT_BOXES: 
  INPUT_FORMAT: BGR
  INPUT_VIDEO: 
  LABEL_FILE_PATH: 
  NUM_CLIPS_SKIP: 0
  NUM_VIS_INSTANCES: 2
  OUTPUT_FILE: 
  OUTPUT_FPS: -1
  PREDS_BOXES: 
  SLOWMO: 1
  STARTING_SECOND: 900
  THREAD_ENABLE: False
  UNCOMMON_CLASS_THRES: 0.3
  VIS_MODE: thres
  WEBCAM: -1
DETECTION:
  ALIGNED: True
  ENABLE: True
  ROI_XFORM_RESOLUTION: 7
  SPATIAL_SCALE_FACTOR: 16
DIST_BACKEND: nccl
LOG_MODEL_INFO: True
LOG_PERIOD: 10
MASK:
  DECODER_DEPTH: 0
  DECODER_EMBED_DIM: 512
  DECODER_SEP_POS_EMBED: False
  DEC_KV_KERNEL: []
  DEC_KV_STRIDE: []
  ENABLE: False
  HEAD_TYPE: separate
  MAE_ON: False
  MAE_RND_MASK: False
  NORM_PRED_PIXEL: True
  PER_FRAME_MASKING: False
  PRED_HOG: False
  PRETRAIN_DEPTH: [15]
  SCALE_INIT_BY_DEPTH: False
  TIME_STRIDE_LOSS: True
MIXUP:
  ALPHA: 0.8
  CUTMIX_ALPHA: 1.0
  ENABLE: False
  LABEL_SMOOTH_VALUE: 0.1
  PROB: 1.0
  SWITCH_PROB: 0.5
MODEL:
  ACT_CHECKPOINT: False
  ARCH: mvit
  DETACH_FINAL_FC: False
  DROPCONNECT_RATE: 0.0
  DROPOUT_RATE: 0.5
  FC_INIT_STD: 0.01
  FP16_ALLREDUCE: False
  FROZEN_BN: False
  HEAD_ACT: none
  LOSS_FUNC: bce_logit
  MODEL_NAME: MViT
  MULTI_PATHWAY_ARCH: ['slowfast']
  NUM_CLASSES: 50
  SINGLE_PATHWAY_ARCH: ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'maskmvit']
MULTIGRID:
  BN_BASE_SIZE: 8
  DEFAULT_B: 0
  DEFAULT_S: 0
  DEFAULT_T: 0
  EPOCH_FACTOR: 1.5
  EVAL_FREQ: 3
  LONG_CYCLE: False
  LONG_CYCLE_FACTORS: [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)]
  LONG_CYCLE_SAMPLING_RATE: 0
  SHORT_CYCLE: False
  SHORT_CYCLE_FACTORS: [0.5, 0.7071067811865476]
MVIT:
  CLS_EMBED_ON: True
  DEPTH: 16
  DIM_MUL: [[1, 2.0], [3, 2.0], [14, 2.0]]
  DIM_MUL_IN_ATT: False
  DROPOUT_RATE: 0.0
  DROPPATH_RATE: 0.2
  EMBED_DIM: 96
  HEAD_INIT_SCALE: 1.0
  HEAD_MUL: [[1, 2.0], [3, 2.0], [14, 2.0]]
  LAYER_SCALE_INIT_VALUE: 0.0
  MLP_RATIO: 4.0
  MODE: conv
  NORM: layernorm
  NORM_STEM: False
  NUM_HEADS: 1
  PATCH_2D: False
  PATCH_KERNEL: [3, 7, 7]
  PATCH_PADDING: [1, 3, 3]
  PATCH_STRIDE: [2, 4, 4]
  POOL_FIRST: False
  POOL_KVQ_KERNEL: [3, 3, 3]
  POOL_KV_STRIDE: []
  POOL_KV_STRIDE_ADAPTIVE: [1, 8, 8]
  POOL_Q_STRIDE: [[1, 1, 2, 2], [3, 1, 2, 2], [14, 1, 2, 2]]
  QKV_BIAS: True
  REL_POS_SPATIAL: False
  REL_POS_TEMPORAL: False
  REL_POS_ZERO_INIT: False
  RESIDUAL_POOLING: False
  REV:
    BUFFER_LAYERS: []
    ENABLE: False
    PRE_Q_FUSION: avg
    RESPATH_FUSE: concat
    RES_PATH: conv
  SEPARATE_QKV: False
  SEP_POS_EMBED: True
  USE_ABS_POS: True
  USE_FIXED_SINCOS_POS: False
  USE_MEAN_POOLING: False
  ZERO_DECAY_POS_CLS: False
NONLOCAL:
  GROUP: [[1], [1], [1], [1]]
  INSTANTIATION: dot_product
  LOCATION: [[[]], [[]], [[]], [[]]]
  POOL: [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]
NUM_GPUS: 3
NUM_SHARDS: 1
OUTPUT_DIR: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4
RESNET:
  DEPTH: 50
  INPLACE_RELU: True
  NUM_BLOCK_TEMP_KERNEL: [[3], [4], [6], [3]]
  NUM_GROUPS: 1
  SPATIAL_DILATIONS: [[1], [1], [1], [1]]
  SPATIAL_STRIDES: [[1], [2], [2], [2]]
  STRIDE_1X1: False
  TRANS_FUNC: bottleneck_transform
  WIDTH_PER_GROUP: 64
  ZERO_INIT_FINAL_BN: False
  ZERO_INIT_FINAL_CONV: False
RNG_SEED: 0
SHARD_ID: 0
SLOWFAST:
  ALPHA: 8
  BETA_INV: 8
  FUSION_CONV_CHANNEL_RATIO: 2
  FUSION_KERNEL_SZ: 5
SOLVER:
  BASE_LR: 0.0001
  BASE_LR_SCALE_NUM_SHARDS: False
  BETAS: (0.9, 0.999)
  CLIP_GRAD_L2NORM: 1.0
  CLIP_GRAD_VAL: None
  COSINE_AFTER_WARMUP: False
  COSINE_END_LR: 0.0
  DAMPENING: 0.0
  GAMMA: 0.1
  LARS_ON: False
  LAYER_DECAY: 1.0
  LRS: [1, 0.1, 0.01, 0.001, 0.0001]
  LR_POLICY: steps_with_relative_lrs
  MAX_EPOCH: 60
  MOMENTUM: 0.9
  NESTEROV: True
  OPTIMIZING_METHOD: adamw
  STEPS: [0, 20, 30, 40, 50]
  STEP_SIZE: 1
  WARMUP_EPOCHS: 5.0
  WARMUP_FACTOR: 0.1
  WARMUP_START_LR: 1e-06
  WEIGHT_DECAY: 0.05
  ZERO_WD_1D_PARAM: False
TASK: 
TENSORBOARD:
  CATEGORIES_PATH: 
  CLASS_NAMES_PATH: 
  CONFUSION_MATRIX:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
  ENABLE: False
  HISTOGRAM:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
    TOPK: 10
  LOG_DIR: 
  MODEL_VIS:
    ACTIVATIONS: False
    COLORMAP: Pastel2
    ENABLE: False
    GRAD_CAM:
      COLORMAP: viridis
      ENABLE: True
      LAYER_LIST: []
      USE_TRUE_LABEL: False
    INPUT_VIDEO: False
    LAYER_LIST: []
    MODEL_WEIGHTS: False
    TOPK_PREDS: 1
  PREDICTIONS_PATH: 
  WRONG_PRED_VIS:
    ENABLE: False
    SUBSET_PATH: 
    TAG: Incorrectly classified videos.
TEST:
  BATCH_SIZE: 3
  CHECKPOINT_FILE_PATH: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/checkpoints/checkpoint_epoch_00050.pyth
  CHECKPOINT_TYPE: pytorch
  DATASET: ava
  ENABLE: True
  NUM_ENSEMBLE_VIEWS: 10
  NUM_SPATIAL_CROPS: 1
  NUM_TEMPORAL_CLIPS: [10]
  SAVE_RESULTS_PATH: 
TRAIN:
  AUTO_RESUME: True
  BATCH_SIZE: 48
  CHECKPOINT_CLEAR_NAME_PATTERN: ()
  CHECKPOINT_EPOCH_RESET: True
  CHECKPOINT_FILE_PATH: /home/lqi/lqi_temp/trainingspace/pretrained_models/MVIT_B_16x4.pyth
  CHECKPOINT_INFLATE: False
  CHECKPOINT_IN_INIT: False
  CHECKPOINT_PERIOD: 5
  CHECKPOINT_TYPE: pytorch
  DATASET: ava
  ENABLE: False
  EVAL_PERIOD: 5
  KILL_LOSS_EXPLOSION_FACTOR: 0.0
  MIXED_PRECISION: True
VIS_MASK:
  ENABLE: False
X3D:
  BN_LIN5: False
  BOTTLENECK_FACTOR: 1.0
  CHANNELWISE_3x3x3: True
  DEPTH_FACTOR: 1.0
  DIM_C1: 12
  DIM_C5: 2048
  SCALE_RES2: False
  WIDTH_FACTOR: 1.0
[05/07 12:56:05][INFO] misc.py:  186: Model:
DistributedDataParallel(
  (module): MViT(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
    )
    (blocks): ModuleList(
      (0): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=384, out_features=192, bias=True)
        )
        (proj): Linear(in_features=96, out_features=192, bias=True)
      )
      (1): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (2): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=384, bias=True)
        )
        (proj): Linear(in_features=192, out_features=384, bias=True)
      )
      (3): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (4-12): 9 x MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (13): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=768, bias=True)
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
      )
      (14): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (15): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (head): ResNetRoIHead(
      (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
      (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=768, out_features=50, bias=True)
      (act): Identity()
    )
  )
)
[05/07 12:56:05][INFO] misc.py:  188: Params: 36,341,522
[05/07 12:56:05][INFO] misc.py:  189: Mem: 0.2725391387939453 MB
[05/07 12:56:06][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat encountered 1 time(s)
[05/07 12:56:06][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[05/07 12:56:06][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 33 time(s)
[05/07 12:56:06][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 1 time(s)
[05/07 12:56:06][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 130 time(s)
[05/07 12:56:06][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/07 12:56:06][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/07 12:56:06][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/07 12:56:06][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/07 12:56:06][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/07 12:56:06][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/07 12:56:06][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/07 12:56:06][INFO] misc.py:  191: Flops: 70.803616128 G
[05/07 12:56:07][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat encountered 1 time(s)
[05/07 12:56:07][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[05/07 12:56:07][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 33 time(s)
[05/07 12:56:07][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 1 time(s)
[05/07 12:56:07][WARNING] jit_analysis.py:  499: Unsupported operator aten::layer_norm encountered 68 time(s)
[05/07 12:56:07][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 130 time(s)
[05/07 12:56:07][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/07 12:56:07][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/07 12:56:07][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/07 12:56:07][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/07 12:56:07][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/07 12:56:07][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/07 12:56:07][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/07 12:56:07][INFO] misc.py:  192: Activations: 239.822315 M
[05/07 12:56:07][INFO] misc.py:  197: nvidia-smi
[05/07 12:56:07][INFO] misc.py:  186: Model:
DistributedDataParallel(
  (module): MViT(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
    )
    (blocks): ModuleList(
      (0): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=384, out_features=192, bias=True)
        )
        (proj): Linear(in_features=96, out_features=192, bias=True)
      )
      (1): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (2): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=384, bias=True)
        )
        (proj): Linear(in_features=192, out_features=384, bias=True)
      )
      (3): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (4-12): 9 x MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (13): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=768, bias=True)
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
      )
      (14): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (15): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (head): ResNetRoIHead(
      (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
      (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=768, out_features=50, bias=True)
      (act): Identity()
    )
  )
)
[05/07 12:56:07][INFO] misc.py:  188: Params: 36,341,522
[05/07 12:56:07][INFO] misc.py:  189: Mem: 1.554469108581543 MB
[05/07 12:56:08][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat encountered 1 time(s)
[05/07 12:56:08][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[05/07 12:56:08][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 33 time(s)
[05/07 12:56:08][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 1 time(s)
[05/07 12:56:08][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 130 time(s)
[05/07 12:56:08][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/07 12:56:08][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/07 12:56:08][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/07 12:56:08][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/07 12:56:08][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/07 12:56:08][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/07 12:56:08][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/07 12:56:08][INFO] misc.py:  191: Flops: 70.803616128 G
[05/07 12:56:08][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat encountered 1 time(s)
[05/07 12:56:08][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[05/07 12:56:08][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 33 time(s)
[05/07 12:56:08][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 1 time(s)
[05/07 12:56:08][WARNING] jit_analysis.py:  499: Unsupported operator aten::layer_norm encountered 68 time(s)
[05/07 12:56:08][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 130 time(s)
[05/07 12:56:08][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/07 12:56:08][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/07 12:56:08][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/07 12:56:08][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/07 12:56:08][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/07 12:56:08][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/07 12:56:08][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/07 12:56:08][INFO] misc.py:  192: Activations: 239.822315 M
[05/07 12:56:08][INFO] misc.py:  197: nvidia-smi
[05/07 12:56:08][INFO] checkpoint.py:  213: Loading network weights from /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/checkpoints/checkpoint_epoch_00050.pyth.
[05/07 12:56:09][INFO] ava_helper.py:   58: Finished loading image paths from: ../ava/frame_lists/test.csv
[05/07 12:56:09][INFO] ava_helper.py:  139: Finished loading annotations from: ../ava/annotations/ava_test_predicted_boxes.csv
[05/07 12:56:09][INFO] ava_helper.py:  140: Detection threshold: 0.0
[05/07 12:56:09][INFO] ava_helper.py:  141: Number of unique boxes: 1136
[05/07 12:56:09][INFO] ava_helper.py:  142: Number of annotations: 0
[05/07 12:56:09][INFO] ava_helper.py:  185: 1091 keyframes used.
[05/07 12:56:09][INFO] ava_dataset.py:  130: === AVA dataset summary ===
[05/07 12:56:09][INFO] ava_dataset.py:  131: Split: test
[05/07 12:56:09][INFO] ava_dataset.py:  132: Number of videos: 953
[05/07 12:56:09][INFO] ava_dataset.py:  136: Number of frames: 85775
[05/07 12:56:09][INFO] ava_dataset.py:  137: Number of key frames: 1091
[05/07 12:56:09][INFO] ava_dataset.py:  138: Number of boxes: 1136.
[05/07 12:56:09][INFO] test_net.py:  215: Testing model for 364 iterations
[05/07 12:56:09][INFO] ava_helper.py:   58: Finished loading image paths from: ../ava/frame_lists/test.csv
[05/07 12:56:38][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "10", "eta": "0:00:28", "dt": 0.08137, "dt_data": 0.00220, "dt_net": 0.07917, "mode": "test"}
[05/07 12:56:39][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "20", "eta": "0:00:27", "dt": 0.08009, "dt_data": 0.00161, "dt_net": 0.07848, "mode": "test"}
[05/07 12:56:40][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "30", "eta": "0:00:34", "dt": 0.10363, "dt_data": 0.00222, "dt_net": 0.10141, "mode": "test"}
[05/07 12:56:41][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "40", "eta": "0:00:31", "dt": 0.09675, "dt_data": 0.00224, "dt_net": 0.09450, "mode": "test"}
[05/07 12:56:41][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "50", "eta": "0:00:25", "dt": 0.07965, "dt_data": 0.00213, "dt_net": 0.07752, "mode": "test"}
[05/07 12:56:42][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "60", "eta": "0:00:24", "dt": 0.08075, "dt_data": 0.00177, "dt_net": 0.07898, "mode": "test"}
[05/07 12:56:43][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "70", "eta": "0:00:23", "dt": 0.08116, "dt_data": 0.00165, "dt_net": 0.07951, "mode": "test"}
[05/07 12:56:44][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "80", "eta": "0:00:15", "dt": 0.05457, "dt_data": 0.00179, "dt_net": 0.05277, "mode": "test"}
[05/07 12:56:44][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "90", "eta": "0:00:22", "dt": 0.08105, "dt_data": 0.00164, "dt_net": 0.07941, "mode": "test"}
[05/07 12:56:45][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "100", "eta": "0:00:22", "dt": 0.08340, "dt_data": 0.00183, "dt_net": 0.08157, "mode": "test"}
[05/07 12:56:46][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "110", "eta": "0:00:20", "dt": 0.08185, "dt_data": 0.00180, "dt_net": 0.08006, "mode": "test"}
[05/07 12:56:47][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "120", "eta": "0:00:20", "dt": 0.08275, "dt_data": 0.00182, "dt_net": 0.08092, "mode": "test"}
[05/07 12:56:47][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "130", "eta": "0:00:12", "dt": 0.05477, "dt_data": 0.00150, "dt_net": 0.05326, "mode": "test"}
[05/07 12:56:48][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "140", "eta": "0:00:18", "dt": 0.08303, "dt_data": 0.00179, "dt_net": 0.08124, "mode": "test"}
[05/07 12:56:49][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "150", "eta": "0:00:17", "dt": 0.08285, "dt_data": 0.00234, "dt_net": 0.08051, "mode": "test"}
[05/07 12:56:50][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "160", "eta": "0:00:16", "dt": 0.08047, "dt_data": 0.00187, "dt_net": 0.07859, "mode": "test"}
[05/07 12:56:50][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "170", "eta": "0:00:16", "dt": 0.08320, "dt_data": 0.00180, "dt_net": 0.08140, "mode": "test"}
[05/07 12:56:51][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "180", "eta": "0:00:15", "dt": 0.08356, "dt_data": 0.00150, "dt_net": 0.08206, "mode": "test"}
[05/07 12:56:52][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "190", "eta": "0:00:14", "dt": 0.08307, "dt_data": 0.00218, "dt_net": 0.08090, "mode": "test"}
[05/07 12:56:53][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "200", "eta": "0:00:09", "dt": 0.05612, "dt_data": 0.00173, "dt_net": 0.05450, "mode": "test"}
[05/07 12:56:53][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "210", "eta": "0:00:12", "dt": 0.08185, "dt_data": 0.00209, "dt_net": 0.07977, "mode": "test"}
[05/07 12:56:54][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "220", "eta": "0:00:12", "dt": 0.08364, "dt_data": 0.00190, "dt_net": 0.08173, "mode": "test"}
[05/07 12:56:55][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "230", "eta": "0:00:11", "dt": 0.08171, "dt_data": 0.00220, "dt_net": 0.07951, "mode": "test"}
[05/07 12:56:56][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "240", "eta": "0:00:10", "dt": 0.08290, "dt_data": 0.00232, "dt_net": 0.08057, "mode": "test"}
[05/07 12:56:56][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "250", "eta": "0:00:09", "dt": 0.08207, "dt_data": 0.00158, "dt_net": 0.08048, "mode": "test"}
[05/07 12:56:57][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "260", "eta": "0:00:08", "dt": 0.08221, "dt_data": 0.00211, "dt_net": 0.08009, "mode": "test"}
[05/07 12:56:58][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "270", "eta": "0:00:07", "dt": 0.08304, "dt_data": 0.00178, "dt_net": 0.08125, "mode": "test"}
[05/07 12:56:59][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "280", "eta": "0:00:07", "dt": 0.08523, "dt_data": 0.00169, "dt_net": 0.08354, "mode": "test"}
[05/07 12:56:59][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "290", "eta": "0:00:06", "dt": 0.08354, "dt_data": 0.00169, "dt_net": 0.08185, "mode": "test"}
[05/07 12:57:00][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "300", "eta": "0:00:03", "dt": 0.05742, "dt_data": 0.00150, "dt_net": 0.05591, "mode": "test"}
[05/07 12:57:01][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "310", "eta": "0:00:03", "dt": 0.05737, "dt_data": 0.00183, "dt_net": 0.05554, "mode": "test"}
[05/07 12:57:02][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "320", "eta": "0:00:03", "dt": 0.08478, "dt_data": 0.00156, "dt_net": 0.08322, "mode": "test"}
[05/07 12:57:02][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "330", "eta": "0:00:02", "dt": 0.08315, "dt_data": 0.00182, "dt_net": 0.08133, "mode": "test"}
[05/07 12:57:03][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "340", "eta": "0:00:02", "dt": 0.08183, "dt_data": 0.00176, "dt_net": 0.08006, "mode": "test"}
[05/07 12:57:04][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "350", "eta": "0:00:00", "dt": 0.05514, "dt_data": 0.00161, "dt_net": 0.05353, "mode": "test"}
[05/07 12:57:04][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "360", "eta": "0:00:00", "dt": 0.05445, "dt_data": 0.00149, "dt_net": 0.05296, "mode": "test"}
[05/07 12:57:06][INFO] ava_eval_helper.py:  204: Evaluating with 1091 unique GT frames.
[05/07 12:57:06][INFO] ava_eval_helper.py:  208: Evaluating with 1091 unique detection frames
[05/07 12:57:06][INFO] ava_eval_helper.py:  469: AVA results wrote to detections_latest.csv
[05/07 12:57:06][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 12:57:06][INFO] ava_eval_helper.py:  469: AVA results wrote to groundtruth_latest.csv
[05/07 12:57:06][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 12:57:12][INFO] object_detection_evaluation.py:  751: The following classes have no ground truth examples: [ 2  4  9 13 15 16 18 19 20 21 23 25 31 32 33 35 37 39 40 41 42 44 49 50
 51 52 53 54 55 58 63 67 68 71 72 73 75 76 77]
[05/07 12:57:12][INFO] ava_eval_helper.py:  298: mAP@0.5 = 0.12856 | macro-F1 = 0.05539 | macro-AUROC = 0.74626 | macro-recall = 0.04662
[05/07 12:57:12][INFO] logging.py:   98: json_stats: {"mode": "test", "map": 0.12856, "f1_macro": 0.05539, "auroc_macro": 0.74626, "recall_macro": 0.04662}
[05/07 12:57:12][INFO] ava_eval_helper.py:  469: AVA results wrote to /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/detections_test.csv
[05/07 12:57:12][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 12:57:12][INFO] meters.py:  327: Saved CSVs:
  per-class AP: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/ap_per_class_test.csv
  detections: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/detections_test.csv
[05/07 12:57:12][INFO] test_net.py:  256: Finalized testing with 10 temporal clips and 1 spatial crops
[05/07 12:57:12][INFO] test_net.py:  275: _p36.34_f70.80_10a12.86 Top5 Acc: 12.86 MEM: 1.55 f: 70.8036
[05/07 12:57:12][INFO] test_net.py:  276: _p36.34_f70.80_10a12.86
[05/08 01:42:08][INFO] test_net.py:  188: Test with config:
[05/08 01:42:08][INFO] test_net.py:  189: AUG:
  AA_TYPE: rand-m7-n4-mstd0.5-inc1
  COLOR_JITTER: 0.4
  ENABLE: True
  GEN_MASK_LOADER: False
  INTERPOLATION: bicubic
  MASK_FRAMES: False
  MASK_RATIO: 0.0
  MASK_TUBE: False
  MASK_WINDOW_SIZE: [8, 7, 7]
  MAX_MASK_PATCHES_PER_BLOCK: None
  NUM_SAMPLE: 2
  RE_COUNT: 1
  RE_MODE: pixel
  RE_PROB: 0.25
  RE_SPLIT: False
AVA:
  ANNOTATION_DIR: ../ava/annotations
  BGR: False
  DETECTION_SCORE_THRESH: 0.0
  EXCLUSION_FILE: ava_val_excluded_timestamps_v2.2.csv
  FRAME_DIR: ../ava/frames
  FRAME_LIST_DIR: ../ava/frame_lists
  FULL_TEST_ON_VAL: True
  GROUNDTRUTH_FILE: ava_test_gt.csv
  IMG_PROC_BACKEND: cv2
  LABEL_MAP_FILE: label_map.pbtxt
  TEST_FORCE_FLIP: False
  TEST_LISTS: ['test.csv']
  TEST_PREDICT_BOX_LISTS: ['ava_test_predicted_boxes.csv']
  TRAIN_GT_BOX_LISTS: ['ava_train.csv']
  TRAIN_LISTS: ['train.csv']
  TRAIN_PCA_JITTER_ONLY: True
  TRAIN_PREDICT_BOX_LISTS: []
  TRAIN_USE_COLOR_AUGMENTATION: False
BENCHMARK:
  LOG_PERIOD: 100
  NUM_EPOCHS: 5
  SHUFFLE: True
BN:
  GLOBAL_SYNC: False
  NORM_TYPE: batchnorm
  NUM_BATCHES_PRECISE: 200
  NUM_SPLITS: 1
  NUM_SYNC_DEVICES: 1
  USE_PRECISE_STATS: False
  WEIGHT_DECAY: 0.0
CONTRASTIVE:
  BN_MLP: False
  BN_SYNC_MLP: False
  DELTA_CLIPS_MAX: inf
  DELTA_CLIPS_MIN: -inf
  DIM: 128
  INTERP_MEMORY: False
  KNN_ON: True
  LENGTH: 239975
  LOCAL_SHUFFLE_BN: True
  MEM_TYPE: 1d
  MLP_DIM: 2048
  MOCO_MULTI_VIEW_QUEUE: False
  MOMENTUM: 0.5
  MOMENTUM_ANNEALING: False
  NUM_CLASSES_DOWNSTREAM: 400
  NUM_MLP_LAYERS: 1
  PREDICTOR_DEPTHS: []
  QUEUE_LEN: 65536
  SEQUENTIAL: False
  SIMCLR_DIST_ON: True
  SWAV_QEUE_LEN: 0
  T: 0.07
  TYPE: mem
DATA:
  COLOR_RND_GRAYSCALE: 0.0
  DECODING_BACKEND: torchvision
  DECODING_SHORT_SIZE: 256
  DUMMY_LOAD: False
  ENSEMBLE_METHOD: sum
  IN22K_TRAINVAL: False
  IN22k_VAL_IN1K: 
  INPUT_CHANNEL_NUM: [3]
  INV_UNIFORM_SAMPLE: False
  IN_VAL_CROP_RATIO: 0.875
  LOADER_CHUNK_OVERALL_SIZE: 0
  LOADER_CHUNK_SIZE: 0
  MEAN: [0.45, 0.45, 0.45]
  MULTI_LABEL: False
  NUM_FRAMES: 16
  PATH_LABEL_SEPARATOR:  
  PATH_PREFIX: 
  PATH_TO_DATA_DIR: ../ava
  PATH_TO_PRELOAD_IMDB: 
  RANDOM_FLIP: True
  REVERSE_INPUT_CHANNEL: False
  SAMPLING_RATE: 4
  SKIP_ROWS: 0
  SSL_BLUR_SIGMA_MAX: [0.0, 2.0]
  SSL_BLUR_SIGMA_MIN: [0.0, 0.1]
  SSL_COLOR_BRI_CON_SAT: [0.4, 0.4, 0.4]
  SSL_COLOR_HUE: 0.1
  SSL_COLOR_JITTER: False
  SSL_MOCOV2_AUG: False
  STD: [0.225, 0.225, 0.225]
  TARGET_FPS: 30
  TEST_CROP_SIZE: 224
  TIME_DIFF_PROB: 0.0
  TRAIN_CROP_NUM_SPATIAL: 1
  TRAIN_CROP_NUM_TEMPORAL: 1
  TRAIN_CROP_SIZE: 224
  TRAIN_JITTER_ASPECT_RELATIVE: [0.75, 1.3333]
  TRAIN_JITTER_FPS: 0.0
  TRAIN_JITTER_MOTION_SHIFT: False
  TRAIN_JITTER_SCALES: [256, 320]
  TRAIN_JITTER_SCALES_RELATIVE: [0.08, 1.0]
  TRAIN_PCA_EIGVAL: [0.225, 0.224, 0.229]
  TRAIN_PCA_EIGVEC: [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]]
  USE_OFFSET_SAMPLING: True
DATA_LOADER:
  ENABLE_MULTI_THREAD_DECODE: False
  NUM_WORKERS: 8
  PIN_MEMORY: True
DEMO:
  BUFFER_SIZE: 0
  CLIP_VIS_SIZE: 10
  COMMON_CLASS_NAMES: ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)']
  COMMON_CLASS_THRES: 0.7
  DETECTRON2_CFG: COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml
  DETECTRON2_THRESH: 0.9
  DETECTRON2_WEIGHTS: detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
  DISPLAY_HEIGHT: 0
  DISPLAY_WIDTH: 0
  ENABLE: False
  FPS: 30
  GT_BOXES: 
  INPUT_FORMAT: BGR
  INPUT_VIDEO: 
  LABEL_FILE_PATH: 
  NUM_CLIPS_SKIP: 0
  NUM_VIS_INSTANCES: 2
  OUTPUT_FILE: 
  OUTPUT_FPS: -1
  PREDS_BOXES: 
  SLOWMO: 1
  STARTING_SECOND: 900
  THREAD_ENABLE: False
  UNCOMMON_CLASS_THRES: 0.3
  VIS_MODE: thres
  WEBCAM: -1
DETECTION:
  ALIGNED: True
  ENABLE: True
  ROI_XFORM_RESOLUTION: 7
  SPATIAL_SCALE_FACTOR: 16
DIST_BACKEND: nccl
LOG_MODEL_INFO: True
LOG_PERIOD: 10
MASK:
  DECODER_DEPTH: 0
  DECODER_EMBED_DIM: 512
  DECODER_SEP_POS_EMBED: False
  DEC_KV_KERNEL: []
  DEC_KV_STRIDE: []
  ENABLE: False
  HEAD_TYPE: separate
  MAE_ON: False
  MAE_RND_MASK: False
  NORM_PRED_PIXEL: True
  PER_FRAME_MASKING: False
  PRED_HOG: False
  PRETRAIN_DEPTH: [15]
  SCALE_INIT_BY_DEPTH: False
  TIME_STRIDE_LOSS: True
MIXUP:
  ALPHA: 0.8
  CUTMIX_ALPHA: 1.0
  ENABLE: False
  LABEL_SMOOTH_VALUE: 0.1
  PROB: 1.0
  SWITCH_PROB: 0.5
MODEL:
  ACT_CHECKPOINT: False
  ARCH: mvit
  BLIP2:
    FREEZE: True
    PRETRAINED: Salesforce/blip2-flan-t5-xl
  DETACH_FINAL_FC: False
  DROPCONNECT_RATE: 0.0
  DROPOUT_RATE: 0.5
  FC_INIT_STD: 0.01
  FP16_ALLREDUCE: False
  FROZEN_BN: False
  HEAD_ACT: sigmoid
  LOSS_FUNC: bce
  MODEL_NAME: MViT
  MULTI_PATHWAY_ARCH: ['slowfast']
  NUM_CLASSES: 50
  SINGLE_PATHWAY_ARCH: ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'maskmvit', 'blip2']
MULTIGRID:
  BN_BASE_SIZE: 8
  DEFAULT_B: 0
  DEFAULT_S: 0
  DEFAULT_T: 0
  EPOCH_FACTOR: 1.5
  EVAL_FREQ: 3
  LONG_CYCLE: False
  LONG_CYCLE_FACTORS: [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)]
  LONG_CYCLE_SAMPLING_RATE: 0
  SHORT_CYCLE: False
  SHORT_CYCLE_FACTORS: [0.5, 0.7071067811865476]
MVIT:
  CLS_EMBED_ON: True
  DEPTH: 16
  DIM_MUL: [[1, 2.0], [3, 2.0], [14, 2.0]]
  DIM_MUL_IN_ATT: False
  DROPOUT_RATE: 0.0
  DROPPATH_RATE: 0.2
  EMBED_DIM: 96
  HEAD_INIT_SCALE: 1.0
  HEAD_MUL: [[1, 2.0], [3, 2.0], [14, 2.0]]
  LAYER_SCALE_INIT_VALUE: 0.0
  MLP_RATIO: 4.0
  MODE: conv
  NORM: layernorm
  NORM_STEM: False
  NUM_HEADS: 1
  PATCH_2D: False
  PATCH_KERNEL: [3, 7, 7]
  PATCH_PADDING: [1, 3, 3]
  PATCH_STRIDE: [2, 4, 4]
  POOL_FIRST: False
  POOL_KVQ_KERNEL: [3, 3, 3]
  POOL_KV_STRIDE: []
  POOL_KV_STRIDE_ADAPTIVE: [1, 8, 8]
  POOL_Q_STRIDE: [[1, 1, 2, 2], [3, 1, 2, 2], [14, 1, 2, 2]]
  QKV_BIAS: True
  REL_POS_SPATIAL: False
  REL_POS_TEMPORAL: False
  REL_POS_ZERO_INIT: False
  RESIDUAL_POOLING: False
  REV:
    BUFFER_LAYERS: []
    ENABLE: False
    PRE_Q_FUSION: avg
    RESPATH_FUSE: concat
    RES_PATH: conv
  SEPARATE_QKV: False
  SEP_POS_EMBED: True
  USE_ABS_POS: True
  USE_FIXED_SINCOS_POS: False
  USE_MEAN_POOLING: False
  ZERO_DECAY_POS_CLS: False
NONLOCAL:
  GROUP: [[1], [1], [1], [1]]
  INSTANTIATION: dot_product
  LOCATION: [[[]], [[]], [[]], [[]]]
  POOL: [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]
NUM_GPUS: 4
NUM_SHARDS: 1
OUTPUT_DIR: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4
RESNET:
  DEPTH: 50
  INPLACE_RELU: True
  NUM_BLOCK_TEMP_KERNEL: [[3], [4], [6], [3]]
  NUM_GROUPS: 1
  SPATIAL_DILATIONS: [[1], [1], [1], [1]]
  SPATIAL_STRIDES: [[1], [2], [2], [2]]
  STRIDE_1X1: False
  TRANS_FUNC: bottleneck_transform
  WIDTH_PER_GROUP: 64
  ZERO_INIT_FINAL_BN: False
  ZERO_INIT_FINAL_CONV: False
RNG_SEED: 0
SHARD_ID: 0
SLOWFAST:
  ALPHA: 8
  BETA_INV: 8
  FUSION_CONV_CHANNEL_RATIO: 2
  FUSION_KERNEL_SZ: 5
SOLVER:
  BASE_LR: 0.0001
  BASE_LR_SCALE_NUM_SHARDS: False
  BETAS: (0.9, 0.999)
  CLIP_GRAD_L2NORM: 1.0
  CLIP_GRAD_VAL: None
  COSINE_AFTER_WARMUP: False
  COSINE_END_LR: 0.0
  DAMPENING: 0.0
  GAMMA: 0.1
  LARS_ON: False
  LAYER_DECAY: 1.0
  LRS: [1, 0.1, 0.01, 0.001, 0.0001]
  LR_POLICY: steps_with_relative_lrs
  MAX_EPOCH: 60
  MOMENTUM: 0.9
  NESTEROV: True
  OPTIMIZING_METHOD: adamw
  STEPS: [0, 20, 30, 40, 50]
  STEP_SIZE: 1
  WARMUP_EPOCHS: 5.0
  WARMUP_FACTOR: 0.1
  WARMUP_START_LR: 1e-06
  WEIGHT_DECAY: 0.05
  ZERO_WD_1D_PARAM: False
TASK: 
TENSORBOARD:
  CATEGORIES_PATH: 
  CLASS_NAMES_PATH: 
  CONFUSION_MATRIX:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
  ENABLE: False
  HISTOGRAM:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
    TOPK: 10
  LOG_DIR: 
  MODEL_VIS:
    ACTIVATIONS: False
    COLORMAP: Pastel2
    ENABLE: False
    GRAD_CAM:
      COLORMAP: viridis
      ENABLE: True
      LAYER_LIST: []
      USE_TRUE_LABEL: False
    INPUT_VIDEO: False
    LAYER_LIST: []
    MODEL_WEIGHTS: False
    TOPK_PREDS: 1
  PREDICTIONS_PATH: 
  WRONG_PRED_VIS:
    ENABLE: False
    SUBSET_PATH: 
    TAG: Incorrectly classified videos.
TEST:
  BATCH_SIZE: 4
  CHECKPOINT_FILE_PATH: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/checkpoints/checkpoint_epoch_00050.pyth
  CHECKPOINT_TYPE: pytorch
  DATASET: ava
  ENABLE: True
  NUM_ENSEMBLE_VIEWS: 10
  NUM_SPATIAL_CROPS: 1
  NUM_TEMPORAL_CLIPS: [10]
  SAVE_RESULTS_PATH: 
TRAIN:
  AUTO_RESUME: True
  BATCH_SIZE: 48
  CHECKPOINT_CLEAR_NAME_PATTERN: ()
  CHECKPOINT_EPOCH_RESET: True
  CHECKPOINT_FILE_PATH: /home/lqi/lqi_temp/trainingspace/pretrained_models/MVIT_B_16x4.pyth
  CHECKPOINT_INFLATE: False
  CHECKPOINT_IN_INIT: False
  CHECKPOINT_PERIOD: 5
  CHECKPOINT_TYPE: pytorch
  DATASET: ava
  ENABLE: False
  EVAL_PERIOD: 5
  KILL_LOSS_EXPLOSION_FACTOR: 0.0
  MIXED_PRECISION: True
VIS_MASK:
  ENABLE: False
X3D:
  BN_LIN5: False
  BOTTLENECK_FACTOR: 1.0
  CHANNELWISE_3x3x3: True
  DEPTH_FACTOR: 1.0
  DIM_C1: 12
  DIM_C5: 2048
  SCALE_RES2: False
  WIDTH_FACTOR: 1.0
[05/08 01:42:10][INFO] misc.py:  186: Model:
DistributedDataParallel(
  (module): MViT(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
    )
    (blocks): ModuleList(
      (0): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=384, out_features=192, bias=True)
        )
        (proj): Linear(in_features=96, out_features=192, bias=True)
      )
      (1): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (2): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=384, bias=True)
        )
        (proj): Linear(in_features=192, out_features=384, bias=True)
      )
      (3): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (4-12): 9 x MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (13): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=768, bias=True)
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
      )
      (14): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (15): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (head): ResNetRoIHead(
      (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
      (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=768, out_features=50, bias=True)
      (act): Sigmoid()
    )
  )
)
[05/08 01:42:10][INFO] misc.py:  188: Params: 36,341,522
[05/08 01:42:10][INFO] misc.py:  189: Mem: 0.2725391387939453 MB
[05/08 01:42:11][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat encountered 1 time(s)
[05/08 01:42:11][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[05/08 01:42:11][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 33 time(s)
[05/08 01:42:11][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 1 time(s)
[05/08 01:42:11][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 130 time(s)
[05/08 01:42:11][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/08 01:42:11][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/08 01:42:11][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/08 01:42:11][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/08 01:42:11][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/08 01:42:11][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/08 01:42:11][WARNING] jit_analysis.py:  499: Unsupported operator aten::sigmoid encountered 1 time(s)
[05/08 01:42:11][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/08 01:42:11][INFO] misc.py:  191: Flops: 70.803616128 G
[05/08 01:42:11][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat encountered 1 time(s)
[05/08 01:42:11][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[05/08 01:42:11][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 33 time(s)
[05/08 01:42:11][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 1 time(s)
[05/08 01:42:11][WARNING] jit_analysis.py:  499: Unsupported operator aten::layer_norm encountered 68 time(s)
[05/08 01:42:11][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 130 time(s)
[05/08 01:42:11][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/08 01:42:11][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/08 01:42:11][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/08 01:42:11][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/08 01:42:11][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/08 01:42:11][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/08 01:42:11][WARNING] jit_analysis.py:  499: Unsupported operator aten::sigmoid encountered 1 time(s)
[05/08 01:42:11][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/08 01:42:11][INFO] misc.py:  192: Activations: 239.822315 M
[05/08 01:42:11][INFO] misc.py:  197: nvidia-smi
[05/08 01:42:11][INFO] misc.py:  186: Model:
DistributedDataParallel(
  (module): MViT(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
    )
    (blocks): ModuleList(
      (0): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=384, out_features=192, bias=True)
        )
        (proj): Linear(in_features=96, out_features=192, bias=True)
      )
      (1): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (2): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=384, bias=True)
        )
        (proj): Linear(in_features=192, out_features=384, bias=True)
      )
      (3): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (4-12): 9 x MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (13): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=768, bias=True)
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
      )
      (14): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (15): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (head): ResNetRoIHead(
      (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
      (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=768, out_features=50, bias=True)
      (act): Sigmoid()
    )
  )
)
[05/08 01:42:11][INFO] misc.py:  188: Params: 36,341,522
[05/08 01:42:11][INFO] misc.py:  189: Mem: 1.555396556854248 MB
[05/08 01:42:12][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat encountered 1 time(s)
[05/08 01:42:12][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[05/08 01:42:12][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 33 time(s)
[05/08 01:42:12][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 1 time(s)
[05/08 01:42:12][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 130 time(s)
[05/08 01:42:12][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/08 01:42:12][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/08 01:42:12][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/08 01:42:12][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/08 01:42:12][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/08 01:42:12][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/08 01:42:12][WARNING] jit_analysis.py:  499: Unsupported operator aten::sigmoid encountered 1 time(s)
[05/08 01:42:12][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/08 01:42:12][INFO] misc.py:  191: Flops: 70.803616128 G
[05/08 01:42:13][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat encountered 1 time(s)
[05/08 01:42:13][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[05/08 01:42:13][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 33 time(s)
[05/08 01:42:13][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 1 time(s)
[05/08 01:42:13][WARNING] jit_analysis.py:  499: Unsupported operator aten::layer_norm encountered 68 time(s)
[05/08 01:42:13][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 130 time(s)
[05/08 01:42:13][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/08 01:42:13][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/08 01:42:13][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/08 01:42:13][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/08 01:42:13][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/08 01:42:13][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/08 01:42:13][WARNING] jit_analysis.py:  499: Unsupported operator aten::sigmoid encountered 1 time(s)
[05/08 01:42:13][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/08 01:42:13][INFO] misc.py:  192: Activations: 239.822315 M
[05/08 01:42:13][INFO] misc.py:  197: nvidia-smi
[05/08 01:42:13][INFO] checkpoint.py:  213: Loading network weights from /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/checkpoints/checkpoint_epoch_00050.pyth.
[05/08 01:42:21][INFO] ava_helper.py:   58: Finished loading image paths from: ../ava/frame_lists/test.csv
[05/08 01:42:21][INFO] ava_helper.py:  139: Finished loading annotations from: ../ava/annotations/ava_test_predicted_boxes.csv
[05/08 01:42:21][INFO] ava_helper.py:  140: Detection threshold: 0.0
[05/08 01:42:21][INFO] ava_helper.py:  141: Number of unique boxes: 1136
[05/08 01:42:21][INFO] ava_helper.py:  142: Number of annotations: 0
[05/08 01:42:21][INFO] ava_helper.py:  185: 1091 keyframes used.
[05/08 01:42:21][INFO] ava_dataset.py:  130: === AVA dataset summary ===
[05/08 01:42:21][INFO] ava_dataset.py:  131: Split: test
[05/08 01:42:21][INFO] ava_dataset.py:  132: Number of videos: 953
[05/08 01:42:21][INFO] ava_dataset.py:  136: Number of frames: 85775
[05/08 01:42:21][INFO] ava_dataset.py:  137: Number of key frames: 1091
[05/08 01:42:21][INFO] ava_dataset.py:  138: Number of boxes: 1136.
[05/08 01:42:21][INFO] test_net.py:  215: Testing model for 273 iterations
[05/08 01:42:21][INFO] ava_helper.py:   58: Finished loading image paths from: ../ava/frame_lists/test.csv
[05/08 01:42:55][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "10", "eta": "0:00:24", "dt": 0.09303, "dt_data": 0.00430, "dt_net": 0.08872, "mode": "test"}
[05/08 01:42:56][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "20", "eta": "0:00:23", "dt": 0.09222, "dt_data": 0.00361, "dt_net": 0.08861, "mode": "test"}
[05/08 01:42:57][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "30", "eta": "0:00:22", "dt": 0.09146, "dt_data": 0.00341, "dt_net": 0.08804, "mode": "test"}
[05/08 01:42:57][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "40", "eta": "0:00:21", "dt": 0.09234, "dt_data": 0.00479, "dt_net": 0.08755, "mode": "test"}
[05/08 01:42:58][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "50", "eta": "0:00:21", "dt": 0.09665, "dt_data": 0.00326, "dt_net": 0.09339, "mode": "test"}
[05/08 01:42:59][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "60", "eta": "0:00:14", "dt": 0.06964, "dt_data": 0.00402, "dt_net": 0.06561, "mode": "test"}
[05/08 01:43:00][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "70", "eta": "0:00:18", "dt": 0.09208, "dt_data": 0.00343, "dt_net": 0.08865, "mode": "test"}
[05/08 01:43:01][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "80", "eta": "0:00:17", "dt": 0.09022, "dt_data": 0.00384, "dt_net": 0.08638, "mode": "test"}
[05/08 01:43:02][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "90", "eta": "0:00:16", "dt": 0.09182, "dt_data": 0.00402, "dt_net": 0.08780, "mode": "test"}
[05/08 01:43:03][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "100", "eta": "0:00:16", "dt": 0.09335, "dt_data": 0.00464, "dt_net": 0.08871, "mode": "test"}
[05/08 01:43:04][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "110", "eta": "0:00:15", "dt": 0.09350, "dt_data": 0.00431, "dt_net": 0.08918, "mode": "test"}
[05/08 01:43:05][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "120", "eta": "0:00:14", "dt": 0.09117, "dt_data": 0.00427, "dt_net": 0.08690, "mode": "test"}
[05/08 01:43:05][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "130", "eta": "0:00:13", "dt": 0.09403, "dt_data": 0.00319, "dt_net": 0.09083, "mode": "test"}
[05/08 01:43:06][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "140", "eta": "0:00:11", "dt": 0.08932, "dt_data": 0.00300, "dt_net": 0.08632, "mode": "test"}
[05/08 01:43:07][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "150", "eta": "0:00:07", "dt": 0.06340, "dt_data": 0.00377, "dt_net": 0.05963, "mode": "test"}
[05/08 01:43:08][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "160", "eta": "0:00:10", "dt": 0.09129, "dt_data": 0.00396, "dt_net": 0.08733, "mode": "test"}
[05/08 01:43:09][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "170", "eta": "0:00:09", "dt": 0.09490, "dt_data": 0.00573, "dt_net": 0.08916, "mode": "test"}
[05/08 01:43:10][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "180", "eta": "0:00:08", "dt": 0.09182, "dt_data": 0.00416, "dt_net": 0.08766, "mode": "test"}
[05/08 01:43:11][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "190", "eta": "0:00:05", "dt": 0.06316, "dt_data": 0.00332, "dt_net": 0.05983, "mode": "test"}
[05/08 01:43:11][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "200", "eta": "0:00:06", "dt": 0.09260, "dt_data": 0.00340, "dt_net": 0.08920, "mode": "test"}
[05/08 01:43:12][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "210", "eta": "0:00:05", "dt": 0.08989, "dt_data": 0.00305, "dt_net": 0.08684, "mode": "test"}
[05/08 01:43:13][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "220", "eta": "0:00:05", "dt": 0.09263, "dt_data": 0.00441, "dt_net": 0.08821, "mode": "test"}
[05/08 01:43:14][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "230", "eta": "0:00:02", "dt": 0.06713, "dt_data": 0.00501, "dt_net": 0.06211, "mode": "test"}
[05/08 01:43:15][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "240", "eta": "0:00:03", "dt": 0.09303, "dt_data": 0.00411, "dt_net": 0.08892, "mode": "test"}
[05/08 01:43:16][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "250", "eta": "0:00:02", "dt": 0.09405, "dt_data": 0.00454, "dt_net": 0.08951, "mode": "test"}
[05/08 01:43:17][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "260", "eta": "0:00:01", "dt": 0.08890, "dt_data": 0.00289, "dt_net": 0.08601, "mode": "test"}
[05/08 01:43:17][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "270", "eta": "0:00:00", "dt": 0.06354, "dt_data": 0.00288, "dt_net": 0.06066, "mode": "test"}
[05/08 01:43:20][INFO] ava_eval_helper.py:  204: Evaluating with 1091 unique GT frames.
[05/08 01:43:20][INFO] ava_eval_helper.py:  208: Evaluating with 1091 unique detection frames
[05/08 01:43:26][INFO] object_detection_evaluation.py:  751: The following classes have no ground truth examples: [ 2  4  9 13 15 16 18 19 20 21 23 25 31 32 33 35 37 39 40 41 42 44 49 50
 51 52 53 54 55 58 63 67 68 71 72 73 75 76 77]
[05/08 01:43:26][INFO] ava_eval_helper.py:  298: mAP@0.5 = 0.12856 | macro-F1 = 0.06516 | macro-AUROC = 0.74626 | macro-recall = 0.06041
[05/08 01:43:26][INFO] logging.py:   98: json_stats: {"mode": "test", "map": 0.12856, "f1_macro": 0.06516, "auroc_macro": 0.74626, "recall_macro": 0.06041}
[05/08 01:43:26][INFO] ava_eval_helper.py:  469: AVA results wrote to /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/detections_test.csv
[05/08 01:43:26][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/08 01:43:26][INFO] meters.py:  327: Saved CSVs:
  per-class AP: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/ap_per_class_test.csv
  detections: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/detections_test.csv
[05/08 01:43:26][INFO] test_net.py:  256: Finalized testing with 10 temporal clips and 1 spatial crops
[05/08 01:43:26][INFO] test_net.py:  275: _p36.34_f70.80_10a12.86 Top5 Acc: 12.86 MEM: 1.72 f: 70.8036
[05/08 01:43:26][INFO] test_net.py:  276: _p36.34_f70.80_10a12.86
[05/08 01:44:11][INFO] test_net.py:  188: Test with config:
[05/08 01:44:11][INFO] test_net.py:  189: AUG:
  AA_TYPE: rand-m7-n4-mstd0.5-inc1
  COLOR_JITTER: 0.4
  ENABLE: True
  GEN_MASK_LOADER: False
  INTERPOLATION: bicubic
  MASK_FRAMES: False
  MASK_RATIO: 0.0
  MASK_TUBE: False
  MASK_WINDOW_SIZE: [8, 7, 7]
  MAX_MASK_PATCHES_PER_BLOCK: None
  NUM_SAMPLE: 2
  RE_COUNT: 1
  RE_MODE: pixel
  RE_PROB: 0.25
  RE_SPLIT: False
AVA:
  ANNOTATION_DIR: ../ava/annotations
  BGR: False
  DETECTION_SCORE_THRESH: 0.0
  EXCLUSION_FILE: ava_val_excluded_timestamps_v2.2.csv
  FRAME_DIR: ../ava/frames
  FRAME_LIST_DIR: ../ava/frame_lists
  FULL_TEST_ON_VAL: True
  GROUNDTRUTH_FILE: ava_test_gt.csv
  IMG_PROC_BACKEND: cv2
  LABEL_MAP_FILE: label_map.pbtxt
  TEST_FORCE_FLIP: False
  TEST_LISTS: ['test.csv']
  TEST_PREDICT_BOX_LISTS: ['ava_test_predicted_boxes.csv']
  TRAIN_GT_BOX_LISTS: ['ava_train.csv']
  TRAIN_LISTS: ['train.csv']
  TRAIN_PCA_JITTER_ONLY: True
  TRAIN_PREDICT_BOX_LISTS: []
  TRAIN_USE_COLOR_AUGMENTATION: False
BENCHMARK:
  LOG_PERIOD: 100
  NUM_EPOCHS: 5
  SHUFFLE: True
BN:
  GLOBAL_SYNC: False
  NORM_TYPE: batchnorm
  NUM_BATCHES_PRECISE: 200
  NUM_SPLITS: 1
  NUM_SYNC_DEVICES: 1
  USE_PRECISE_STATS: False
  WEIGHT_DECAY: 0.0
CONTRASTIVE:
  BN_MLP: False
  BN_SYNC_MLP: False
  DELTA_CLIPS_MAX: inf
  DELTA_CLIPS_MIN: -inf
  DIM: 128
  INTERP_MEMORY: False
  KNN_ON: True
  LENGTH: 239975
  LOCAL_SHUFFLE_BN: True
  MEM_TYPE: 1d
  MLP_DIM: 2048
  MOCO_MULTI_VIEW_QUEUE: False
  MOMENTUM: 0.5
  MOMENTUM_ANNEALING: False
  NUM_CLASSES_DOWNSTREAM: 400
  NUM_MLP_LAYERS: 1
  PREDICTOR_DEPTHS: []
  QUEUE_LEN: 65536
  SEQUENTIAL: False
  SIMCLR_DIST_ON: True
  SWAV_QEUE_LEN: 0
  T: 0.07
  TYPE: mem
DATA:
  COLOR_RND_GRAYSCALE: 0.0
  DECODING_BACKEND: torchvision
  DECODING_SHORT_SIZE: 256
  DUMMY_LOAD: False
  ENSEMBLE_METHOD: sum
  IN22K_TRAINVAL: False
  IN22k_VAL_IN1K: 
  INPUT_CHANNEL_NUM: [3]
  INV_UNIFORM_SAMPLE: False
  IN_VAL_CROP_RATIO: 0.875
  LOADER_CHUNK_OVERALL_SIZE: 0
  LOADER_CHUNK_SIZE: 0
  MEAN: [0.45, 0.45, 0.45]
  MULTI_LABEL: False
  NUM_FRAMES: 16
  PATH_LABEL_SEPARATOR:  
  PATH_PREFIX: 
  PATH_TO_DATA_DIR: ../ava
  PATH_TO_PRELOAD_IMDB: 
  RANDOM_FLIP: True
  REVERSE_INPUT_CHANNEL: False
  SAMPLING_RATE: 4
  SKIP_ROWS: 0
  SSL_BLUR_SIGMA_MAX: [0.0, 2.0]
  SSL_BLUR_SIGMA_MIN: [0.0, 0.1]
  SSL_COLOR_BRI_CON_SAT: [0.4, 0.4, 0.4]
  SSL_COLOR_HUE: 0.1
  SSL_COLOR_JITTER: False
  SSL_MOCOV2_AUG: False
  STD: [0.225, 0.225, 0.225]
  TARGET_FPS: 30
  TEST_CROP_SIZE: 224
  TIME_DIFF_PROB: 0.0
  TRAIN_CROP_NUM_SPATIAL: 1
  TRAIN_CROP_NUM_TEMPORAL: 1
  TRAIN_CROP_SIZE: 224
  TRAIN_JITTER_ASPECT_RELATIVE: [0.75, 1.3333]
  TRAIN_JITTER_FPS: 0.0
  TRAIN_JITTER_MOTION_SHIFT: False
  TRAIN_JITTER_SCALES: [256, 320]
  TRAIN_JITTER_SCALES_RELATIVE: [0.08, 1.0]
  TRAIN_PCA_EIGVAL: [0.225, 0.224, 0.229]
  TRAIN_PCA_EIGVEC: [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]]
  USE_OFFSET_SAMPLING: True
DATA_LOADER:
  ENABLE_MULTI_THREAD_DECODE: False
  NUM_WORKERS: 8
  PIN_MEMORY: True
DEMO:
  BUFFER_SIZE: 0
  CLIP_VIS_SIZE: 10
  COMMON_CLASS_NAMES: ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)']
  COMMON_CLASS_THRES: 0.7
  DETECTRON2_CFG: COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml
  DETECTRON2_THRESH: 0.9
  DETECTRON2_WEIGHTS: detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
  DISPLAY_HEIGHT: 0
  DISPLAY_WIDTH: 0
  ENABLE: False
  FPS: 30
  GT_BOXES: 
  INPUT_FORMAT: BGR
  INPUT_VIDEO: 
  LABEL_FILE_PATH: 
  NUM_CLIPS_SKIP: 0
  NUM_VIS_INSTANCES: 2
  OUTPUT_FILE: 
  OUTPUT_FPS: -1
  PREDS_BOXES: 
  SLOWMO: 1
  STARTING_SECOND: 900
  THREAD_ENABLE: False
  UNCOMMON_CLASS_THRES: 0.3
  VIS_MODE: thres
  WEBCAM: -1
DETECTION:
  ALIGNED: True
  ENABLE: True
  ROI_XFORM_RESOLUTION: 7
  SPATIAL_SCALE_FACTOR: 16
DIST_BACKEND: nccl
LOG_MODEL_INFO: True
LOG_PERIOD: 10
MASK:
  DECODER_DEPTH: 0
  DECODER_EMBED_DIM: 512
  DECODER_SEP_POS_EMBED: False
  DEC_KV_KERNEL: []
  DEC_KV_STRIDE: []
  ENABLE: False
  HEAD_TYPE: separate
  MAE_ON: False
  MAE_RND_MASK: False
  NORM_PRED_PIXEL: True
  PER_FRAME_MASKING: False
  PRED_HOG: False
  PRETRAIN_DEPTH: [15]
  SCALE_INIT_BY_DEPTH: False
  TIME_STRIDE_LOSS: True
MIXUP:
  ALPHA: 0.8
  CUTMIX_ALPHA: 1.0
  ENABLE: False
  LABEL_SMOOTH_VALUE: 0.1
  PROB: 1.0
  SWITCH_PROB: 0.5
MODEL:
  ACT_CHECKPOINT: False
  ARCH: mvit
  BLIP2:
    FREEZE: True
    PRETRAINED: Salesforce/blip2-flan-t5-xl
  DETACH_FINAL_FC: False
  DROPCONNECT_RATE: 0.0
  DROPOUT_RATE: 0.5
  FC_INIT_STD: 0.01
  FP16_ALLREDUCE: False
  FROZEN_BN: False
  HEAD_ACT: sigmoid
  LOSS_FUNC: bce
  MODEL_NAME: MViT
  MULTI_PATHWAY_ARCH: ['slowfast']
  NUM_CLASSES: 50
  SINGLE_PATHWAY_ARCH: ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'maskmvit', 'blip2']
MULTIGRID:
  BN_BASE_SIZE: 8
  DEFAULT_B: 0
  DEFAULT_S: 0
  DEFAULT_T: 0
  EPOCH_FACTOR: 1.5
  EVAL_FREQ: 3
  LONG_CYCLE: False
  LONG_CYCLE_FACTORS: [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)]
  LONG_CYCLE_SAMPLING_RATE: 0
  SHORT_CYCLE: False
  SHORT_CYCLE_FACTORS: [0.5, 0.7071067811865476]
MVIT:
  CLS_EMBED_ON: True
  DEPTH: 16
  DIM_MUL: [[1, 2.0], [3, 2.0], [14, 2.0]]
  DIM_MUL_IN_ATT: False
  DROPOUT_RATE: 0.0
  DROPPATH_RATE: 0.2
  EMBED_DIM: 96
  HEAD_INIT_SCALE: 1.0
  HEAD_MUL: [[1, 2.0], [3, 2.0], [14, 2.0]]
  LAYER_SCALE_INIT_VALUE: 0.0
  MLP_RATIO: 4.0
  MODE: conv
  NORM: layernorm
  NORM_STEM: False
  NUM_HEADS: 1
  PATCH_2D: False
  PATCH_KERNEL: [3, 7, 7]
  PATCH_PADDING: [1, 3, 3]
  PATCH_STRIDE: [2, 4, 4]
  POOL_FIRST: False
  POOL_KVQ_KERNEL: [3, 3, 3]
  POOL_KV_STRIDE: []
  POOL_KV_STRIDE_ADAPTIVE: [1, 8, 8]
  POOL_Q_STRIDE: [[1, 1, 2, 2], [3, 1, 2, 2], [14, 1, 2, 2]]
  QKV_BIAS: True
  REL_POS_SPATIAL: False
  REL_POS_TEMPORAL: False
  REL_POS_ZERO_INIT: False
  RESIDUAL_POOLING: False
  REV:
    BUFFER_LAYERS: []
    ENABLE: False
    PRE_Q_FUSION: avg
    RESPATH_FUSE: concat
    RES_PATH: conv
  SEPARATE_QKV: False
  SEP_POS_EMBED: True
  USE_ABS_POS: True
  USE_FIXED_SINCOS_POS: False
  USE_MEAN_POOLING: False
  ZERO_DECAY_POS_CLS: False
NONLOCAL:
  GROUP: [[1], [1], [1], [1]]
  INSTANTIATION: dot_product
  LOCATION: [[[]], [[]], [[]], [[]]]
  POOL: [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]
NUM_GPUS: 4
NUM_SHARDS: 1
OUTPUT_DIR: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4
RESNET:
  DEPTH: 50
  INPLACE_RELU: True
  NUM_BLOCK_TEMP_KERNEL: [[3], [4], [6], [3]]
  NUM_GROUPS: 1
  SPATIAL_DILATIONS: [[1], [1], [1], [1]]
  SPATIAL_STRIDES: [[1], [2], [2], [2]]
  STRIDE_1X1: False
  TRANS_FUNC: bottleneck_transform
  WIDTH_PER_GROUP: 64
  ZERO_INIT_FINAL_BN: False
  ZERO_INIT_FINAL_CONV: False
RNG_SEED: 0
SHARD_ID: 0
SLOWFAST:
  ALPHA: 8
  BETA_INV: 8
  FUSION_CONV_CHANNEL_RATIO: 2
  FUSION_KERNEL_SZ: 5
SOLVER:
  BASE_LR: 0.0001
  BASE_LR_SCALE_NUM_SHARDS: False
  BETAS: (0.9, 0.999)
  CLIP_GRAD_L2NORM: 1.0
  CLIP_GRAD_VAL: None
  COSINE_AFTER_WARMUP: False
  COSINE_END_LR: 0.0
  DAMPENING: 0.0
  GAMMA: 0.1
  LARS_ON: False
  LAYER_DECAY: 1.0
  LRS: [1, 0.1, 0.01, 0.001, 0.0001]
  LR_POLICY: steps_with_relative_lrs
  MAX_EPOCH: 60
  MOMENTUM: 0.9
  NESTEROV: True
  OPTIMIZING_METHOD: adamw
  STEPS: [0, 20, 30, 40, 50]
  STEP_SIZE: 1
  WARMUP_EPOCHS: 5.0
  WARMUP_FACTOR: 0.1
  WARMUP_START_LR: 1e-06
  WEIGHT_DECAY: 0.05
  ZERO_WD_1D_PARAM: False
TASK: 
TENSORBOARD:
  CATEGORIES_PATH: 
  CLASS_NAMES_PATH: 
  CONFUSION_MATRIX:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
  ENABLE: False
  HISTOGRAM:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
    TOPK: 10
  LOG_DIR: 
  MODEL_VIS:
    ACTIVATIONS: False
    COLORMAP: Pastel2
    ENABLE: False
    GRAD_CAM:
      COLORMAP: viridis
      ENABLE: True
      LAYER_LIST: []
      USE_TRUE_LABEL: False
    INPUT_VIDEO: False
    LAYER_LIST: []
    MODEL_WEIGHTS: False
    TOPK_PREDS: 1
  PREDICTIONS_PATH: 
  WRONG_PRED_VIS:
    ENABLE: False
    SUBSET_PATH: 
    TAG: Incorrectly classified videos.
TEST:
  BATCH_SIZE: 4
  CHECKPOINT_FILE_PATH: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/checkpoints/checkpoint_epoch_00035.pyth
  CHECKPOINT_TYPE: pytorch
  DATASET: ava
  ENABLE: True
  NUM_ENSEMBLE_VIEWS: 10
  NUM_SPATIAL_CROPS: 1
  NUM_TEMPORAL_CLIPS: [10]
  SAVE_RESULTS_PATH: 
TRAIN:
  AUTO_RESUME: True
  BATCH_SIZE: 48
  CHECKPOINT_CLEAR_NAME_PATTERN: ()
  CHECKPOINT_EPOCH_RESET: True
  CHECKPOINT_FILE_PATH: /home/lqi/lqi_temp/trainingspace/pretrained_models/MVIT_B_16x4.pyth
  CHECKPOINT_INFLATE: False
  CHECKPOINT_IN_INIT: False
  CHECKPOINT_PERIOD: 5
  CHECKPOINT_TYPE: pytorch
  DATASET: ava
  ENABLE: False
  EVAL_PERIOD: 5
  KILL_LOSS_EXPLOSION_FACTOR: 0.0
  MIXED_PRECISION: True
VIS_MASK:
  ENABLE: False
X3D:
  BN_LIN5: False
  BOTTLENECK_FACTOR: 1.0
  CHANNELWISE_3x3x3: True
  DEPTH_FACTOR: 1.0
  DIM_C1: 12
  DIM_C5: 2048
  SCALE_RES2: False
  WIDTH_FACTOR: 1.0
[05/08 01:44:13][INFO] misc.py:  186: Model:
DistributedDataParallel(
  (module): MViT(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
    )
    (blocks): ModuleList(
      (0): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=384, out_features=192, bias=True)
        )
        (proj): Linear(in_features=96, out_features=192, bias=True)
      )
      (1): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (2): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=384, bias=True)
        )
        (proj): Linear(in_features=192, out_features=384, bias=True)
      )
      (3): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (4-12): 9 x MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (13): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=768, bias=True)
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
      )
      (14): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (15): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (head): ResNetRoIHead(
      (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
      (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=768, out_features=50, bias=True)
      (act): Sigmoid()
    )
  )
)
[05/08 01:44:13][INFO] misc.py:  188: Params: 36,341,522
[05/08 01:44:13][INFO] misc.py:  189: Mem: 0.2725391387939453 MB
[05/08 01:44:14][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat encountered 1 time(s)
[05/08 01:44:14][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[05/08 01:44:14][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 33 time(s)
[05/08 01:44:14][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 1 time(s)
[05/08 01:44:14][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 130 time(s)
[05/08 01:44:14][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/08 01:44:14][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/08 01:44:14][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/08 01:44:14][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/08 01:44:14][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/08 01:44:14][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/08 01:44:14][WARNING] jit_analysis.py:  499: Unsupported operator aten::sigmoid encountered 1 time(s)
[05/08 01:44:14][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/08 01:44:14][INFO] misc.py:  191: Flops: 70.803616128 G
[05/08 01:44:14][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat encountered 1 time(s)
[05/08 01:44:14][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[05/08 01:44:14][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 33 time(s)
[05/08 01:44:14][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 1 time(s)
[05/08 01:44:14][WARNING] jit_analysis.py:  499: Unsupported operator aten::layer_norm encountered 68 time(s)
[05/08 01:44:14][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 130 time(s)
[05/08 01:44:14][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/08 01:44:14][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/08 01:44:14][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/08 01:44:14][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/08 01:44:14][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/08 01:44:14][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/08 01:44:14][WARNING] jit_analysis.py:  499: Unsupported operator aten::sigmoid encountered 1 time(s)
[05/08 01:44:14][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/08 01:44:14][INFO] misc.py:  192: Activations: 239.822315 M
[05/08 01:44:14][INFO] misc.py:  197: nvidia-smi
[05/08 01:44:15][INFO] misc.py:  186: Model:
DistributedDataParallel(
  (module): MViT(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
    )
    (blocks): ModuleList(
      (0): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=384, out_features=192, bias=True)
        )
        (proj): Linear(in_features=96, out_features=192, bias=True)
      )
      (1): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (2): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=384, bias=True)
        )
        (proj): Linear(in_features=192, out_features=384, bias=True)
      )
      (3): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (4-12): 9 x MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (13): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=768, bias=True)
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
      )
      (14): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (15): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (head): ResNetRoIHead(
      (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
      (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=768, out_features=50, bias=True)
      (act): Sigmoid()
    )
  )
)
[05/08 01:44:15][INFO] misc.py:  188: Params: 36,341,522
[05/08 01:44:15][INFO] misc.py:  189: Mem: 1.554469108581543 MB
[05/08 01:44:15][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat encountered 1 time(s)
[05/08 01:44:15][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[05/08 01:44:15][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 33 time(s)
[05/08 01:44:15][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 1 time(s)
[05/08 01:44:15][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 130 time(s)
[05/08 01:44:15][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/08 01:44:15][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/08 01:44:15][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/08 01:44:15][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/08 01:44:15][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/08 01:44:15][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/08 01:44:15][WARNING] jit_analysis.py:  499: Unsupported operator aten::sigmoid encountered 1 time(s)
[05/08 01:44:15][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/08 01:44:15][INFO] misc.py:  191: Flops: 70.803616128 G
[05/08 01:44:16][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat encountered 1 time(s)
[05/08 01:44:16][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[05/08 01:44:16][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 33 time(s)
[05/08 01:44:16][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 1 time(s)
[05/08 01:44:16][WARNING] jit_analysis.py:  499: Unsupported operator aten::layer_norm encountered 68 time(s)
[05/08 01:44:16][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 130 time(s)
[05/08 01:44:16][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/08 01:44:16][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/08 01:44:16][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/08 01:44:16][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/08 01:44:16][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/08 01:44:16][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/08 01:44:16][WARNING] jit_analysis.py:  499: Unsupported operator aten::sigmoid encountered 1 time(s)
[05/08 01:44:16][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/08 01:44:16][INFO] misc.py:  192: Activations: 239.822315 M
[05/08 01:44:16][INFO] misc.py:  197: nvidia-smi
[05/08 01:44:16][INFO] checkpoint.py:  213: Loading network weights from /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/checkpoints/checkpoint_epoch_00035.pyth.
[05/08 01:44:23][INFO] ava_helper.py:   58: Finished loading image paths from: ../ava/frame_lists/test.csv
[05/08 01:44:23][INFO] ava_helper.py:  139: Finished loading annotations from: ../ava/annotations/ava_test_predicted_boxes.csv
[05/08 01:44:23][INFO] ava_helper.py:  140: Detection threshold: 0.0
[05/08 01:44:23][INFO] ava_helper.py:  141: Number of unique boxes: 1136
[05/08 01:44:23][INFO] ava_helper.py:  142: Number of annotations: 0
[05/08 01:44:23][INFO] ava_helper.py:  185: 1091 keyframes used.
[05/08 01:44:23][INFO] ava_dataset.py:  130: === AVA dataset summary ===
[05/08 01:44:23][INFO] ava_dataset.py:  131: Split: test
[05/08 01:44:23][INFO] ava_dataset.py:  132: Number of videos: 953
[05/08 01:44:23][INFO] ava_dataset.py:  136: Number of frames: 85775
[05/08 01:44:23][INFO] ava_dataset.py:  137: Number of key frames: 1091
[05/08 01:44:23][INFO] ava_dataset.py:  138: Number of boxes: 1136.
[05/08 01:44:23][INFO] test_net.py:  215: Testing model for 273 iterations
[05/08 01:44:23][INFO] ava_helper.py:   58: Finished loading image paths from: ../ava/frame_lists/test.csv
[05/08 01:44:57][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "10", "eta": "0:00:24", "dt": 0.09322, "dt_data": 0.00468, "dt_net": 0.08854, "mode": "test"}
[05/08 01:44:58][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "20", "eta": "0:00:23", "dt": 0.09218, "dt_data": 0.00335, "dt_net": 0.08883, "mode": "test"}
[05/08 01:44:59][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "30", "eta": "0:00:22", "dt": 0.09153, "dt_data": 0.00382, "dt_net": 0.08771, "mode": "test"}
[05/08 01:44:59][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "40", "eta": "0:00:21", "dt": 0.09074, "dt_data": 0.00406, "dt_net": 0.08667, "mode": "test"}
[05/08 01:45:00][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "50", "eta": "0:00:20", "dt": 0.09112, "dt_data": 0.00323, "dt_net": 0.08789, "mode": "test"}
[05/08 01:45:01][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "60", "eta": "0:00:13", "dt": 0.06399, "dt_data": 0.00358, "dt_net": 0.06041, "mode": "test"}
[05/08 01:45:02][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "70", "eta": "0:00:18", "dt": 0.09111, "dt_data": 0.00399, "dt_net": 0.08712, "mode": "test"}
[05/08 01:45:03][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "80", "eta": "0:00:17", "dt": 0.08969, "dt_data": 0.00328, "dt_net": 0.08641, "mode": "test"}
[05/08 01:45:04][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "90", "eta": "0:00:17", "dt": 0.09316, "dt_data": 0.00452, "dt_net": 0.08863, "mode": "test"}
[05/08 01:45:05][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "100", "eta": "0:00:16", "dt": 0.09225, "dt_data": 0.00487, "dt_net": 0.08738, "mode": "test"}
[05/08 01:45:06][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "110", "eta": "0:00:15", "dt": 0.09339, "dt_data": 0.00403, "dt_net": 0.08936, "mode": "test"}
[05/08 01:45:07][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "120", "eta": "0:00:14", "dt": 0.09253, "dt_data": 0.00408, "dt_net": 0.08844, "mode": "test"}
[05/08 01:45:07][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "130", "eta": "0:00:13", "dt": 0.09622, "dt_data": 0.00394, "dt_net": 0.09227, "mode": "test"}
[05/08 01:45:08][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "140", "eta": "0:00:12", "dt": 0.09006, "dt_data": 0.00321, "dt_net": 0.08685, "mode": "test"}
[05/08 01:45:09][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "150", "eta": "0:00:08", "dt": 0.06502, "dt_data": 0.00323, "dt_net": 0.06179, "mode": "test"}
[05/08 01:45:10][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "160", "eta": "0:00:10", "dt": 0.09243, "dt_data": 0.00426, "dt_net": 0.08816, "mode": "test"}
[05/08 01:45:11][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "170", "eta": "0:00:09", "dt": 0.09317, "dt_data": 0.00481, "dt_net": 0.08836, "mode": "test"}
[05/08 01:45:12][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "180", "eta": "0:00:08", "dt": 0.09372, "dt_data": 0.00477, "dt_net": 0.08896, "mode": "test"}
[05/08 01:45:13][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "190", "eta": "0:00:05", "dt": 0.06424, "dt_data": 0.00316, "dt_net": 0.06109, "mode": "test"}
[05/08 01:45:13][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "200", "eta": "0:00:06", "dt": 0.09250, "dt_data": 0.00370, "dt_net": 0.08880, "mode": "test"}
[05/08 01:45:14][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "210", "eta": "0:00:05", "dt": 0.09251, "dt_data": 0.00417, "dt_net": 0.08834, "mode": "test"}
[05/08 01:45:15][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "220", "eta": "0:00:05", "dt": 0.09283, "dt_data": 0.00429, "dt_net": 0.08854, "mode": "test"}
[05/08 01:45:16][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "230", "eta": "0:00:02", "dt": 0.06435, "dt_data": 0.00330, "dt_net": 0.06104, "mode": "test"}
[05/08 01:45:17][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "240", "eta": "0:00:03", "dt": 0.09202, "dt_data": 0.00412, "dt_net": 0.08790, "mode": "test"}
[05/08 01:45:18][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "250", "eta": "0:00:02", "dt": 0.09235, "dt_data": 0.00442, "dt_net": 0.08793, "mode": "test"}
[05/08 01:45:19][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "260", "eta": "0:00:01", "dt": 0.09021, "dt_data": 0.00280, "dt_net": 0.08742, "mode": "test"}
[05/08 01:45:19][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "270", "eta": "0:00:00", "dt": 0.06378, "dt_data": 0.00279, "dt_net": 0.06098, "mode": "test"}
[05/08 01:45:22][INFO] ava_eval_helper.py:  204: Evaluating with 1091 unique GT frames.
[05/08 01:45:22][INFO] ava_eval_helper.py:  208: Evaluating with 1091 unique detection frames
[05/08 01:45:28][INFO] object_detection_evaluation.py:  751: The following classes have no ground truth examples: [ 2  4  9 13 15 16 18 19 20 21 23 25 31 32 33 35 37 39 40 41 42 44 49 50
 51 52 53 54 55 58 63 67 68 71 72 73 75 76 77]
[05/08 01:45:28][INFO] ava_eval_helper.py:  298: mAP@0.5 = 0.12393 | macro-F1 = 0.06448 | macro-AUROC = 0.74449 | macro-recall = 0.05991
[05/08 01:45:28][INFO] logging.py:   98: json_stats: {"mode": "test", "map": 0.12393, "f1_macro": 0.06448, "auroc_macro": 0.74449, "recall_macro": 0.05991}
[05/08 01:45:28][INFO] ava_eval_helper.py:  469: AVA results wrote to /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/detections_test.csv
[05/08 01:45:28][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/08 01:45:28][INFO] meters.py:  327: Saved CSVs:
  per-class AP: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/ap_per_class_test.csv
  detections: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/detections_test.csv
[05/08 01:45:28][INFO] test_net.py:  256: Finalized testing with 10 temporal clips and 1 spatial crops
[05/08 01:45:28][INFO] test_net.py:  275: _p36.34_f70.80_10a12.39 Top5 Acc: 12.39 MEM: 1.72 f: 70.8036
[05/08 01:45:28][INFO] test_net.py:  276: _p36.34_f70.80_10a12.39
[05/08 01:46:15][INFO] test_net.py:  188: Test with config:
[05/08 01:46:15][INFO] test_net.py:  189: AUG:
  AA_TYPE: rand-m7-n4-mstd0.5-inc1
  COLOR_JITTER: 0.4
  ENABLE: True
  GEN_MASK_LOADER: False
  INTERPOLATION: bicubic
  MASK_FRAMES: False
  MASK_RATIO: 0.0
  MASK_TUBE: False
  MASK_WINDOW_SIZE: [8, 7, 7]
  MAX_MASK_PATCHES_PER_BLOCK: None
  NUM_SAMPLE: 2
  RE_COUNT: 1
  RE_MODE: pixel
  RE_PROB: 0.25
  RE_SPLIT: False
AVA:
  ANNOTATION_DIR: ../ava/annotations
  BGR: False
  DETECTION_SCORE_THRESH: 0.0
  EXCLUSION_FILE: ava_val_excluded_timestamps_v2.2.csv
  FRAME_DIR: ../ava/frames
  FRAME_LIST_DIR: ../ava/frame_lists
  FULL_TEST_ON_VAL: True
  GROUNDTRUTH_FILE: ava_test_gt.csv
  IMG_PROC_BACKEND: cv2
  LABEL_MAP_FILE: label_map.pbtxt
  TEST_FORCE_FLIP: False
  TEST_LISTS: ['test.csv']
  TEST_PREDICT_BOX_LISTS: ['ava_test_predicted_boxes.csv']
  TRAIN_GT_BOX_LISTS: ['ava_train.csv']
  TRAIN_LISTS: ['train.csv']
  TRAIN_PCA_JITTER_ONLY: True
  TRAIN_PREDICT_BOX_LISTS: []
  TRAIN_USE_COLOR_AUGMENTATION: False
BENCHMARK:
  LOG_PERIOD: 100
  NUM_EPOCHS: 5
  SHUFFLE: True
BN:
  GLOBAL_SYNC: False
  NORM_TYPE: batchnorm
  NUM_BATCHES_PRECISE: 200
  NUM_SPLITS: 1
  NUM_SYNC_DEVICES: 1
  USE_PRECISE_STATS: False
  WEIGHT_DECAY: 0.0
CONTRASTIVE:
  BN_MLP: False
  BN_SYNC_MLP: False
  DELTA_CLIPS_MAX: inf
  DELTA_CLIPS_MIN: -inf
  DIM: 128
  INTERP_MEMORY: False
  KNN_ON: True
  LENGTH: 239975
  LOCAL_SHUFFLE_BN: True
  MEM_TYPE: 1d
  MLP_DIM: 2048
  MOCO_MULTI_VIEW_QUEUE: False
  MOMENTUM: 0.5
  MOMENTUM_ANNEALING: False
  NUM_CLASSES_DOWNSTREAM: 400
  NUM_MLP_LAYERS: 1
  PREDICTOR_DEPTHS: []
  QUEUE_LEN: 65536
  SEQUENTIAL: False
  SIMCLR_DIST_ON: True
  SWAV_QEUE_LEN: 0
  T: 0.07
  TYPE: mem
DATA:
  COLOR_RND_GRAYSCALE: 0.0
  DECODING_BACKEND: torchvision
  DECODING_SHORT_SIZE: 256
  DUMMY_LOAD: False
  ENSEMBLE_METHOD: sum
  IN22K_TRAINVAL: False
  IN22k_VAL_IN1K: 
  INPUT_CHANNEL_NUM: [3]
  INV_UNIFORM_SAMPLE: False
  IN_VAL_CROP_RATIO: 0.875
  LOADER_CHUNK_OVERALL_SIZE: 0
  LOADER_CHUNK_SIZE: 0
  MEAN: [0.45, 0.45, 0.45]
  MULTI_LABEL: False
  NUM_FRAMES: 16
  PATH_LABEL_SEPARATOR:  
  PATH_PREFIX: 
  PATH_TO_DATA_DIR: ../ava
  PATH_TO_PRELOAD_IMDB: 
  RANDOM_FLIP: True
  REVERSE_INPUT_CHANNEL: False
  SAMPLING_RATE: 4
  SKIP_ROWS: 0
  SSL_BLUR_SIGMA_MAX: [0.0, 2.0]
  SSL_BLUR_SIGMA_MIN: [0.0, 0.1]
  SSL_COLOR_BRI_CON_SAT: [0.4, 0.4, 0.4]
  SSL_COLOR_HUE: 0.1
  SSL_COLOR_JITTER: False
  SSL_MOCOV2_AUG: False
  STD: [0.225, 0.225, 0.225]
  TARGET_FPS: 30
  TEST_CROP_SIZE: 224
  TIME_DIFF_PROB: 0.0
  TRAIN_CROP_NUM_SPATIAL: 1
  TRAIN_CROP_NUM_TEMPORAL: 1
  TRAIN_CROP_SIZE: 224
  TRAIN_JITTER_ASPECT_RELATIVE: [0.75, 1.3333]
  TRAIN_JITTER_FPS: 0.0
  TRAIN_JITTER_MOTION_SHIFT: False
  TRAIN_JITTER_SCALES: [256, 320]
  TRAIN_JITTER_SCALES_RELATIVE: [0.08, 1.0]
  TRAIN_PCA_EIGVAL: [0.225, 0.224, 0.229]
  TRAIN_PCA_EIGVEC: [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]]
  USE_OFFSET_SAMPLING: True
DATA_LOADER:
  ENABLE_MULTI_THREAD_DECODE: False
  NUM_WORKERS: 8
  PIN_MEMORY: True
DEMO:
  BUFFER_SIZE: 0
  CLIP_VIS_SIZE: 10
  COMMON_CLASS_NAMES: ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)']
  COMMON_CLASS_THRES: 0.7
  DETECTRON2_CFG: COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml
  DETECTRON2_THRESH: 0.9
  DETECTRON2_WEIGHTS: detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
  DISPLAY_HEIGHT: 0
  DISPLAY_WIDTH: 0
  ENABLE: False
  FPS: 30
  GT_BOXES: 
  INPUT_FORMAT: BGR
  INPUT_VIDEO: 
  LABEL_FILE_PATH: 
  NUM_CLIPS_SKIP: 0
  NUM_VIS_INSTANCES: 2
  OUTPUT_FILE: 
  OUTPUT_FPS: -1
  PREDS_BOXES: 
  SLOWMO: 1
  STARTING_SECOND: 900
  THREAD_ENABLE: False
  UNCOMMON_CLASS_THRES: 0.3
  VIS_MODE: thres
  WEBCAM: -1
DETECTION:
  ALIGNED: True
  ENABLE: True
  ROI_XFORM_RESOLUTION: 7
  SPATIAL_SCALE_FACTOR: 16
DIST_BACKEND: nccl
LOG_MODEL_INFO: True
LOG_PERIOD: 10
MASK:
  DECODER_DEPTH: 0
  DECODER_EMBED_DIM: 512
  DECODER_SEP_POS_EMBED: False
  DEC_KV_KERNEL: []
  DEC_KV_STRIDE: []
  ENABLE: False
  HEAD_TYPE: separate
  MAE_ON: False
  MAE_RND_MASK: False
  NORM_PRED_PIXEL: True
  PER_FRAME_MASKING: False
  PRED_HOG: False
  PRETRAIN_DEPTH: [15]
  SCALE_INIT_BY_DEPTH: False
  TIME_STRIDE_LOSS: True
MIXUP:
  ALPHA: 0.8
  CUTMIX_ALPHA: 1.0
  ENABLE: False
  LABEL_SMOOTH_VALUE: 0.1
  PROB: 1.0
  SWITCH_PROB: 0.5
MODEL:
  ACT_CHECKPOINT: False
  ARCH: mvit
  BLIP2:
    FREEZE: True
    PRETRAINED: Salesforce/blip2-flan-t5-xl
  DETACH_FINAL_FC: False
  DROPCONNECT_RATE: 0.0
  DROPOUT_RATE: 0.5
  FC_INIT_STD: 0.01
  FP16_ALLREDUCE: False
  FROZEN_BN: False
  HEAD_ACT: sigmoid
  LOSS_FUNC: bce
  MODEL_NAME: MViT
  MULTI_PATHWAY_ARCH: ['slowfast']
  NUM_CLASSES: 50
  SINGLE_PATHWAY_ARCH: ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'maskmvit', 'blip2']
MULTIGRID:
  BN_BASE_SIZE: 8
  DEFAULT_B: 0
  DEFAULT_S: 0
  DEFAULT_T: 0
  EPOCH_FACTOR: 1.5
  EVAL_FREQ: 3
  LONG_CYCLE: False
  LONG_CYCLE_FACTORS: [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)]
  LONG_CYCLE_SAMPLING_RATE: 0
  SHORT_CYCLE: False
  SHORT_CYCLE_FACTORS: [0.5, 0.7071067811865476]
MVIT:
  CLS_EMBED_ON: True
  DEPTH: 16
  DIM_MUL: [[1, 2.0], [3, 2.0], [14, 2.0]]
  DIM_MUL_IN_ATT: False
  DROPOUT_RATE: 0.0
  DROPPATH_RATE: 0.2
  EMBED_DIM: 96
  HEAD_INIT_SCALE: 1.0
  HEAD_MUL: [[1, 2.0], [3, 2.0], [14, 2.0]]
  LAYER_SCALE_INIT_VALUE: 0.0
  MLP_RATIO: 4.0
  MODE: conv
  NORM: layernorm
  NORM_STEM: False
  NUM_HEADS: 1
  PATCH_2D: False
  PATCH_KERNEL: [3, 7, 7]
  PATCH_PADDING: [1, 3, 3]
  PATCH_STRIDE: [2, 4, 4]
  POOL_FIRST: False
  POOL_KVQ_KERNEL: [3, 3, 3]
  POOL_KV_STRIDE: []
  POOL_KV_STRIDE_ADAPTIVE: [1, 8, 8]
  POOL_Q_STRIDE: [[1, 1, 2, 2], [3, 1, 2, 2], [14, 1, 2, 2]]
  QKV_BIAS: True
  REL_POS_SPATIAL: False
  REL_POS_TEMPORAL: False
  REL_POS_ZERO_INIT: False
  RESIDUAL_POOLING: False
  REV:
    BUFFER_LAYERS: []
    ENABLE: False
    PRE_Q_FUSION: avg
    RESPATH_FUSE: concat
    RES_PATH: conv
  SEPARATE_QKV: False
  SEP_POS_EMBED: True
  USE_ABS_POS: True
  USE_FIXED_SINCOS_POS: False
  USE_MEAN_POOLING: False
  ZERO_DECAY_POS_CLS: False
NONLOCAL:
  GROUP: [[1], [1], [1], [1]]
  INSTANTIATION: dot_product
  LOCATION: [[[]], [[]], [[]], [[]]]
  POOL: [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]
NUM_GPUS: 4
NUM_SHARDS: 1
OUTPUT_DIR: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4
RESNET:
  DEPTH: 50
  INPLACE_RELU: True
  NUM_BLOCK_TEMP_KERNEL: [[3], [4], [6], [3]]
  NUM_GROUPS: 1
  SPATIAL_DILATIONS: [[1], [1], [1], [1]]
  SPATIAL_STRIDES: [[1], [2], [2], [2]]
  STRIDE_1X1: False
  TRANS_FUNC: bottleneck_transform
  WIDTH_PER_GROUP: 64
  ZERO_INIT_FINAL_BN: False
  ZERO_INIT_FINAL_CONV: False
RNG_SEED: 0
SHARD_ID: 0
SLOWFAST:
  ALPHA: 8
  BETA_INV: 8
  FUSION_CONV_CHANNEL_RATIO: 2
  FUSION_KERNEL_SZ: 5
SOLVER:
  BASE_LR: 0.0001
  BASE_LR_SCALE_NUM_SHARDS: False
  BETAS: (0.9, 0.999)
  CLIP_GRAD_L2NORM: 1.0
  CLIP_GRAD_VAL: None
  COSINE_AFTER_WARMUP: False
  COSINE_END_LR: 0.0
  DAMPENING: 0.0
  GAMMA: 0.1
  LARS_ON: False
  LAYER_DECAY: 1.0
  LRS: [1, 0.1, 0.01, 0.001, 0.0001]
  LR_POLICY: steps_with_relative_lrs
  MAX_EPOCH: 60
  MOMENTUM: 0.9
  NESTEROV: True
  OPTIMIZING_METHOD: adamw
  STEPS: [0, 20, 30, 40, 50]
  STEP_SIZE: 1
  WARMUP_EPOCHS: 5.0
  WARMUP_FACTOR: 0.1
  WARMUP_START_LR: 1e-06
  WEIGHT_DECAY: 0.05
  ZERO_WD_1D_PARAM: False
TASK: 
TENSORBOARD:
  CATEGORIES_PATH: 
  CLASS_NAMES_PATH: 
  CONFUSION_MATRIX:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
  ENABLE: False
  HISTOGRAM:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
    TOPK: 10
  LOG_DIR: 
  MODEL_VIS:
    ACTIVATIONS: False
    COLORMAP: Pastel2
    ENABLE: False
    GRAD_CAM:
      COLORMAP: viridis
      ENABLE: True
      LAYER_LIST: []
      USE_TRUE_LABEL: False
    INPUT_VIDEO: False
    LAYER_LIST: []
    MODEL_WEIGHTS: False
    TOPK_PREDS: 1
  PREDICTIONS_PATH: 
  WRONG_PRED_VIS:
    ENABLE: False
    SUBSET_PATH: 
    TAG: Incorrectly classified videos.
TEST:
  BATCH_SIZE: 4
  CHECKPOINT_FILE_PATH: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/checkpoints/checkpoint_epoch_00050.pyth
  CHECKPOINT_TYPE: pytorch
  DATASET: ava
  ENABLE: True
  NUM_ENSEMBLE_VIEWS: 10
  NUM_SPATIAL_CROPS: 1
  NUM_TEMPORAL_CLIPS: [10]
  SAVE_RESULTS_PATH: 
TRAIN:
  AUTO_RESUME: True
  BATCH_SIZE: 48
  CHECKPOINT_CLEAR_NAME_PATTERN: ()
  CHECKPOINT_EPOCH_RESET: True
  CHECKPOINT_FILE_PATH: /home/lqi/lqi_temp/trainingspace/pretrained_models/MVIT_B_16x4.pyth
  CHECKPOINT_INFLATE: False
  CHECKPOINT_IN_INIT: False
  CHECKPOINT_PERIOD: 5
  CHECKPOINT_TYPE: pytorch
  DATASET: ava
  ENABLE: False
  EVAL_PERIOD: 5
  KILL_LOSS_EXPLOSION_FACTOR: 0.0
  MIXED_PRECISION: True
VIS_MASK:
  ENABLE: False
X3D:
  BN_LIN5: False
  BOTTLENECK_FACTOR: 1.0
  CHANNELWISE_3x3x3: True
  DEPTH_FACTOR: 1.0
  DIM_C1: 12
  DIM_C5: 2048
  SCALE_RES2: False
  WIDTH_FACTOR: 1.0
[05/08 01:46:17][INFO] misc.py:  186: Model:
DistributedDataParallel(
  (module): MViT(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
    )
    (blocks): ModuleList(
      (0): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=384, out_features=192, bias=True)
        )
        (proj): Linear(in_features=96, out_features=192, bias=True)
      )
      (1): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (2): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=384, bias=True)
        )
        (proj): Linear(in_features=192, out_features=384, bias=True)
      )
      (3): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (4-12): 9 x MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (13): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=768, bias=True)
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
      )
      (14): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (15): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (head): ResNetRoIHead(
      (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
      (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=768, out_features=50, bias=True)
      (act): Sigmoid()
    )
  )
)
[05/08 01:46:17][INFO] misc.py:  188: Params: 36,341,522
[05/08 01:46:17][INFO] misc.py:  189: Mem: 0.2725391387939453 MB
[05/08 01:46:17][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat encountered 1 time(s)
[05/08 01:46:17][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[05/08 01:46:17][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 33 time(s)
[05/08 01:46:17][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 1 time(s)
[05/08 01:46:17][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 130 time(s)
[05/08 01:46:17][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/08 01:46:17][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/08 01:46:17][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/08 01:46:17][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/08 01:46:17][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/08 01:46:17][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/08 01:46:17][WARNING] jit_analysis.py:  499: Unsupported operator aten::sigmoid encountered 1 time(s)
[05/08 01:46:17][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/08 01:46:18][INFO] misc.py:  191: Flops: 70.803616128 G
[05/08 01:46:18][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat encountered 1 time(s)
[05/08 01:46:18][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[05/08 01:46:18][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 33 time(s)
[05/08 01:46:18][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 1 time(s)
[05/08 01:46:18][WARNING] jit_analysis.py:  499: Unsupported operator aten::layer_norm encountered 68 time(s)
[05/08 01:46:18][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 130 time(s)
[05/08 01:46:18][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/08 01:46:18][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/08 01:46:18][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/08 01:46:18][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/08 01:46:18][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/08 01:46:18][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/08 01:46:18][WARNING] jit_analysis.py:  499: Unsupported operator aten::sigmoid encountered 1 time(s)
[05/08 01:46:18][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/08 01:46:18][INFO] misc.py:  192: Activations: 239.822315 M
[05/08 01:46:18][INFO] misc.py:  197: nvidia-smi
[05/08 01:46:18][INFO] misc.py:  186: Model:
DistributedDataParallel(
  (module): MViT(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
    )
    (blocks): ModuleList(
      (0): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=384, out_features=192, bias=True)
        )
        (proj): Linear(in_features=96, out_features=192, bias=True)
      )
      (1): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (2): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=384, bias=True)
        )
        (proj): Linear(in_features=192, out_features=384, bias=True)
      )
      (3): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (4-12): 9 x MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (13): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=768, bias=True)
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
      )
      (14): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (15): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (head): ResNetRoIHead(
      (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
      (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=768, out_features=50, bias=True)
      (act): Sigmoid()
    )
  )
)
[05/08 01:46:18][INFO] misc.py:  188: Params: 36,341,522
[05/08 01:46:18][INFO] misc.py:  189: Mem: 1.555396556854248 MB
[05/08 01:46:19][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat encountered 1 time(s)
[05/08 01:46:19][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[05/08 01:46:19][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 33 time(s)
[05/08 01:46:19][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 1 time(s)
[05/08 01:46:19][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 130 time(s)
[05/08 01:46:19][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/08 01:46:19][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/08 01:46:19][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/08 01:46:19][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/08 01:46:19][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/08 01:46:19][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/08 01:46:19][WARNING] jit_analysis.py:  499: Unsupported operator aten::sigmoid encountered 1 time(s)
[05/08 01:46:19][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/08 01:46:19][INFO] misc.py:  191: Flops: 70.803616128 G
[05/08 01:46:19][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat encountered 1 time(s)
[05/08 01:46:19][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[05/08 01:46:19][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 33 time(s)
[05/08 01:46:19][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 1 time(s)
[05/08 01:46:19][WARNING] jit_analysis.py:  499: Unsupported operator aten::layer_norm encountered 68 time(s)
[05/08 01:46:19][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 130 time(s)
[05/08 01:46:19][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/08 01:46:19][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/08 01:46:19][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/08 01:46:19][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/08 01:46:19][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/08 01:46:19][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/08 01:46:19][WARNING] jit_analysis.py:  499: Unsupported operator aten::sigmoid encountered 1 time(s)
[05/08 01:46:19][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/08 01:46:19][INFO] misc.py:  192: Activations: 239.822315 M
[05/08 01:46:19][INFO] misc.py:  197: nvidia-smi
[05/08 01:46:20][INFO] checkpoint.py:  213: Loading network weights from /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/checkpoints/checkpoint_epoch_00050.pyth.
[05/08 01:46:20][INFO] ava_helper.py:   58: Finished loading image paths from: ../ava/frame_lists/test.csv
[05/08 01:46:20][INFO] ava_helper.py:  139: Finished loading annotations from: ../ava/annotations/ava_test_predicted_boxes.csv
[05/08 01:46:20][INFO] ava_helper.py:  140: Detection threshold: 0.0
[05/08 01:46:20][INFO] ava_helper.py:  141: Number of unique boxes: 1136
[05/08 01:46:20][INFO] ava_helper.py:  142: Number of annotations: 0
[05/08 01:46:20][INFO] ava_helper.py:  185: 1091 keyframes used.
[05/08 01:46:20][INFO] ava_dataset.py:  130: === AVA dataset summary ===
[05/08 01:46:20][INFO] ava_dataset.py:  131: Split: test
[05/08 01:46:20][INFO] ava_dataset.py:  132: Number of videos: 953
[05/08 01:46:20][INFO] ava_dataset.py:  136: Number of frames: 85775
[05/08 01:46:20][INFO] ava_dataset.py:  137: Number of key frames: 1091
[05/08 01:46:20][INFO] ava_dataset.py:  138: Number of boxes: 1136.
[05/08 01:46:20][INFO] test_net.py:  215: Testing model for 273 iterations
[05/08 01:46:20][INFO] ava_helper.py:   58: Finished loading image paths from: ../ava/frame_lists/test.csv
[05/08 01:46:53][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "10", "eta": "0:00:25", "dt": 0.09646, "dt_data": 0.00489, "dt_net": 0.09157, "mode": "test"}
[05/08 01:46:54][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "20", "eta": "0:00:23", "dt": 0.09088, "dt_data": 0.00328, "dt_net": 0.08760, "mode": "test"}
[05/08 01:46:55][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "30", "eta": "0:00:22", "dt": 0.09102, "dt_data": 0.00356, "dt_net": 0.08746, "mode": "test"}
[05/08 01:46:56][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "40", "eta": "0:00:21", "dt": 0.09291, "dt_data": 0.00403, "dt_net": 0.08887, "mode": "test"}
[05/08 01:46:57][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "50", "eta": "0:00:20", "dt": 0.09326, "dt_data": 0.00304, "dt_net": 0.09022, "mode": "test"}
[05/08 01:46:58][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "60", "eta": "0:00:13", "dt": 0.06326, "dt_data": 0.00315, "dt_net": 0.06011, "mode": "test"}
[05/08 01:46:59][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "70", "eta": "0:00:18", "dt": 0.09204, "dt_data": 0.00347, "dt_net": 0.08857, "mode": "test"}
[05/08 01:46:59][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "80", "eta": "0:00:17", "dt": 0.09030, "dt_data": 0.00302, "dt_net": 0.08729, "mode": "test"}
[05/08 01:47:00][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "90", "eta": "0:00:16", "dt": 0.09215, "dt_data": 0.00397, "dt_net": 0.08817, "mode": "test"}
[05/08 01:47:01][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "100", "eta": "0:00:16", "dt": 0.09310, "dt_data": 0.00460, "dt_net": 0.08850, "mode": "test"}
[05/08 01:47:02][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "110", "eta": "0:00:15", "dt": 0.09346, "dt_data": 0.00427, "dt_net": 0.08919, "mode": "test"}
[05/08 01:47:03][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "120", "eta": "0:00:14", "dt": 0.09222, "dt_data": 0.00459, "dt_net": 0.08764, "mode": "test"}
[05/08 01:47:04][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "130", "eta": "0:00:13", "dt": 0.09348, "dt_data": 0.00310, "dt_net": 0.09037, "mode": "test"}
[05/08 01:47:05][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "140", "eta": "0:00:11", "dt": 0.08925, "dt_data": 0.00330, "dt_net": 0.08595, "mode": "test"}
[05/08 01:47:05][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "150", "eta": "0:00:08", "dt": 0.06627, "dt_data": 0.00313, "dt_net": 0.06313, "mode": "test"}
[05/08 01:47:06][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "160", "eta": "0:00:10", "dt": 0.09295, "dt_data": 0.00487, "dt_net": 0.08807, "mode": "test"}
[05/08 01:47:07][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "170", "eta": "0:00:09", "dt": 0.09270, "dt_data": 0.00446, "dt_net": 0.08824, "mode": "test"}
[05/08 01:47:08][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "180", "eta": "0:00:08", "dt": 0.09273, "dt_data": 0.00433, "dt_net": 0.08840, "mode": "test"}
[05/08 01:47:09][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "190", "eta": "0:00:05", "dt": 0.06482, "dt_data": 0.00317, "dt_net": 0.06165, "mode": "test"}
[05/08 01:47:10][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "200", "eta": "0:00:07", "dt": 0.09722, "dt_data": 0.00403, "dt_net": 0.09319, "mode": "test"}
[05/08 01:47:11][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "210", "eta": "0:00:05", "dt": 0.08903, "dt_data": 0.00304, "dt_net": 0.08599, "mode": "test"}
[05/08 01:47:12][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "220", "eta": "0:00:05", "dt": 0.09376, "dt_data": 0.00401, "dt_net": 0.08975, "mode": "test"}
[05/08 01:47:12][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "230", "eta": "0:00:02", "dt": 0.06756, "dt_data": 0.00339, "dt_net": 0.06416, "mode": "test"}
[05/08 01:47:13][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "240", "eta": "0:00:03", "dt": 0.09213, "dt_data": 0.00400, "dt_net": 0.08812, "mode": "test"}
[05/08 01:47:14][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "250", "eta": "0:00:02", "dt": 0.09135, "dt_data": 0.00389, "dt_net": 0.08746, "mode": "test"}
[05/08 01:47:15][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "260", "eta": "0:00:01", "dt": 0.09040, "dt_data": 0.00288, "dt_net": 0.08752, "mode": "test"}
[05/08 01:47:16][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "270", "eta": "0:00:00", "dt": 0.06384, "dt_data": 0.00279, "dt_net": 0.06105, "mode": "test"}
[05/08 01:47:18][INFO] ava_eval_helper.py:  204: Evaluating with 1091 unique GT frames.
[05/08 01:47:18][INFO] ava_eval_helper.py:  208: Evaluating with 1091 unique detection frames
[05/08 01:47:24][INFO] object_detection_evaluation.py:  751: The following classes have no ground truth examples: [ 2  4  9 13 15 16 18 19 20 21 23 25 31 32 33 35 37 39 40 41 42 44 49 50
 51 52 53 54 55 58 63 67 68 71 72 73 75 76 77]
[05/08 01:47:25][INFO] ava_eval_helper.py:  298: mAP@0.5 = 0.12856 | macro-F1 = 0.06516 | macro-AUROC = 0.74626 | macro-recall = 0.06041
[05/08 01:47:25][INFO] logging.py:   98: json_stats: {"mode": "test", "map": 0.12856, "f1_macro": 0.06516, "auroc_macro": 0.74626, "recall_macro": 0.06041}
[05/08 01:47:25][INFO] ava_eval_helper.py:  469: AVA results wrote to /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/detections_test.csv
[05/08 01:47:25][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/08 01:47:25][INFO] meters.py:  327: Saved CSVs:
  per-class AP: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/ap_per_class_test.csv
  detections: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/detections_test.csv
[05/08 01:47:25][INFO] test_net.py:  256: Finalized testing with 10 temporal clips and 1 spatial crops
[05/08 01:47:25][INFO] test_net.py:  275: _p36.34_f70.80_10a12.86 Top5 Acc: 12.86 MEM: 1.72 f: 70.8036
[05/08 01:47:25][INFO] test_net.py:  276: _p36.34_f70.80_10a12.86
[05/13 22:51:47][INFO] test_net.py:  188: Test with config:
[05/13 22:51:47][INFO] test_net.py:  189: AUG:
  AA_TYPE: rand-m7-n4-mstd0.5-inc1
  COLOR_JITTER: 0.4
  ENABLE: True
  GEN_MASK_LOADER: False
  INTERPOLATION: bicubic
  MASK_FRAMES: False
  MASK_RATIO: 0.0
  MASK_TUBE: False
  MASK_WINDOW_SIZE: [8, 7, 7]
  MAX_MASK_PATCHES_PER_BLOCK: None
  NUM_SAMPLE: 2
  RE_COUNT: 1
  RE_MODE: pixel
  RE_PROB: 0.25
  RE_SPLIT: False
AVA:
  ANNOTATION_DIR: ../ava/annotations
  BGR: False
  DETECTION_SCORE_THRESH: 0.0
  EXCLUSION_FILE: ava_val_excluded_timestamps_v2.2.csv
  FRAME_DIR: ../ava/frames
  FRAME_LIST_DIR: ../ava/frame_lists
  FULL_TEST_ON_VAL: True
  GROUNDTRUTH_FILE: ava_test_gt.csv
  IMG_PROC_BACKEND: cv2
  LABEL_MAP_FILE: label_map.pbtxt
  TEST_FORCE_FLIP: False
  TEST_LISTS: ['test.csv']
  TEST_PREDICT_BOX_LISTS: ['ava_test_predicted_boxes.csv']
  TRAIN_GT_BOX_LISTS: ['ava_train.csv']
  TRAIN_LISTS: ['train.csv']
  TRAIN_PCA_JITTER_ONLY: True
  TRAIN_PREDICT_BOX_LISTS: []
  TRAIN_USE_COLOR_AUGMENTATION: False
BENCHMARK:
  LOG_PERIOD: 100
  NUM_EPOCHS: 5
  SHUFFLE: True
BN:
  GLOBAL_SYNC: False
  NORM_TYPE: batchnorm
  NUM_BATCHES_PRECISE: 200
  NUM_SPLITS: 1
  NUM_SYNC_DEVICES: 1
  USE_PRECISE_STATS: False
  WEIGHT_DECAY: 0.0
CONTRASTIVE:
  BN_MLP: False
  BN_SYNC_MLP: False
  DELTA_CLIPS_MAX: inf
  DELTA_CLIPS_MIN: -inf
  DIM: 128
  INTERP_MEMORY: False
  KNN_ON: True
  LENGTH: 239975
  LOCAL_SHUFFLE_BN: True
  MEM_TYPE: 1d
  MLP_DIM: 2048
  MOCO_MULTI_VIEW_QUEUE: False
  MOMENTUM: 0.5
  MOMENTUM_ANNEALING: False
  NUM_CLASSES_DOWNSTREAM: 400
  NUM_MLP_LAYERS: 1
  PREDICTOR_DEPTHS: []
  QUEUE_LEN: 65536
  SEQUENTIAL: False
  SIMCLR_DIST_ON: True
  SWAV_QEUE_LEN: 0
  T: 0.07
  TYPE: mem
DATA:
  COLOR_RND_GRAYSCALE: 0.0
  DECODING_BACKEND: torchvision
  DECODING_SHORT_SIZE: 256
  DUMMY_LOAD: False
  ENSEMBLE_METHOD: sum
  IN22K_TRAINVAL: False
  IN22k_VAL_IN1K: 
  INPUT_CHANNEL_NUM: [3]
  INV_UNIFORM_SAMPLE: False
  IN_VAL_CROP_RATIO: 0.875
  LOADER_CHUNK_OVERALL_SIZE: 0
  LOADER_CHUNK_SIZE: 0
  MEAN: [0.45, 0.45, 0.45]
  MULTI_LABEL: False
  NUM_FRAMES: 16
  PATH_LABEL_SEPARATOR:  
  PATH_PREFIX: 
  PATH_TO_DATA_DIR: ../ava
  PATH_TO_PRELOAD_IMDB: 
  RANDOM_FLIP: True
  REVERSE_INPUT_CHANNEL: False
  SAMPLING_RATE: 4
  SKIP_ROWS: 0
  SSL_BLUR_SIGMA_MAX: [0.0, 2.0]
  SSL_BLUR_SIGMA_MIN: [0.0, 0.1]
  SSL_COLOR_BRI_CON_SAT: [0.4, 0.4, 0.4]
  SSL_COLOR_HUE: 0.1
  SSL_COLOR_JITTER: False
  SSL_MOCOV2_AUG: False
  STD: [0.225, 0.225, 0.225]
  TARGET_FPS: 30
  TEST_CROP_SIZE: 224
  TIME_DIFF_PROB: 0.0
  TRAIN_CROP_NUM_SPATIAL: 1
  TRAIN_CROP_NUM_TEMPORAL: 1
  TRAIN_CROP_SIZE: 224
  TRAIN_JITTER_ASPECT_RELATIVE: [0.75, 1.3333]
  TRAIN_JITTER_FPS: 0.0
  TRAIN_JITTER_MOTION_SHIFT: False
  TRAIN_JITTER_SCALES: [256, 320]
  TRAIN_JITTER_SCALES_RELATIVE: [0.08, 1.0]
  TRAIN_PCA_EIGVAL: [0.225, 0.224, 0.229]
  TRAIN_PCA_EIGVEC: [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]]
  USE_OFFSET_SAMPLING: True
DATA_LOADER:
  ENABLE_MULTI_THREAD_DECODE: False
  NUM_WORKERS: 8
  PIN_MEMORY: True
DEMO:
  BUFFER_SIZE: 0
  CLIP_VIS_SIZE: 10
  COMMON_CLASS_NAMES: ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)']
  COMMON_CLASS_THRES: 0.7
  DETECTRON2_CFG: COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml
  DETECTRON2_THRESH: 0.9
  DETECTRON2_WEIGHTS: detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
  DISPLAY_HEIGHT: 0
  DISPLAY_WIDTH: 0
  ENABLE: False
  FPS: 30
  GT_BOXES: 
  INPUT_FORMAT: BGR
  INPUT_VIDEO: 
  LABEL_FILE_PATH: 
  NUM_CLIPS_SKIP: 0
  NUM_VIS_INSTANCES: 2
  OUTPUT_FILE: 
  OUTPUT_FPS: -1
  PREDS_BOXES: 
  SLOWMO: 1
  STARTING_SECOND: 900
  THREAD_ENABLE: False
  UNCOMMON_CLASS_THRES: 0.3
  VIS_MODE: thres
  WEBCAM: -1
DETECTION:
  ALIGNED: True
  ENABLE: True
  ROI_XFORM_RESOLUTION: 7
  SPATIAL_SCALE_FACTOR: 16
DIST_BACKEND: nccl
LOG_MODEL_INFO: True
LOG_PERIOD: 10
MASK:
  DECODER_DEPTH: 0
  DECODER_EMBED_DIM: 512
  DECODER_SEP_POS_EMBED: False
  DEC_KV_KERNEL: []
  DEC_KV_STRIDE: []
  ENABLE: False
  HEAD_TYPE: separate
  MAE_ON: False
  MAE_RND_MASK: False
  NORM_PRED_PIXEL: True
  PER_FRAME_MASKING: False
  PRED_HOG: False
  PRETRAIN_DEPTH: [15]
  SCALE_INIT_BY_DEPTH: False
  TIME_STRIDE_LOSS: True
MIXUP:
  ALPHA: 0.8
  CUTMIX_ALPHA: 1.0
  ENABLE: False
  LABEL_SMOOTH_VALUE: 0.1
  PROB: 1.0
  SWITCH_PROB: 0.5
MODEL:
  ACT_CHECKPOINT: False
  ARCH: mvit
  BLIP2:
    FREEZE: True
    PRETRAINED: Salesforce/blip2-flan-t5-xl
  DETACH_FINAL_FC: False
  DROPCONNECT_RATE: 0.0
  DROPOUT_RATE: 0.5
  FC_INIT_STD: 0.01
  FP16_ALLREDUCE: False
  FROZEN_BN: False
  HEAD_ACT: none
  LOSS_FUNC: bce_logit
  MODEL_NAME: MViT
  MULTI_PATHWAY_ARCH: ['slowfast']
  NUM_CLASSES: 50
  SINGLE_PATHWAY_ARCH: ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'maskmvit', 'blip2']
MULTIGRID:
  BN_BASE_SIZE: 8
  DEFAULT_B: 0
  DEFAULT_S: 0
  DEFAULT_T: 0
  EPOCH_FACTOR: 1.5
  EVAL_FREQ: 3
  LONG_CYCLE: False
  LONG_CYCLE_FACTORS: [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)]
  LONG_CYCLE_SAMPLING_RATE: 0
  SHORT_CYCLE: False
  SHORT_CYCLE_FACTORS: [0.5, 0.7071067811865476]
MVIT:
  CLS_EMBED_ON: True
  DEPTH: 16
  DIM_MUL: [[1, 2.0], [3, 2.0], [14, 2.0]]
  DIM_MUL_IN_ATT: False
  DROPOUT_RATE: 0.0
  DROPPATH_RATE: 0.2
  EMBED_DIM: 96
  HEAD_INIT_SCALE: 1.0
  HEAD_MUL: [[1, 2.0], [3, 2.0], [14, 2.0]]
  LAYER_SCALE_INIT_VALUE: 0.0
  MLP_RATIO: 4.0
  MODE: conv
  NORM: layernorm
  NORM_STEM: False
  NUM_HEADS: 1
  PATCH_2D: False
  PATCH_KERNEL: [3, 7, 7]
  PATCH_PADDING: [1, 3, 3]
  PATCH_STRIDE: [2, 4, 4]
  POOL_FIRST: False
  POOL_KVQ_KERNEL: [3, 3, 3]
  POOL_KV_STRIDE: []
  POOL_KV_STRIDE_ADAPTIVE: [1, 8, 8]
  POOL_Q_STRIDE: [[1, 1, 2, 2], [3, 1, 2, 2], [14, 1, 2, 2]]
  QKV_BIAS: True
  REL_POS_SPATIAL: False
  REL_POS_TEMPORAL: False
  REL_POS_ZERO_INIT: False
  RESIDUAL_POOLING: False
  REV:
    BUFFER_LAYERS: []
    ENABLE: False
    PRE_Q_FUSION: avg
    RESPATH_FUSE: concat
    RES_PATH: conv
  SEPARATE_QKV: False
  SEP_POS_EMBED: True
  USE_ABS_POS: True
  USE_FIXED_SINCOS_POS: False
  USE_MEAN_POOLING: False
  ZERO_DECAY_POS_CLS: False
NONLOCAL:
  GROUP: [[1], [1], [1], [1]]
  INSTANTIATION: dot_product
  LOCATION: [[[]], [[]], [[]], [[]]]
  POOL: [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]
NUM_GPUS: 4
NUM_SHARDS: 1
OUTPUT_DIR: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4
RESNET:
  DEPTH: 50
  INPLACE_RELU: True
  NUM_BLOCK_TEMP_KERNEL: [[3], [4], [6], [3]]
  NUM_GROUPS: 1
  SPATIAL_DILATIONS: [[1], [1], [1], [1]]
  SPATIAL_STRIDES: [[1], [2], [2], [2]]
  STRIDE_1X1: False
  TRANS_FUNC: bottleneck_transform
  WIDTH_PER_GROUP: 64
  ZERO_INIT_FINAL_BN: False
  ZERO_INIT_FINAL_CONV: False
RNG_SEED: 0
SHARD_ID: 0
SLOWFAST:
  ALPHA: 8
  BETA_INV: 8
  FUSION_CONV_CHANNEL_RATIO: 2
  FUSION_KERNEL_SZ: 5
SOLVER:
  BASE_LR: 0.0001
  BASE_LR_SCALE_NUM_SHARDS: False
  BETAS: (0.9, 0.999)
  CLIP_GRAD_L2NORM: 1.0
  CLIP_GRAD_VAL: None
  COSINE_AFTER_WARMUP: False
  COSINE_END_LR: 0.0
  DAMPENING: 0.0
  GAMMA: 0.1
  LARS_ON: False
  LAYER_DECAY: 1.0
  LRS: [1, 0.1, 0.01, 0.001, 0.0001]
  LR_POLICY: steps_with_relative_lrs
  MAX_EPOCH: 60
  MOMENTUM: 0.9
  NESTEROV: True
  OPTIMIZING_METHOD: adamw
  STEPS: [0, 20, 30, 40, 50]
  STEP_SIZE: 1
  WARMUP_EPOCHS: 5.0
  WARMUP_FACTOR: 0.1
  WARMUP_START_LR: 1e-06
  WEIGHT_DECAY: 0.05
  ZERO_WD_1D_PARAM: False
TASK: 
TENSORBOARD:
  CATEGORIES_PATH: 
  CLASS_NAMES_PATH: 
  CONFUSION_MATRIX:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
  ENABLE: False
  HISTOGRAM:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
    TOPK: 10
  LOG_DIR: 
  MODEL_VIS:
    ACTIVATIONS: False
    COLORMAP: Pastel2
    ENABLE: False
    GRAD_CAM:
      COLORMAP: viridis
      ENABLE: True
      LAYER_LIST: []
      USE_TRUE_LABEL: False
    INPUT_VIDEO: False
    LAYER_LIST: []
    MODEL_WEIGHTS: False
    TOPK_PREDS: 1
  PREDICTIONS_PATH: 
  WRONG_PRED_VIS:
    ENABLE: False
    SUBSET_PATH: 
    TAG: Incorrectly classified videos.
TEST:
  BATCH_SIZE: 4
  CHECKPOINT_FILE_PATH: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/checkpoints/checkpoint_epoch_00050.pyth
  CHECKPOINT_TYPE: pytorch
  DATASET: ava
  ENABLE: True
  NUM_ENSEMBLE_VIEWS: 10
  NUM_SPATIAL_CROPS: 1
  NUM_TEMPORAL_CLIPS: [10]
  SAVE_RESULTS_PATH: 
TRAIN:
  AUTO_RESUME: True
  BATCH_SIZE: 48
  CHECKPOINT_CLEAR_NAME_PATTERN: ()
  CHECKPOINT_EPOCH_RESET: True
  CHECKPOINT_FILE_PATH: /home/lqi/lqi_temp/trainingspace/pretrained_models/MVIT_B_16x4.pyth
  CHECKPOINT_INFLATE: False
  CHECKPOINT_IN_INIT: False
  CHECKPOINT_PERIOD: 5
  CHECKPOINT_TYPE: pytorch
  DATASET: ava
  ENABLE: False
  EVAL_PERIOD: 5
  KILL_LOSS_EXPLOSION_FACTOR: 0.0
  MIXED_PRECISION: True
VIS_MASK:
  ENABLE: False
X3D:
  BN_LIN5: False
  BOTTLENECK_FACTOR: 1.0
  CHANNELWISE_3x3x3: True
  DEPTH_FACTOR: 1.0
  DIM_C1: 12
  DIM_C5: 2048
  SCALE_RES2: False
  WIDTH_FACTOR: 1.0
[05/13 22:51:49][INFO] misc.py:  186: Model:
DistributedDataParallel(
  (module): MViT(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
    )
    (blocks): ModuleList(
      (0): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=384, out_features=192, bias=True)
        )
        (proj): Linear(in_features=96, out_features=192, bias=True)
      )
      (1): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (2): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=384, bias=True)
        )
        (proj): Linear(in_features=192, out_features=384, bias=True)
      )
      (3): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (4-12): 9 x MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (13): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=768, bias=True)
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
      )
      (14): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (15): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (head): ResNetRoIHead(
      (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
      (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=768, out_features=50, bias=True)
      (act): Identity()
    )
  )
)
[05/13 22:51:49][INFO] misc.py:  188: Params: 36,341,522
[05/13 22:51:49][INFO] misc.py:  189: Mem: 0.2725391387939453 MB
[05/13 22:51:50][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat encountered 1 time(s)
[05/13 22:51:50][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[05/13 22:51:50][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 33 time(s)
[05/13 22:51:50][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 1 time(s)
[05/13 22:51:50][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 130 time(s)
[05/13 22:51:50][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/13 22:51:50][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/13 22:51:50][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/13 22:51:50][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/13 22:51:50][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/13 22:51:50][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/13 22:51:50][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/13 22:51:50][INFO] misc.py:  191: Flops: 70.803616128 G
[05/13 22:51:50][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat encountered 1 time(s)
[05/13 22:51:50][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[05/13 22:51:50][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 33 time(s)
[05/13 22:51:50][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 1 time(s)
[05/13 22:51:50][WARNING] jit_analysis.py:  499: Unsupported operator aten::layer_norm encountered 68 time(s)
[05/13 22:51:50][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 130 time(s)
[05/13 22:51:50][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/13 22:51:50][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/13 22:51:50][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/13 22:51:50][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/13 22:51:50][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/13 22:51:50][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/13 22:51:50][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/13 22:51:50][INFO] misc.py:  192: Activations: 239.822315 M
[05/13 22:51:50][INFO] misc.py:  197: nvidia-smi
[05/13 22:51:50][INFO] misc.py:  186: Model:
DistributedDataParallel(
  (module): MViT(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
    )
    (blocks): ModuleList(
      (0): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=384, out_features=192, bias=True)
        )
        (proj): Linear(in_features=96, out_features=192, bias=True)
      )
      (1): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (2): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=384, bias=True)
        )
        (proj): Linear(in_features=192, out_features=384, bias=True)
      )
      (3): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (4-12): 9 x MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (13): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=768, bias=True)
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
      )
      (14): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (15): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (head): ResNetRoIHead(
      (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
      (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=768, out_features=50, bias=True)
      (act): Identity()
    )
  )
)
[05/13 22:51:50][INFO] misc.py:  188: Params: 36,341,522
[05/13 22:51:50][INFO] misc.py:  189: Mem: 1.555396556854248 MB
[05/13 22:51:51][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat encountered 1 time(s)
[05/13 22:51:51][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[05/13 22:51:51][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 33 time(s)
[05/13 22:51:51][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 1 time(s)
[05/13 22:51:51][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 130 time(s)
[05/13 22:51:51][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/13 22:51:51][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/13 22:51:51][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/13 22:51:51][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/13 22:51:51][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/13 22:51:51][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/13 22:51:51][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/13 22:51:51][INFO] misc.py:  191: Flops: 70.803616128 G
[05/13 22:51:51][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat encountered 1 time(s)
[05/13 22:51:51][WARNING] jit_analysis.py:  499: Unsupported operator aten::repeat_interleave encountered 1 time(s)
[05/13 22:51:51][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 33 time(s)
[05/13 22:51:51][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 1 time(s)
[05/13 22:51:51][WARNING] jit_analysis.py:  499: Unsupported operator aten::layer_norm encountered 68 time(s)
[05/13 22:51:51][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 130 time(s)
[05/13 22:51:51][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/13 22:51:51][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/13 22:51:51][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/13 22:51:51][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/13 22:51:51][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/13 22:51:51][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/13 22:51:51][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/13 22:51:51][INFO] misc.py:  192: Activations: 239.822315 M
[05/13 22:51:51][INFO] misc.py:  197: nvidia-smi
[05/13 22:51:52][INFO] checkpoint.py:  213: Loading network weights from /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/checkpoints/checkpoint_epoch_00050.pyth.
[05/13 22:51:58][INFO] ava_helper.py:   58: Finished loading image paths from: ../ava/frame_lists/test.csv
[05/13 22:51:58][INFO] ava_helper.py:  139: Finished loading annotations from: ../ava/annotations/ava_test_predicted_boxes.csv
[05/13 22:51:58][INFO] ava_helper.py:  140: Detection threshold: 0.0
[05/13 22:51:58][INFO] ava_helper.py:  141: Number of unique boxes: 1136
[05/13 22:51:58][INFO] ava_helper.py:  142: Number of annotations: 0
[05/13 22:51:58][INFO] ava_helper.py:  185: 1091 keyframes used.
[05/13 22:51:58][INFO] ava_dataset.py:  130: === AVA dataset summary ===
[05/13 22:51:58][INFO] ava_dataset.py:  131: Split: test
[05/13 22:51:58][INFO] ava_dataset.py:  132: Number of videos: 953
[05/13 22:51:58][INFO] ava_dataset.py:  136: Number of frames: 85775
[05/13 22:51:58][INFO] ava_dataset.py:  137: Number of key frames: 1091
[05/13 22:51:58][INFO] ava_dataset.py:  138: Number of boxes: 1136.
[05/13 22:51:58][INFO] test_net.py:  215: Testing model for 273 iterations
[05/13 22:51:59][INFO] ava_helper.py:   58: Finished loading image paths from: ../ava/frame_lists/test.csv
[05/13 22:52:32][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "10", "eta": "0:00:24", "dt": 0.09285, "dt_data": 0.00426, "dt_net": 0.08859, "mode": "test"}
[05/13 22:52:33][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "20", "eta": "0:00:23", "dt": 0.09083, "dt_data": 0.00325, "dt_net": 0.08757, "mode": "test"}
[05/13 22:52:34][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "30", "eta": "0:00:22", "dt": 0.09234, "dt_data": 0.00342, "dt_net": 0.08892, "mode": "test"}
[05/13 22:52:35][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "40", "eta": "0:00:21", "dt": 0.09168, "dt_data": 0.00409, "dt_net": 0.08759, "mode": "test"}
[05/13 22:52:35][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "50", "eta": "0:00:20", "dt": 0.09182, "dt_data": 0.00303, "dt_net": 0.08879, "mode": "test"}
[05/13 22:52:36][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "60", "eta": "0:00:14", "dt": 0.06613, "dt_data": 0.00337, "dt_net": 0.06276, "mode": "test"}
[05/13 22:52:37][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "70", "eta": "0:00:18", "dt": 0.09178, "dt_data": 0.00389, "dt_net": 0.08789, "mode": "test"}
[05/13 22:52:38][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "80", "eta": "0:00:17", "dt": 0.09210, "dt_data": 0.00312, "dt_net": 0.08898, "mode": "test"}
[05/13 22:52:39][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "90", "eta": "0:00:16", "dt": 0.09198, "dt_data": 0.00410, "dt_net": 0.08788, "mode": "test"}
[05/13 22:52:40][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "100", "eta": "0:00:16", "dt": 0.09354, "dt_data": 0.00403, "dt_net": 0.08951, "mode": "test"}
[05/13 22:52:41][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "110", "eta": "0:00:15", "dt": 0.09210, "dt_data": 0.00402, "dt_net": 0.08807, "mode": "test"}
[05/13 22:52:42][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "120", "eta": "0:00:14", "dt": 0.09322, "dt_data": 0.00517, "dt_net": 0.08804, "mode": "test"}
[05/13 22:52:42][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "130", "eta": "0:00:13", "dt": 0.09160, "dt_data": 0.00319, "dt_net": 0.08841, "mode": "test"}
[05/13 22:52:43][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "140", "eta": "0:00:12", "dt": 0.09081, "dt_data": 0.00316, "dt_net": 0.08765, "mode": "test"}
[05/13 22:52:44][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "150", "eta": "0:00:07", "dt": 0.06381, "dt_data": 0.00313, "dt_net": 0.06068, "mode": "test"}
[05/13 22:52:45][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "160", "eta": "0:00:10", "dt": 0.09053, "dt_data": 0.00413, "dt_net": 0.08640, "mode": "test"}
[05/13 22:52:46][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "170", "eta": "0:00:09", "dt": 0.09256, "dt_data": 0.00398, "dt_net": 0.08858, "mode": "test"}
[05/13 22:52:47][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "180", "eta": "0:00:08", "dt": 0.09254, "dt_data": 0.00416, "dt_net": 0.08838, "mode": "test"}
[05/13 22:52:48][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "190", "eta": "0:00:05", "dt": 0.06330, "dt_data": 0.00310, "dt_net": 0.06020, "mode": "test"}
[05/13 22:52:49][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "200", "eta": "0:00:06", "dt": 0.09158, "dt_data": 0.00311, "dt_net": 0.08847, "mode": "test"}
[05/13 22:52:49][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "210", "eta": "0:00:05", "dt": 0.09160, "dt_data": 0.00304, "dt_net": 0.08857, "mode": "test"}
[05/13 22:52:50][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "220", "eta": "0:00:04", "dt": 0.09195, "dt_data": 0.00396, "dt_net": 0.08799, "mode": "test"}
[05/13 22:52:51][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "230", "eta": "0:00:02", "dt": 0.06543, "dt_data": 0.00310, "dt_net": 0.06233, "mode": "test"}
[05/13 22:52:52][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "240", "eta": "0:00:03", "dt": 0.09177, "dt_data": 0.00389, "dt_net": 0.08788, "mode": "test"}
[05/13 22:52:53][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "250", "eta": "0:00:02", "dt": 0.09223, "dt_data": 0.00396, "dt_net": 0.08827, "mode": "test"}
[05/13 22:52:54][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "260", "eta": "0:00:01", "dt": 0.08936, "dt_data": 0.00295, "dt_net": 0.08641, "mode": "test"}
[05/13 22:52:54][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "270", "eta": "0:00:00", "dt": 0.06283, "dt_data": 0.00285, "dt_net": 0.05997, "mode": "test"}
[05/13 22:52:57][INFO] ava_eval_helper.py:  204: Evaluating with 1091 unique GT frames.
[05/13 22:52:57][INFO] ava_eval_helper.py:  208: Evaluating with 1091 unique detection frames
[05/13 22:53:03][INFO] object_detection_evaluation.py:  751: The following classes have no ground truth examples: [ 2  4  9 13 15 16 18 19 20 21 23 25 31 32 33 35 37 39 40 41 42 44 49 50
 51 52 53 54 55 58 63 67 68 71 72 73 75 76 77]
[05/13 22:53:03][INFO] ava_eval_helper.py:  298: mAP@0.5 = 0.12856 | macro-F1 = 0.05539 | macro-AUROC = 0.74626 | macro-recall = 0.04662
[05/13 22:53:03][INFO] logging.py:   98: json_stats: {"mode": "test", "map": 0.12856, "f1_macro": 0.05539, "auroc_macro": 0.74626, "recall_macro": 0.04662}
[05/13 22:53:04][INFO] ava_eval_helper.py:  469: AVA results wrote to /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/detections_test.csv
[05/13 22:53:04][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/13 22:53:04][INFO] meters.py:  327: Saved CSVs:
  per-class AP: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/ap_per_class_test.csv
  detections: /home/lqi/lqi_temp/trainingspace/results/MVIT_B_16x4/detailed_csv/detections_test.csv
[05/13 22:53:04][INFO] test_net.py:  256: Finalized testing with 10 temporal clips and 1 spatial crops
[05/13 22:53:04][INFO] test_net.py:  275: _p36.34_f70.80_10a12.86 Top5 Acc: 12.86 MEM: 1.72 f: 70.8036
[05/13 22:53:04][INFO] test_net.py:  276: _p36.34_f70.80_10a12.86
