[05/07 13:03:02][INFO] train_net.py:  518: Train with config:
[05/07 13:03:02][INFO] train_net.py:  519: {'AUG': {'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1',
         'COLOR_JITTER': 0.4,
         'ENABLE': True,
         'GEN_MASK_LOADER': False,
         'INTERPOLATION': 'bicubic',
         'MASK_FRAMES': False,
         'MASK_RATIO': 0.0,
         'MASK_TUBE': False,
         'MASK_WINDOW_SIZE': [8, 7, 7],
         'MAX_MASK_PATCHES_PER_BLOCK': None,
         'NUM_SAMPLE': 2,
         'RE_COUNT': 1,
         'RE_MODE': 'pixel',
         'RE_PROB': 0.25,
         'RE_SPLIT': False},
 'AVA': {'ANNOTATION_DIR': '../ava/annotations',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.0,
         'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv',
         'FRAME_DIR': '../ava/frames',
         'FRAME_LIST_DIR': '../ava/frame_lists',
         'FULL_TEST_ON_VAL': True,
         'GROUNDTRUTH_FILE': 'ava_val_gt.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'label_map.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'],
         'TRAIN_GT_BOX_LISTS': ['ava_train.csv'],
         'TRAIN_LISTS': ['train.csv'],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': [],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'GLOBAL_SYNC': False,
        'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'CONTRASTIVE': {'BN_MLP': False,
                 'BN_SYNC_MLP': False,
                 'DELTA_CLIPS_MAX': inf,
                 'DELTA_CLIPS_MIN': -inf,
                 'DIM': 128,
                 'INTERP_MEMORY': False,
                 'KNN_ON': True,
                 'LENGTH': 239975,
                 'LOCAL_SHUFFLE_BN': True,
                 'MEM_TYPE': '1d',
                 'MLP_DIM': 2048,
                 'MOCO_MULTI_VIEW_QUEUE': False,
                 'MOMENTUM': 0.5,
                 'MOMENTUM_ANNEALING': False,
                 'NUM_CLASSES_DOWNSTREAM': 400,
                 'NUM_MLP_LAYERS': 1,
                 'PREDICTOR_DEPTHS': [],
                 'QUEUE_LEN': 65536,
                 'SEQUENTIAL': False,
                 'SIMCLR_DIST_ON': True,
                 'SWAV_QEUE_LEN': 0,
                 'T': 0.07,
                 'TYPE': 'mem'},
 'DATA': {'COLOR_RND_GRAYSCALE': 0.0,
          'DECODING_BACKEND': 'torchvision',
          'DECODING_SHORT_SIZE': 256,
          'DUMMY_LOAD': False,
          'ENSEMBLE_METHOD': 'sum',
          'IN22K_TRAINVAL': False,
          'IN22k_VAL_IN1K': '',
          'INPUT_CHANNEL_NUM': [3],
          'INV_UNIFORM_SAMPLE': False,
          'IN_VAL_CROP_RATIO': 0.875,
          'LOADER_CHUNK_OVERALL_SIZE': 0,
          'LOADER_CHUNK_SIZE': 0,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 16,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '../ava',
          'PATH_TO_PRELOAD_IMDB': '',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 4,
          'SKIP_ROWS': 0,
          'SSL_BLUR_SIGMA_MAX': [0.0, 2.0],
          'SSL_BLUR_SIGMA_MIN': [0.0, 0.1],
          'SSL_COLOR_BRI_CON_SAT': [0.4, 0.4, 0.4],
          'SSL_COLOR_HUE': 0.1,
          'SSL_COLOR_JITTER': False,
          'SSL_MOCOV2_AUG': False,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 30,
          'TEST_CROP_SIZE': 224,
          'TIME_DIFF_PROB': 0.0,
          'TRAIN_CROP_NUM_SPATIAL': 1,
          'TRAIN_CROP_NUM_TEMPORAL': 1,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333],
          'TRAIN_JITTER_FPS': 0.0,
          'TRAIN_JITTER_MOTION_SHIFT': False,
          'TRAIN_JITTER_SCALES': [256, 320],
          'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0],
          'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
          'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                               [-0.5808, -0.0045, -0.814],
                               [-0.5836, -0.6948, 0.4203]],
          'USE_OFFSET_SAMPLING': True},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 8,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': True,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 10,
 'MASK': {'DECODER_DEPTH': 0,
          'DECODER_EMBED_DIM': 512,
          'DECODER_SEP_POS_EMBED': False,
          'DEC_KV_KERNEL': [],
          'DEC_KV_STRIDE': [],
          'ENABLE': False,
          'HEAD_TYPE': 'separate',
          'MAE_ON': False,
          'MAE_RND_MASK': False,
          'NORM_PRED_PIXEL': True,
          'PER_FRAME_MASKING': False,
          'PRED_HOG': False,
          'PRETRAIN_DEPTH': [15],
          'SCALE_INIT_BY_DEPTH': False,
          'TIME_STRIDE_LOSS': True},
 'MIXUP': {'ALPHA': 0.8,
           'CUTMIX_ALPHA': 1.0,
           'ENABLE': False,
           'LABEL_SMOOTH_VALUE': 0.1,
           'PROB': 1.0,
           'SWITCH_PROB': 0.5},
 'MODEL': {'ACT_CHECKPOINT': False,
           'ARCH': 'mvit',
           'DETACH_FINAL_FC': False,
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'FP16_ALLREDUCE': False,
           'FROZEN_BN': False,
           'HEAD_ACT': 'none',
           'LOSS_FUNC': 'bce_logit',
           'MODEL_NAME': 'MViT',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 50,
           'SINGLE_PATHWAY_ARCH': ['2d',
                                   'c2d',
                                   'i3d',
                                   'slow',
                                   'x3d',
                                   'mvit',
                                   'maskmvit']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'MVIT': {'CLS_EMBED_ON': True,
          'DEPTH': 16,
          'DIM_MUL': [[1, 2.0], [3, 2.0], [14, 2.0]],
          'DIM_MUL_IN_ATT': True,
          'DROPOUT_RATE': 0.0,
          'DROPPATH_RATE': 0.2,
          'EMBED_DIM': 96,
          'HEAD_INIT_SCALE': 1.0,
          'HEAD_MUL': [[1, 2.0], [3, 2.0], [14, 2.0]],
          'LAYER_SCALE_INIT_VALUE': 0.0,
          'MLP_RATIO': 4.0,
          'MODE': 'conv',
          'NORM': 'layernorm',
          'NORM_STEM': False,
          'NUM_HEADS': 1,
          'PATCH_2D': False,
          'PATCH_KERNEL': [3, 7, 7],
          'PATCH_PADDING': [1, 3, 3],
          'PATCH_STRIDE': [2, 4, 4],
          'POOL_FIRST': False,
          'POOL_KVQ_KERNEL': [3, 3, 3],
          'POOL_KV_STRIDE': [],
          'POOL_KV_STRIDE_ADAPTIVE': [1, 8, 8],
          'POOL_Q_STRIDE': [[0, 1, 1, 1],
                            [1, 1, 2, 2],
                            [2, 1, 1, 1],
                            [3, 1, 2, 2],
                            [4, 1, 1, 1],
                            [5, 1, 1, 1],
                            [6, 1, 1, 1],
                            [7, 1, 1, 1],
                            [8, 1, 1, 1],
                            [9, 1, 1, 1],
                            [10, 1, 1, 1],
                            [11, 1, 1, 1],
                            [12, 1, 1, 1],
                            [13, 1, 1, 1],
                            [14, 1, 2, 2],
                            [15, 1, 1, 1]],
          'QKV_BIAS': True,
          'REL_POS_SPATIAL': True,
          'REL_POS_TEMPORAL': True,
          'REL_POS_ZERO_INIT': False,
          'RESIDUAL_POOLING': True,
          'REV': {'BUFFER_LAYERS': [],
                  'ENABLE': False,
                  'PRE_Q_FUSION': 'avg',
                  'RESPATH_FUSE': 'concat',
                  'RES_PATH': 'conv'},
          'SEPARATE_QKV': False,
          'SEP_POS_EMBED': False,
          'USE_ABS_POS': False,
          'USE_FIXED_SINCOS_POS': False,
          'USE_MEAN_POOLING': False,
          'ZERO_DECAY_POS_CLS': False},
 'NONLOCAL': {'GROUP': [[1], [1], [1], [1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[]], [[]], [[]], [[]]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 3,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '/home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1], [1], [1], [1]],
            'SPATIAL_STRIDES': [[1], [2], [2], [2]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': False,
            'ZERO_INIT_FINAL_CONV': False},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 8,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 5},
 'SOLVER': {'BASE_LR': 0.0001,
            'BASE_LR_SCALE_NUM_SHARDS': False,
            'BETAS': (0.9, 0.999),
            'CLIP_GRAD_L2NORM': 1.0,
            'CLIP_GRAD_VAL': None,
            'COSINE_AFTER_WARMUP': False,
            'COSINE_END_LR': 0.0,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LARS_ON': False,
            'LAYER_DECAY': 1.0,
            'LRS': [1, 0.1, 0.01, 0.001, 0.0001],
            'LR_POLICY': 'steps_with_relative_lrs',
            'MAX_EPOCH': 60,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'adamw',
            'STEPS': [0, 20, 30, 40, 50],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 5.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 1e-06,
            'WEIGHT_DECAY': 0.05,
            'ZERO_WD_1D_PARAM': False},
 'TASK': '',
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': False,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 3,
          'CHECKPOINT_FILE_PATH': '/home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/checkpoints/checkpoint_epoch_00035.pyth',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'ava',
          'ENABLE': False,
          'NUM_ENSEMBLE_VIEWS': 5,
          'NUM_SPATIAL_CROPS': 1,
          'NUM_TEMPORAL_CLIPS': [],
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 48,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': True,
           'CHECKPOINT_FILE_PATH': '/home/lqi/lqi_temp/trainingspace/pretrained_models/MViTv2_S_16x4.pyth',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_IN_INIT': False,
           'CHECKPOINT_PERIOD': 5,
           'CHECKPOINT_TYPE': 'pytorch',
           'DATASET': 'ava',
           'ENABLE': True,
           'EVAL_PERIOD': 5,
           'KILL_LOSS_EXPLOSION_FACTOR': 0.0,
           'MIXED_PRECISION': True},
 'VIS_MASK': CfgNode({'ENABLE': False}),
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[05/07 13:03:04][INFO] misc.py:  186: Model:
DistributedDataParallel(
  (module): MViT(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
    )
    (blocks): ModuleList(
      (0): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=384, out_features=96, bias=True)
        )
      )
      (1): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
        (proj): Linear(in_features=96, out_features=192, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (2): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
      )
      (3): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
        (proj): Linear(in_features=192, out_features=384, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (4-13): 10 x MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (14): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (15): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (head): ResNetRoIHead(
      (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
      (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=768, out_features=50, bias=True)
      (act): Identity()
    )
  )
)
[05/07 13:03:04][INFO] misc.py:  188: Params: 34,268,594
[05/07 13:03:04][INFO] misc.py:  189: Mem: 0.2556772232055664 MB
[05/07 13:03:06][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 489 time(s)
[05/07 13:03:06][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 68 time(s)
[05/07 13:03:06][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 96 time(s)
[05/07 13:03:06][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 64 time(s)
[05/07 13:03:06][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 80 time(s)
[05/07 13:03:06][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/07 13:03:06][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/07 13:03:06][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/07 13:03:06][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/07 13:03:06][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/07 13:03:06][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/07 13:03:06][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/07 13:03:06][INFO] misc.py:  191: Flops: 64.45665578399999 G
[05/07 13:03:08][WARNING] jit_analysis.py:  499: Unsupported operator aten::layer_norm encountered 81 time(s)
[05/07 13:03:08][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 489 time(s)
[05/07 13:03:08][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 68 time(s)
[05/07 13:03:08][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 96 time(s)
[05/07 13:03:08][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 64 time(s)
[05/07 13:03:08][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 80 time(s)
[05/07 13:03:08][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/07 13:03:08][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/07 13:03:08][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/07 13:03:08][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/07 13:03:08][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/07 13:03:08][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/07 13:03:08][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/07 13:03:08][INFO] misc.py:  192: Activations: 248.60871500000002 M
[05/07 13:03:08][INFO] misc.py:  197: nvidia-smi
[05/07 13:03:08][INFO] train_net.py:  560: Load from given checkpoint file.
[05/07 13:03:08][INFO] checkpoint.py:  213: Loading network weights from /home/lqi/lqi_temp/trainingspace/pretrained_models/MViTv2_S_16x4.pyth.
[05/07 13:03:08][INFO] checkpoint.py:  502: Network weights head.projection.weight not loaded.
[05/07 13:03:08][INFO] checkpoint.py:  502: Network weights head.projection.bias not loaded.
[05/07 13:03:08][INFO] checkpoint.py:  505: Network weights head.projection.weight not used.
[05/07 13:03:08][INFO] checkpoint.py:  505: Network weights head.projection.bias not used.
[05/07 13:03:09][INFO] ava_helper.py:   58: Finished loading image paths from: ../ava/frame_lists/train.csv
[05/07 13:03:09][INFO] ava_helper.py:  139: Finished loading annotations from: ../ava/annotations/ava_train.csv
[05/07 13:03:09][INFO] ava_helper.py:  140: Detection threshold: 0.0
[05/07 13:03:09][INFO] ava_helper.py:  141: Number of unique boxes: 4029
[05/07 13:03:09][INFO] ava_helper.py:  142: Number of annotations: 9266
[05/07 13:03:09][INFO] ava_helper.py:  185: 3835 keyframes used.
[05/07 13:03:09][INFO] ava_dataset.py:  130: === AVA dataset summary ===
[05/07 13:03:09][INFO] ava_dataset.py:  131: Split: train
[05/07 13:03:09][INFO] ava_dataset.py:  132: Number of videos: 3331
[05/07 13:03:09][INFO] ava_dataset.py:  136: Number of frames: 299789
[05/07 13:03:09][INFO] ava_dataset.py:  137: Number of key frames: 3835
[05/07 13:03:09][INFO] ava_dataset.py:  138: Number of boxes: 4029.
[05/07 13:03:09][INFO] ava_helper.py:   58: Finished loading image paths from: ../ava/frame_lists/val.csv
[05/07 13:03:09][INFO] ava_helper.py:  139: Finished loading annotations from: ../ava/annotations/ava_val_predicted_boxes.csv
[05/07 13:03:09][INFO] ava_helper.py:  140: Detection threshold: 0.0
[05/07 13:03:09][INFO] ava_helper.py:  141: Number of unique boxes: 570
[05/07 13:03:09][INFO] ava_helper.py:  142: Number of annotations: 0
[05/07 13:03:09][INFO] ava_helper.py:  185: 542 keyframes used.
[05/07 13:03:09][INFO] ava_dataset.py:  130: === AVA dataset summary ===
[05/07 13:03:09][INFO] ava_dataset.py:  131: Split: val
[05/07 13:03:09][INFO] ava_dataset.py:  132: Number of videos: 475
[05/07 13:03:09][INFO] ava_dataset.py:  136: Number of frames: 42751
[05/07 13:03:09][INFO] ava_dataset.py:  137: Number of key frames: 542
[05/07 13:03:09][INFO] ava_dataset.py:  138: Number of boxes: 570.
[05/07 13:03:10][INFO] ava_helper.py:   58: Finished loading image paths from: ../ava/frame_lists/train.csv
[05/07 13:03:10][INFO] ava_helper.py:   58: Finished loading image paths from: ../ava/frame_lists/val.csv
[05/07 13:03:10][INFO] train_net.py:  611: Start epoch: 1
[05/07 13:03:55][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "1/60", "cur_iter": "10", "eta": "0:01:23", "dt": 1.19831, "dt_data": 0.00043, "dt_net": 1.19788, "mode": "train", "loss": 0.70248, "lr": 0.00000}
[05/07 13:04:07][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "1/60", "cur_iter": "20", "eta": "0:01:13", "dt": 1.22069, "dt_data": 0.00042, "dt_net": 1.22027, "mode": "train", "loss": 0.69226, "lr": 0.00001}
[05/07 13:04:20][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "1/60", "cur_iter": "30", "eta": "0:01:01", "dt": 1.23550, "dt_data": 0.00045, "dt_net": 1.23505, "mode": "train", "loss": 0.68355, "lr": 0.00001}
[05/07 13:04:32][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "1/60", "cur_iter": "40", "eta": "0:00:49", "dt": 1.24596, "dt_data": 0.00038, "dt_net": 1.24557, "mode": "train", "loss": 0.66687, "lr": 0.00001}
[05/07 13:04:44][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "1/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.25023, "dt_data": 0.00042, "dt_net": 1.24981, "mode": "train", "loss": 0.64975, "lr": 0.00001}
[05/07 13:04:57][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "1/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.26467, "dt_data": 0.00043, "dt_net": 1.26424, "mode": "train", "loss": 0.62840, "lr": 0.00002}
[05/07 13:05:09][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "1/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.23922, "dt_data": 0.00023, "dt_net": 1.23899, "mode": "train", "loss": 0.60872, "lr": 0.00002}
[05/07 13:05:22][INFO] train_net.py:  669: Epoch 1 takes 131.64s. Epochs from 1 to 1 take 131.64s in average and 131.64s in median.
[05/07 13:05:22][INFO] train_net.py:  675: For epoch 1, each iteraction takes 1.67s in average. From epoch 1 to 1, each iteraction takes 1.67s in average.
[05/07 13:06:08][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "2/60", "cur_iter": "10", "eta": "0:01:24", "dt": 1.21245, "dt_data": 0.00040, "dt_net": 1.21205, "mode": "train", "loss": 0.55071, "lr": 0.00002}
[05/07 13:06:20][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "2/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.23793, "dt_data": 0.00041, "dt_net": 1.23752, "mode": "train", "loss": 0.52307, "lr": 0.00003}
[05/07 13:06:32][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "2/60", "cur_iter": "30", "eta": "0:01:01", "dt": 1.23885, "dt_data": 0.00039, "dt_net": 1.23846, "mode": "train", "loss": 0.50695, "lr": 0.00003}
[05/07 13:06:45][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "2/60", "cur_iter": "40", "eta": "0:00:49", "dt": 1.24072, "dt_data": 0.00040, "dt_net": 1.24032, "mode": "train", "loss": 0.47825, "lr": 0.00003}
[05/07 13:06:57][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "2/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.25633, "dt_data": 0.00042, "dt_net": 1.25591, "mode": "train", "loss": 0.45504, "lr": 0.00003}
[05/07 13:07:10][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "2/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.25112, "dt_data": 0.00039, "dt_net": 1.25072, "mode": "train", "loss": 0.42046, "lr": 0.00004}
[05/07 13:07:22][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "2/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.24931, "dt_data": 0.00026, "dt_net": 1.24905, "mode": "train", "loss": 0.42863, "lr": 0.00004}
[05/07 13:07:34][INFO] train_net.py:  669: Epoch 2 takes 132.88s. Epochs from 1 to 2 take 132.26s in average and 132.26s in median.
[05/07 13:07:34][INFO] train_net.py:  675: For epoch 2, each iteraction takes 1.68s in average. From epoch 1 to 2, each iteraction takes 1.67s in average.
[05/07 13:08:26][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "3/60", "cur_iter": "10", "eta": "0:01:24", "dt": 1.21295, "dt_data": 0.00034, "dt_net": 1.21261, "mode": "train", "loss": 0.37497, "lr": 0.00004}
[05/07 13:08:38][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "3/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.24412, "dt_data": 0.00040, "dt_net": 1.24372, "mode": "train", "loss": 0.35466, "lr": 0.00005}
[05/07 13:08:50][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "3/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.25472, "dt_data": 0.00051, "dt_net": 1.25420, "mode": "train", "loss": 0.32979, "lr": 0.00005}
[05/07 13:09:03][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "3/60", "cur_iter": "40", "eta": "0:00:50", "dt": 1.25022, "dt_data": 0.00039, "dt_net": 1.24983, "mode": "train", "loss": 0.32858, "lr": 0.00005}
[05/07 13:09:15][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "3/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.26389, "dt_data": 0.00044, "dt_net": 1.26345, "mode": "train", "loss": 0.30433, "lr": 0.00005}
[05/07 13:09:28][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "3/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.27067, "dt_data": 0.00071, "dt_net": 1.26996, "mode": "train", "loss": 0.29820, "lr": 0.00006}
[05/07 13:09:41][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "3/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.25565, "dt_data": 0.00023, "dt_net": 1.25541, "mode": "train", "loss": 0.29254, "lr": 0.00006}
[05/07 13:09:53][INFO] train_net.py:  669: Epoch 3 takes 138.58s. Epochs from 1 to 3 take 134.37s in average and 132.88s in median.
[05/07 13:09:53][INFO] train_net.py:  675: For epoch 3, each iteraction takes 1.75s in average. From epoch 1 to 3, each iteraction takes 1.70s in average.
[05/07 13:10:38][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "4/60", "cur_iter": "10", "eta": "0:01:25", "dt": 1.22441, "dt_data": 0.00050, "dt_net": 1.22391, "mode": "train", "loss": 0.26493, "lr": 0.00006}
[05/07 13:10:50][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "4/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.24393, "dt_data": 0.00037, "dt_net": 1.24356, "mode": "train", "loss": 0.27045, "lr": 0.00007}
[05/07 13:11:03][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "4/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.25084, "dt_data": 0.00040, "dt_net": 1.25043, "mode": "train", "loss": 0.24729, "lr": 0.00007}
[05/07 13:11:15][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "4/60", "cur_iter": "40", "eta": "0:00:50", "dt": 1.25142, "dt_data": 0.00070, "dt_net": 1.25072, "mode": "train", "loss": 0.25570, "lr": 0.00007}
[05/07 13:11:28][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "4/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.26159, "dt_data": 0.00047, "dt_net": 1.26112, "mode": "train", "loss": 0.28256, "lr": 0.00007}
[05/07 13:11:41][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "4/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.26152, "dt_data": 0.00044, "dt_net": 1.26108, "mode": "train", "loss": 0.25275, "lr": 0.00008}
[05/07 13:11:53][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "4/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.27817, "dt_data": 0.00024, "dt_net": 1.27793, "mode": "train", "loss": 0.25475, "lr": 0.00008}
[05/07 13:12:06][INFO] train_net.py:  669: Epoch 4 takes 132.64s. Epochs from 1 to 4 take 133.94s in average and 132.76s in median.
[05/07 13:12:06][INFO] train_net.py:  675: For epoch 4, each iteraction takes 1.68s in average. From epoch 1 to 4, each iteraction takes 1.70s in average.
[05/07 13:12:50][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "5/60", "cur_iter": "10", "eta": "0:01:25", "dt": 1.22157, "dt_data": 0.00037, "dt_net": 1.22120, "mode": "train", "loss": 0.23058, "lr": 0.00008}
[05/07 13:13:03][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "5/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.24469, "dt_data": 0.00043, "dt_net": 1.24426, "mode": "train", "loss": 0.24334, "lr": 0.00008}
[05/07 13:13:15][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "5/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.24742, "dt_data": 0.00048, "dt_net": 1.24693, "mode": "train", "loss": 0.23225, "lr": 0.00009}
[05/07 13:13:28][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "5/60", "cur_iter": "40", "eta": "0:00:49", "dt": 1.23102, "dt_data": 0.00037, "dt_net": 1.23065, "mode": "train", "loss": 0.24578, "lr": 0.00009}
[05/07 13:13:40][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "5/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.24732, "dt_data": 0.00049, "dt_net": 1.24682, "mode": "train", "loss": 0.27675, "lr": 0.00009}
[05/07 13:13:53][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "5/60", "cur_iter": "60", "eta": "0:00:24", "dt": 1.24855, "dt_data": 0.00051, "dt_net": 1.24804, "mode": "train", "loss": 0.23410, "lr": 0.00009}
[05/07 13:14:05][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "5/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.24790, "dt_data": 0.00022, "dt_net": 1.24768, "mode": "train", "loss": 0.25323, "lr": 0.00010}
[05/07 13:14:17][INFO] train_net.py:  669: Epoch 5 takes 131.68s. Epochs from 1 to 5 take 133.48s in average and 132.64s in median.
[05/07 13:14:17][INFO] train_net.py:  675: For epoch 5, each iteraction takes 1.67s in average. From epoch 1 to 5, each iteraction takes 1.69s in average.
[05/07 13:14:57][INFO] logging.py:   98: json_stats: {"_type": "val_iter", "cur_epoch": "5/60", "cur_iter": "10", "eta": "0:00:01", "dt": 0.47419, "dt_data": 0.01206, "dt_net": 0.46213, "mode": "val"}
[05/07 13:14:59][INFO] ava_eval_helper.py:  204: Evaluating with 542 unique GT frames.
[05/07 13:14:59][INFO] ava_eval_helper.py:  208: Evaluating with 542 unique detection frames
[05/07 13:14:59][INFO] ava_eval_helper.py:  469: AVA results wrote to detections_latest.csv
[05/07 13:14:59][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 13:14:59][INFO] ava_eval_helper.py:  469: AVA results wrote to groundtruth_latest.csv
[05/07 13:14:59][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 13:15:02][INFO] object_detection_evaluation.py:  751: The following classes have no ground truth examples: [ 2  3  4  5 10 13 15 16 18 19 20 21 23 25 28 31 32 33 35 37 39 40 41 42
 44 49 50 51 52 53 54 55 56 57 63 64 67 68 70 71 72 73 75 77]
[05/07 13:15:02][INFO] ava_eval_helper.py:  298: mAP@0.5 = 0.10939 | macro-F1 = 0.04264 | macro-AUROC = 0.55382 | macro-recall = 0.03966
[05/07 13:15:02][INFO] logging.py:   98: json_stats: {"mode": "val", "cur_epoch": "5", "map": 0.10939, "f1_macro": 0.04264, "auroc_macro": 0.55382, "recall_macro": 0.03966, "gpu_mem": "18.46G", "RAM": "72.09/251.58G", "_type": "val_epoch"}
[05/07 13:15:02][INFO] ava_eval_helper.py:  469: AVA results wrote to /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/detections_val_5.csv
[05/07 13:15:02][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 13:15:02][INFO] meters.py:  327: Saved CSVs:
  per-class AP: /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/ap_per_class_val_5.csv
  detections: /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/detections_val_5.csv
[05/07 13:15:46][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "6/60", "cur_iter": "10", "eta": "0:01:24", "dt": 1.20915, "dt_data": 0.00041, "dt_net": 1.20874, "mode": "train", "loss": 0.25047, "lr": 0.00010}
[05/07 13:15:58][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "6/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.23388, "dt_data": 0.00035, "dt_net": 1.23353, "mode": "train", "loss": 0.22788, "lr": 0.00010}
[05/07 13:16:11][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "6/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.24821, "dt_data": 0.00048, "dt_net": 1.24773, "mode": "train", "loss": 0.25163, "lr": 0.00010}
[05/07 13:16:23][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "6/60", "cur_iter": "40", "eta": "0:00:50", "dt": 1.25097, "dt_data": 0.00037, "dt_net": 1.25060, "mode": "train", "loss": 0.24337, "lr": 0.00010}
[05/07 13:16:36][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "6/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.24768, "dt_data": 0.00044, "dt_net": 1.24724, "mode": "train", "loss": 0.24484, "lr": 0.00010}
[05/07 13:16:48][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "6/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.25733, "dt_data": 0.00054, "dt_net": 1.25678, "mode": "train", "loss": 0.22141, "lr": 0.00010}
[05/07 13:17:01][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "6/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.24910, "dt_data": 0.00023, "dt_net": 1.24887, "mode": "train", "loss": 0.22657, "lr": 0.00010}
[05/07 13:17:13][INFO] train_net.py:  669: Epoch 6 takes 131.15s. Epochs from 1 to 6 take 133.10s in average and 132.16s in median.
[05/07 13:17:13][INFO] train_net.py:  675: For epoch 6, each iteraction takes 1.66s in average. From epoch 1 to 6, each iteraction takes 1.68s in average.
[05/07 13:18:02][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "7/60", "cur_iter": "10", "eta": "0:01:24", "dt": 1.20693, "dt_data": 0.00043, "dt_net": 1.20650, "mode": "train", "loss": 0.22693, "lr": 0.00010}
[05/07 13:18:14][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "7/60", "cur_iter": "20", "eta": "0:01:13", "dt": 1.23278, "dt_data": 0.00041, "dt_net": 1.23237, "mode": "train", "loss": 0.22341, "lr": 0.00010}
[05/07 13:18:27][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "7/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.24405, "dt_data": 0.00043, "dt_net": 1.24362, "mode": "train", "loss": 0.21825, "lr": 0.00010}
[05/07 13:18:39][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "7/60", "cur_iter": "40", "eta": "0:00:50", "dt": 1.25101, "dt_data": 0.00035, "dt_net": 1.25066, "mode": "train", "loss": 0.24904, "lr": 0.00010}
[05/07 13:18:51][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "7/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.24485, "dt_data": 0.00053, "dt_net": 1.24431, "mode": "train", "loss": 0.23849, "lr": 0.00010}
[05/07 13:19:04][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "7/60", "cur_iter": "60", "eta": "0:00:24", "dt": 1.23543, "dt_data": 0.00037, "dt_net": 1.23506, "mode": "train", "loss": 0.22679, "lr": 0.00010}
[05/07 13:19:16][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "7/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.24284, "dt_data": 0.00029, "dt_net": 1.24255, "mode": "train", "loss": 0.22841, "lr": 0.00010}
[05/07 13:19:29][INFO] train_net.py:  669: Epoch 7 takes 135.44s. Epochs from 1 to 7 take 133.43s in average and 132.64s in median.
[05/07 13:19:29][INFO] train_net.py:  675: For epoch 7, each iteraction takes 1.71s in average. From epoch 1 to 7, each iteraction takes 1.69s in average.
[05/07 13:20:16][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "8/60", "cur_iter": "10", "eta": "0:01:25", "dt": 1.21785, "dt_data": 0.00041, "dt_net": 1.21744, "mode": "train", "loss": 0.25472, "lr": 0.00010}
[05/07 13:20:28][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "8/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.23557, "dt_data": 0.00038, "dt_net": 1.23519, "mode": "train", "loss": 0.23843, "lr": 0.00010}
[05/07 13:20:41][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "8/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.25170, "dt_data": 0.00043, "dt_net": 1.25126, "mode": "train", "loss": 0.22337, "lr": 0.00010}
[05/07 13:20:53][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "8/60", "cur_iter": "40", "eta": "0:00:49", "dt": 1.24370, "dt_data": 0.00053, "dt_net": 1.24316, "mode": "train", "loss": 0.23858, "lr": 0.00010}
[05/07 13:21:06][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "8/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.24361, "dt_data": 0.00068, "dt_net": 1.24293, "mode": "train", "loss": 0.22706, "lr": 0.00010}
[05/07 13:21:18][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "8/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.26014, "dt_data": 0.00051, "dt_net": 1.25963, "mode": "train", "loss": 0.22714, "lr": 0.00010}
[05/07 13:21:31][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "8/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.24988, "dt_data": 0.00021, "dt_net": 1.24966, "mode": "train", "loss": 0.22665, "lr": 0.00010}
[05/07 13:21:43][INFO] train_net.py:  669: Epoch 8 takes 134.76s. Epochs from 1 to 8 take 133.60s in average and 132.76s in median.
[05/07 13:21:43][INFO] train_net.py:  675: For epoch 8, each iteraction takes 1.71s in average. From epoch 1 to 8, each iteraction takes 1.69s in average.
[05/07 13:22:30][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "9/60", "cur_iter": "10", "eta": "0:01:25", "dt": 1.22080, "dt_data": 0.00039, "dt_net": 1.22041, "mode": "train", "loss": 0.23304, "lr": 0.00010}
[05/07 13:22:42][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "9/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.23444, "dt_data": 0.00041, "dt_net": 1.23402, "mode": "train", "loss": 0.24501, "lr": 0.00010}
[05/07 13:22:54][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "9/60", "cur_iter": "30", "eta": "0:01:01", "dt": 1.23389, "dt_data": 0.00061, "dt_net": 1.23328, "mode": "train", "loss": 0.23780, "lr": 0.00010}
[05/07 13:23:07][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "9/60", "cur_iter": "40", "eta": "0:00:50", "dt": 1.25862, "dt_data": 0.00036, "dt_net": 1.25826, "mode": "train", "loss": 0.23794, "lr": 0.00010}
[05/07 13:23:19][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "9/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.25770, "dt_data": 0.00040, "dt_net": 1.25730, "mode": "train", "loss": 0.23050, "lr": 0.00010}
[05/07 13:23:32][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "9/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.25124, "dt_data": 0.00042, "dt_net": 1.25082, "mode": "train", "loss": 0.22894, "lr": 0.00010}
[05/07 13:23:44][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "9/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.25614, "dt_data": 0.00022, "dt_net": 1.25592, "mode": "train", "loss": 0.24091, "lr": 0.00010}
[05/07 13:23:57][INFO] train_net.py:  669: Epoch 9 takes 133.34s. Epochs from 1 to 9 take 133.57s in average and 132.88s in median.
[05/07 13:23:57][INFO] train_net.py:  675: For epoch 9, each iteraction takes 1.69s in average. From epoch 1 to 9, each iteraction takes 1.69s in average.
[05/07 13:24:43][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "10/60", "cur_iter": "10", "eta": "0:01:25", "dt": 1.21837, "dt_data": 0.00045, "dt_net": 1.21793, "mode": "train", "loss": 0.20842, "lr": 0.00010}
[05/07 13:24:55][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "10/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.23758, "dt_data": 0.00036, "dt_net": 1.23722, "mode": "train", "loss": 0.22386, "lr": 0.00010}
[05/07 13:25:08][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "10/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.24419, "dt_data": 0.00051, "dt_net": 1.24368, "mode": "train", "loss": 0.25433, "lr": 0.00010}
[05/07 13:25:20][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "10/60", "cur_iter": "40", "eta": "0:00:50", "dt": 1.25094, "dt_data": 0.00038, "dt_net": 1.25056, "mode": "train", "loss": 0.23677, "lr": 0.00010}
[05/07 13:25:33][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "10/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.26381, "dt_data": 0.00039, "dt_net": 1.26342, "mode": "train", "loss": 0.22283, "lr": 0.00010}
[05/07 13:25:46][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "10/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.26280, "dt_data": 0.00071, "dt_net": 1.26208, "mode": "train", "loss": 0.22752, "lr": 0.00010}
[05/07 13:25:58][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "10/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.25945, "dt_data": 0.00024, "dt_net": 1.25921, "mode": "train", "loss": 0.23339, "lr": 0.00010}
[05/07 13:26:11][INFO] train_net.py:  669: Epoch 10 takes 133.86s. Epochs from 1 to 10 take 133.60s in average and 133.11s in median.
[05/07 13:26:11][INFO] train_net.py:  675: For epoch 10, each iteraction takes 1.69s in average. From epoch 1 to 10, each iteraction takes 1.69s in average.
[05/07 13:26:54][INFO] logging.py:   98: json_stats: {"_type": "val_iter", "cur_epoch": "10/60", "cur_iter": "10", "eta": "0:00:01", "dt": 0.47670, "dt_data": 0.01207, "dt_net": 0.46463, "mode": "val"}
[05/07 13:26:55][INFO] ava_eval_helper.py:  204: Evaluating with 542 unique GT frames.
[05/07 13:26:55][INFO] ava_eval_helper.py:  208: Evaluating with 542 unique detection frames
[05/07 13:26:56][INFO] ava_eval_helper.py:  469: AVA results wrote to detections_latest.csv
[05/07 13:26:56][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 13:26:56][INFO] ava_eval_helper.py:  469: AVA results wrote to groundtruth_latest.csv
[05/07 13:26:56][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 13:26:59][INFO] object_detection_evaluation.py:  751: The following classes have no ground truth examples: [ 2  3  4  5 10 13 15 16 18 19 20 21 23 25 28 31 32 33 35 37 39 40 41 42
 44 49 50 51 52 53 54 55 56 57 63 64 67 68 70 71 72 73 75 77]
[05/07 13:26:59][INFO] ava_eval_helper.py:  298: mAP@0.5 = 0.12371 | macro-F1 = 0.04566 | macro-AUROC = 0.64505 | macro-recall = 0.04301
[05/07 13:26:59][INFO] logging.py:   98: json_stats: {"mode": "val", "cur_epoch": "10", "map": 0.12371, "f1_macro": 0.04566, "auroc_macro": 0.64505, "recall_macro": 0.04301, "gpu_mem": "18.46G", "RAM": "72.01/251.58G", "_type": "val_epoch"}
[05/07 13:26:59][INFO] ava_eval_helper.py:  469: AVA results wrote to /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/detections_val_10.csv
[05/07 13:26:59][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 13:26:59][INFO] meters.py:  327: Saved CSVs:
  per-class AP: /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/ap_per_class_val_10.csv
  detections: /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/detections_val_10.csv
[05/07 13:27:43][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "11/60", "cur_iter": "10", "eta": "0:01:24", "dt": 1.21341, "dt_data": 0.00046, "dt_net": 1.21295, "mode": "train", "loss": 0.20253, "lr": 0.00010}
[05/07 13:27:55][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "11/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.23581, "dt_data": 0.00040, "dt_net": 1.23540, "mode": "train", "loss": 0.21801, "lr": 0.00010}
[05/07 13:28:08][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "11/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.25642, "dt_data": 0.00036, "dt_net": 1.25606, "mode": "train", "loss": 0.22445, "lr": 0.00010}
[05/07 13:28:20][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "11/60", "cur_iter": "40", "eta": "0:00:50", "dt": 1.25886, "dt_data": 0.00053, "dt_net": 1.25833, "mode": "train", "loss": 0.22570, "lr": 0.00010}
[05/07 13:28:33][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "11/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.25977, "dt_data": 0.00028, "dt_net": 1.25949, "mode": "train", "loss": 0.20721, "lr": 0.00010}
[05/07 13:28:46][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "11/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.26400, "dt_data": 0.00042, "dt_net": 1.26358, "mode": "train", "loss": 0.23809, "lr": 0.00010}
[05/07 13:28:58][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "11/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.24436, "dt_data": 0.00022, "dt_net": 1.24414, "mode": "train", "loss": 0.20147, "lr": 0.00010}
[05/07 13:29:10][INFO] train_net.py:  669: Epoch 11 takes 131.69s. Epochs from 1 to 11 take 133.42s in average and 132.88s in median.
[05/07 13:29:10][INFO] train_net.py:  675: For epoch 11, each iteraction takes 1.67s in average. From epoch 1 to 11, each iteraction takes 1.69s in average.
[05/07 13:29:56][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "12/60", "cur_iter": "10", "eta": "0:01:25", "dt": 1.21719, "dt_data": 0.00044, "dt_net": 1.21675, "mode": "train", "loss": 0.22645, "lr": 0.00010}
[05/07 13:30:09][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "12/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.24230, "dt_data": 0.00041, "dt_net": 1.24189, "mode": "train", "loss": 0.21269, "lr": 0.00010}
[05/07 13:30:21][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "12/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.24985, "dt_data": 0.00048, "dt_net": 1.24936, "mode": "train", "loss": 0.23009, "lr": 0.00010}
[05/07 13:30:34][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "12/60", "cur_iter": "40", "eta": "0:00:49", "dt": 1.23229, "dt_data": 0.00040, "dt_net": 1.23188, "mode": "train", "loss": 0.21687, "lr": 0.00010}
[05/07 13:30:46][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "12/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.24172, "dt_data": 0.00050, "dt_net": 1.24122, "mode": "train", "loss": 0.23079, "lr": 0.00010}
[05/07 13:30:59][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "12/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.25241, "dt_data": 0.00049, "dt_net": 1.25192, "mode": "train", "loss": 0.23365, "lr": 0.00010}
[05/07 13:31:11][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "12/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.22215, "dt_data": 0.00023, "dt_net": 1.22192, "mode": "train", "loss": 0.22522, "lr": 0.00010}
[05/07 13:31:23][INFO] train_net.py:  669: Epoch 12 takes 133.05s. Epochs from 1 to 12 take 133.39s in average and 132.97s in median.
[05/07 13:31:23][INFO] train_net.py:  675: For epoch 12, each iteraction takes 1.68s in average. From epoch 1 to 12, each iteraction takes 1.69s in average.
[05/07 13:32:10][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "13/60", "cur_iter": "10", "eta": "0:01:25", "dt": 1.21869, "dt_data": 0.00046, "dt_net": 1.21823, "mode": "train", "loss": 0.20128, "lr": 0.00010}
[05/07 13:32:22][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "13/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.24652, "dt_data": 0.00042, "dt_net": 1.24610, "mode": "train", "loss": 0.18466, "lr": 0.00010}
[05/07 13:32:35][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "13/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.24366, "dt_data": 0.00044, "dt_net": 1.24321, "mode": "train", "loss": 0.21168, "lr": 0.00010}
[05/07 13:32:47][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "13/60", "cur_iter": "40", "eta": "0:00:50", "dt": 1.26048, "dt_data": 0.00045, "dt_net": 1.26003, "mode": "train", "loss": 0.22541, "lr": 0.00010}
[05/07 13:33:00][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "13/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.25906, "dt_data": 0.00040, "dt_net": 1.25866, "mode": "train", "loss": 0.22852, "lr": 0.00010}
[05/07 13:33:12][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "13/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.25505, "dt_data": 0.00055, "dt_net": 1.25450, "mode": "train", "loss": 0.21492, "lr": 0.00010}
[05/07 13:33:25][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "13/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.23644, "dt_data": 0.00024, "dt_net": 1.23620, "mode": "train", "loss": 0.21829, "lr": 0.00010}
[05/07 13:33:37][INFO] train_net.py:  669: Epoch 13 takes 133.45s. Epochs from 1 to 13 take 133.40s in average and 133.05s in median.
[05/07 13:33:37][INFO] train_net.py:  675: For epoch 13, each iteraction takes 1.69s in average. From epoch 1 to 13, each iteraction takes 1.69s in average.
[05/07 13:34:23][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "14/60", "cur_iter": "10", "eta": "0:01:25", "dt": 1.21730, "dt_data": 0.00050, "dt_net": 1.21679, "mode": "train", "loss": 0.22321, "lr": 0.00010}
[05/07 13:34:36][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "14/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.23775, "dt_data": 0.00039, "dt_net": 1.23736, "mode": "train", "loss": 0.23067, "lr": 0.00010}
[05/07 13:34:48][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "14/60", "cur_iter": "30", "eta": "0:01:01", "dt": 1.23742, "dt_data": 0.00045, "dt_net": 1.23696, "mode": "train", "loss": 0.22863, "lr": 0.00010}
[05/07 13:35:00][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "14/60", "cur_iter": "40", "eta": "0:00:50", "dt": 1.25240, "dt_data": 0.00059, "dt_net": 1.25180, "mode": "train", "loss": 0.21979, "lr": 0.00010}
[05/07 13:35:13][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "14/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.25825, "dt_data": 0.00043, "dt_net": 1.25782, "mode": "train", "loss": 0.23573, "lr": 0.00010}
[05/07 13:35:26][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "14/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.25837, "dt_data": 0.00048, "dt_net": 1.25789, "mode": "train", "loss": 0.18610, "lr": 0.00010}
[05/07 13:35:38][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "14/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.25097, "dt_data": 0.00020, "dt_net": 1.25076, "mode": "train", "loss": 0.21568, "lr": 0.00010}
[05/07 13:35:50][INFO] train_net.py:  669: Epoch 14 takes 133.54s. Epochs from 1 to 14 take 133.41s in average and 133.20s in median.
[05/07 13:35:50][INFO] train_net.py:  675: For epoch 14, each iteraction takes 1.69s in average. From epoch 1 to 14, each iteraction takes 1.69s in average.
[05/07 13:36:36][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "15/60", "cur_iter": "10", "eta": "0:01:25", "dt": 1.21506, "dt_data": 0.00054, "dt_net": 1.21451, "mode": "train", "loss": 0.20102, "lr": 0.00010}
[05/07 13:36:49][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "15/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.23573, "dt_data": 0.00045, "dt_net": 1.23528, "mode": "train", "loss": 0.22764, "lr": 0.00010}
[05/07 13:37:01][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "15/60", "cur_iter": "30", "eta": "0:01:01", "dt": 1.23086, "dt_data": 0.00042, "dt_net": 1.23044, "mode": "train", "loss": 0.23896, "lr": 0.00010}
[05/07 13:37:13][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "15/60", "cur_iter": "40", "eta": "0:00:49", "dt": 1.23140, "dt_data": 0.00054, "dt_net": 1.23085, "mode": "train", "loss": 0.21936, "lr": 0.00010}
[05/07 13:37:26][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "15/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.24857, "dt_data": 0.00040, "dt_net": 1.24817, "mode": "train", "loss": 0.18843, "lr": 0.00010}
[05/07 13:37:38][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "15/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.25498, "dt_data": 0.00048, "dt_net": 1.25449, "mode": "train", "loss": 0.21273, "lr": 0.00010}
[05/07 13:37:51][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "15/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.25988, "dt_data": 0.00021, "dt_net": 1.25967, "mode": "train", "loss": 0.22429, "lr": 0.00010}
[05/07 13:38:03][INFO] train_net.py:  669: Epoch 15 takes 132.62s. Epochs from 1 to 15 take 133.36s in average and 133.05s in median.
[05/07 13:38:03][INFO] train_net.py:  675: For epoch 15, each iteraction takes 1.68s in average. From epoch 1 to 15, each iteraction takes 1.69s in average.
[05/07 13:38:45][INFO] logging.py:   98: json_stats: {"_type": "val_iter", "cur_epoch": "15/60", "cur_iter": "10", "eta": "0:00:01", "dt": 0.47603, "dt_data": 0.01206, "dt_net": 0.46397, "mode": "val"}
[05/07 13:38:46][INFO] ava_eval_helper.py:  204: Evaluating with 542 unique GT frames.
[05/07 13:38:46][INFO] ava_eval_helper.py:  208: Evaluating with 542 unique detection frames
[05/07 13:38:46][INFO] ava_eval_helper.py:  469: AVA results wrote to detections_latest.csv
[05/07 13:38:46][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 13:38:46][INFO] ava_eval_helper.py:  469: AVA results wrote to groundtruth_latest.csv
[05/07 13:38:46][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 13:38:49][INFO] object_detection_evaluation.py:  751: The following classes have no ground truth examples: [ 2  3  4  5 10 13 15 16 18 19 20 21 23 25 28 31 32 33 35 37 39 40 41 42
 44 49 50 51 52 53 54 55 56 57 63 64 67 68 70 71 72 73 75 77]
[05/07 13:38:50][INFO] ava_eval_helper.py:  298: mAP@0.5 = 0.14245 | macro-F1 = 0.05237 | macro-AUROC = 0.68810 | macro-recall = 0.04733
[05/07 13:38:50][INFO] logging.py:   98: json_stats: {"mode": "val", "cur_epoch": "15", "map": 0.14245, "f1_macro": 0.05237, "auroc_macro": 0.68810, "recall_macro": 0.04733, "gpu_mem": "18.46G", "RAM": "71.98/251.58G", "_type": "val_epoch"}
[05/07 13:38:50][INFO] ava_eval_helper.py:  469: AVA results wrote to /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/detections_val_15.csv
[05/07 13:38:50][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 13:38:50][INFO] meters.py:  327: Saved CSVs:
  per-class AP: /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/ap_per_class_val_15.csv
  detections: /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/detections_val_15.csv
[05/07 13:39:34][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "16/60", "cur_iter": "10", "eta": "0:01:24", "dt": 1.20399, "dt_data": 0.00058, "dt_net": 1.20340, "mode": "train", "loss": 0.21777, "lr": 0.00010}
[05/07 13:39:46][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "16/60", "cur_iter": "20", "eta": "0:01:13", "dt": 1.23177, "dt_data": 0.00029, "dt_net": 1.23147, "mode": "train", "loss": 0.21107, "lr": 0.00010}
[05/07 13:39:58][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "16/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.24165, "dt_data": 0.00042, "dt_net": 1.24123, "mode": "train", "loss": 0.21706, "lr": 0.00010}
[05/07 13:40:11][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "16/60", "cur_iter": "40", "eta": "0:00:49", "dt": 1.23563, "dt_data": 0.00054, "dt_net": 1.23508, "mode": "train", "loss": 0.22491, "lr": 0.00010}
[05/07 13:40:23][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "16/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.24881, "dt_data": 0.00039, "dt_net": 1.24842, "mode": "train", "loss": 0.21106, "lr": 0.00010}
[05/07 13:40:36][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "16/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.25112, "dt_data": 0.00038, "dt_net": 1.25074, "mode": "train", "loss": 0.19008, "lr": 0.00010}
[05/07 13:40:48][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "16/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.25560, "dt_data": 0.00021, "dt_net": 1.25539, "mode": "train", "loss": 0.19603, "lr": 0.00010}
[05/07 13:41:00][INFO] train_net.py:  669: Epoch 16 takes 130.79s. Epochs from 1 to 16 take 133.20s in average and 132.97s in median.
[05/07 13:41:00][INFO] train_net.py:  675: For epoch 16, each iteraction takes 1.66s in average. From epoch 1 to 16, each iteraction takes 1.69s in average.
[05/07 13:41:46][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "17/60", "cur_iter": "10", "eta": "0:01:25", "dt": 1.21599, "dt_data": 0.00031, "dt_net": 1.21567, "mode": "train", "loss": 0.21109, "lr": 0.00010}
[05/07 13:41:58][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "17/60", "cur_iter": "20", "eta": "0:01:13", "dt": 1.22670, "dt_data": 0.00039, "dt_net": 1.22631, "mode": "train", "loss": 0.20581, "lr": 0.00010}
[05/07 13:42:11][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "17/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.24404, "dt_data": 0.00039, "dt_net": 1.24365, "mode": "train", "loss": 0.21123, "lr": 0.00010}
[05/07 13:42:23][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "17/60", "cur_iter": "40", "eta": "0:00:49", "dt": 1.23064, "dt_data": 0.00039, "dt_net": 1.23025, "mode": "train", "loss": 0.18986, "lr": 0.00010}
[05/07 13:42:36][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "17/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.25507, "dt_data": 0.00060, "dt_net": 1.25446, "mode": "train", "loss": 0.21199, "lr": 0.00010}
[05/07 13:42:49][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "17/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.25891, "dt_data": 0.00047, "dt_net": 1.25844, "mode": "train", "loss": 0.21176, "lr": 0.00010}
[05/07 13:43:01][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "17/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.25753, "dt_data": 0.00025, "dt_net": 1.25728, "mode": "train", "loss": 0.19435, "lr": 0.00010}
[05/07 13:43:14][INFO] train_net.py:  669: Epoch 17 takes 133.17s. Epochs from 1 to 17 take 133.19s in average and 133.05s in median.
[05/07 13:43:14][INFO] train_net.py:  675: For epoch 17, each iteraction takes 1.69s in average. From epoch 1 to 17, each iteraction takes 1.69s in average.
[05/07 13:44:00][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "18/60", "cur_iter": "10", "eta": "0:01:25", "dt": 1.22601, "dt_data": 0.00039, "dt_net": 1.22561, "mode": "train", "loss": 0.23194, "lr": 0.00010}
[05/07 13:44:12][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "18/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.23783, "dt_data": 0.00036, "dt_net": 1.23747, "mode": "train", "loss": 0.21850, "lr": 0.00010}
[05/07 13:44:24][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "18/60", "cur_iter": "30", "eta": "0:01:01", "dt": 1.23996, "dt_data": 0.00036, "dt_net": 1.23959, "mode": "train", "loss": 0.22433, "lr": 0.00010}
[05/07 13:44:37][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "18/60", "cur_iter": "40", "eta": "0:00:50", "dt": 1.25746, "dt_data": 0.00038, "dt_net": 1.25708, "mode": "train", "loss": 0.20055, "lr": 0.00010}
[05/07 13:44:50][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "18/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.25786, "dt_data": 0.00051, "dt_net": 1.25734, "mode": "train", "loss": 0.20920, "lr": 0.00010}
[05/07 13:45:02][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "18/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.25708, "dt_data": 0.00079, "dt_net": 1.25629, "mode": "train", "loss": 0.23262, "lr": 0.00010}
[05/07 13:45:15][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "18/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.25901, "dt_data": 0.00036, "dt_net": 1.25865, "mode": "train", "loss": 0.18238, "lr": 0.00010}
[05/07 13:45:27][INFO] train_net.py:  669: Epoch 18 takes 133.70s. Epochs from 1 to 18 take 133.22s in average and 133.11s in median.
[05/07 13:45:27][INFO] train_net.py:  675: For epoch 18, each iteraction takes 1.69s in average. From epoch 1 to 18, each iteraction takes 1.69s in average.
[05/07 13:46:14][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "19/60", "cur_iter": "10", "eta": "0:01:25", "dt": 1.22463, "dt_data": 0.00042, "dt_net": 1.22420, "mode": "train", "loss": 0.19531, "lr": 0.00010}
[05/07 13:46:26][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "19/60", "cur_iter": "20", "eta": "0:01:13", "dt": 1.22494, "dt_data": 0.00040, "dt_net": 1.22453, "mode": "train", "loss": 0.20814, "lr": 0.00010}
[05/07 13:46:38][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "19/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.24329, "dt_data": 0.00040, "dt_net": 1.24289, "mode": "train", "loss": 0.20332, "lr": 0.00010}
[05/07 13:46:51][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "19/60", "cur_iter": "40", "eta": "0:00:50", "dt": 1.25630, "dt_data": 0.00041, "dt_net": 1.25588, "mode": "train", "loss": 0.18588, "lr": 0.00010}
[05/07 13:47:04][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "19/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.26173, "dt_data": 0.00042, "dt_net": 1.26130, "mode": "train", "loss": 0.18521, "lr": 0.00010}
[05/07 13:47:16][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "19/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.25354, "dt_data": 0.00052, "dt_net": 1.25302, "mode": "train", "loss": 0.23495, "lr": 0.00010}
[05/07 13:47:29][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "19/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.25567, "dt_data": 0.00023, "dt_net": 1.25544, "mode": "train", "loss": 0.20524, "lr": 0.00010}
[05/07 13:47:41][INFO] train_net.py:  669: Epoch 19 takes 133.92s. Epochs from 1 to 19 take 133.26s in average and 133.17s in median.
[05/07 13:47:41][INFO] train_net.py:  675: For epoch 19, each iteraction takes 1.70s in average. From epoch 1 to 19, each iteraction takes 1.69s in average.
[05/07 13:48:39][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "20/60", "cur_iter": "10", "eta": "0:01:24", "dt": 1.21336, "dt_data": 0.00042, "dt_net": 1.21294, "mode": "train", "loss": 0.21621, "lr": 0.00010}
[05/07 13:48:51][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "20/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.23539, "dt_data": 0.00046, "dt_net": 1.23493, "mode": "train", "loss": 0.21616, "lr": 0.00010}
[05/07 13:49:04][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "20/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.24041, "dt_data": 0.00039, "dt_net": 1.24001, "mode": "train", "loss": 0.21791, "lr": 0.00010}
[05/07 13:49:16][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "20/60", "cur_iter": "40", "eta": "0:00:49", "dt": 1.23697, "dt_data": 0.00039, "dt_net": 1.23658, "mode": "train", "loss": 0.21561, "lr": 0.00010}
[05/07 13:49:28][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "20/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.23381, "dt_data": 0.00038, "dt_net": 1.23343, "mode": "train", "loss": 0.20931, "lr": 0.00010}
[05/07 13:49:41][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "20/60", "cur_iter": "60", "eta": "0:00:24", "dt": 1.23556, "dt_data": 0.00051, "dt_net": 1.23505, "mode": "train", "loss": 0.21133, "lr": 0.00010}
[05/07 13:49:53][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "20/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.24779, "dt_data": 0.00025, "dt_net": 1.24753, "mode": "train", "loss": 0.18284, "lr": 0.00010}
[05/07 13:50:06][INFO] train_net.py:  669: Epoch 20 takes 144.29s. Epochs from 1 to 20 take 133.81s in average and 133.26s in median.
[05/07 13:50:06][INFO] train_net.py:  675: For epoch 20, each iteraction takes 1.83s in average. From epoch 1 to 20, each iteraction takes 1.69s in average.
[05/07 13:50:44][INFO] logging.py:   98: json_stats: {"_type": "val_iter", "cur_epoch": "20/60", "cur_iter": "10", "eta": "0:00:01", "dt": 0.47439, "dt_data": 0.01199, "dt_net": 0.46239, "mode": "val"}
[05/07 13:50:45][INFO] ava_eval_helper.py:  204: Evaluating with 542 unique GT frames.
[05/07 13:50:45][INFO] ava_eval_helper.py:  208: Evaluating with 542 unique detection frames
[05/07 13:50:46][INFO] ava_eval_helper.py:  469: AVA results wrote to detections_latest.csv
[05/07 13:50:46][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 13:50:46][INFO] ava_eval_helper.py:  469: AVA results wrote to groundtruth_latest.csv
[05/07 13:50:46][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 13:50:49][INFO] object_detection_evaluation.py:  751: The following classes have no ground truth examples: [ 2  3  4  5 10 13 15 16 18 19 20 21 23 25 28 31 32 33 35 37 39 40 41 42
 44 49 50 51 52 53 54 55 56 57 63 64 67 68 70 71 72 73 75 77]
[05/07 13:50:49][INFO] ava_eval_helper.py:  298: mAP@0.5 = 0.17118 | macro-F1 = 0.07013 | macro-AUROC = 0.71996 | macro-recall = 0.05775
[05/07 13:50:49][INFO] logging.py:   98: json_stats: {"mode": "val", "cur_epoch": "20", "map": 0.17118, "f1_macro": 0.07013, "auroc_macro": 0.71996, "recall_macro": 0.05775, "gpu_mem": "18.47G", "RAM": "72.18/251.58G", "_type": "val_epoch"}
[05/07 13:50:49][INFO] ava_eval_helper.py:  469: AVA results wrote to /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/detections_val_20.csv
[05/07 13:50:49][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 13:50:49][INFO] meters.py:  327: Saved CSVs:
  per-class AP: /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/ap_per_class_val_20.csv
  detections: /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/detections_val_20.csv
[05/07 13:51:33][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "21/60", "cur_iter": "10", "eta": "0:01:24", "dt": 1.20880, "dt_data": 0.00038, "dt_net": 1.20842, "mode": "train", "loss": 0.22354, "lr": 0.00001}
[05/07 13:51:45][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "21/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.23396, "dt_data": 0.00060, "dt_net": 1.23336, "mode": "train", "loss": 0.21678, "lr": 0.00001}
[05/07 13:51:58][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "21/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.25810, "dt_data": 0.00043, "dt_net": 1.25767, "mode": "train", "loss": 0.21622, "lr": 0.00001}
[05/07 13:52:10][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "21/60", "cur_iter": "40", "eta": "0:00:49", "dt": 1.24457, "dt_data": 0.00039, "dt_net": 1.24418, "mode": "train", "loss": 0.20427, "lr": 0.00001}
[05/07 13:52:22][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "21/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.24670, "dt_data": 0.00047, "dt_net": 1.24623, "mode": "train", "loss": 0.18522, "lr": 0.00001}
[05/07 13:52:35][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "21/60", "cur_iter": "60", "eta": "0:00:24", "dt": 1.24699, "dt_data": 0.00047, "dt_net": 1.24651, "mode": "train", "loss": 0.20101, "lr": 0.00001}
[05/07 13:52:47][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "21/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.24306, "dt_data": 0.00024, "dt_net": 1.24282, "mode": "train", "loss": 0.20197, "lr": 0.00001}
[05/07 13:53:00][INFO] train_net.py:  669: Epoch 21 takes 131.15s. Epochs from 1 to 21 take 133.68s in average and 133.17s in median.
[05/07 13:53:00][INFO] train_net.py:  675: For epoch 21, each iteraction takes 1.66s in average. From epoch 1 to 21, each iteraction takes 1.69s in average.
[05/07 13:53:45][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "22/60", "cur_iter": "10", "eta": "0:01:25", "dt": 1.21700, "dt_data": 0.00040, "dt_net": 1.21660, "mode": "train", "loss": 0.20780, "lr": 0.00001}
[05/07 13:53:57][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "22/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.24200, "dt_data": 0.00042, "dt_net": 1.24157, "mode": "train", "loss": 0.20826, "lr": 0.00001}
[05/07 13:54:09][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "22/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.25070, "dt_data": 0.00069, "dt_net": 1.25000, "mode": "train", "loss": 0.20374, "lr": 0.00001}
[05/07 13:54:22][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "22/60", "cur_iter": "40", "eta": "0:00:50", "dt": 1.25383, "dt_data": 0.00041, "dt_net": 1.25341, "mode": "train", "loss": 0.19779, "lr": 0.00001}
[05/07 13:54:34][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "22/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.25622, "dt_data": 0.00050, "dt_net": 1.25572, "mode": "train", "loss": 0.23099, "lr": 0.00001}
[05/07 13:54:47][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "22/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.25187, "dt_data": 0.00046, "dt_net": 1.25141, "mode": "train", "loss": 0.21246, "lr": 0.00001}
[05/07 13:54:59][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "22/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.25771, "dt_data": 0.00023, "dt_net": 1.25747, "mode": "train", "loss": 0.18584, "lr": 0.00001}
[05/07 13:55:12][INFO] train_net.py:  669: Epoch 22 takes 132.03s. Epochs from 1 to 22 take 133.61s in average and 133.11s in median.
[05/07 13:55:12][INFO] train_net.py:  675: For epoch 22, each iteraction takes 1.67s in average. From epoch 1 to 22, each iteraction takes 1.69s in average.
[05/07 13:55:56][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "23/60", "cur_iter": "10", "eta": "0:01:25", "dt": 1.21854, "dt_data": 0.00057, "dt_net": 1.21797, "mode": "train", "loss": 0.22894, "lr": 0.00001}
[05/07 13:56:09][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "23/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.23570, "dt_data": 0.00040, "dt_net": 1.23530, "mode": "train", "loss": 0.19636, "lr": 0.00001}
[05/07 13:56:21][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "23/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.24570, "dt_data": 0.00034, "dt_net": 1.24536, "mode": "train", "loss": 0.19704, "lr": 0.00001}
[05/07 13:56:34][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "23/60", "cur_iter": "40", "eta": "0:00:50", "dt": 1.25781, "dt_data": 0.00040, "dt_net": 1.25741, "mode": "train", "loss": 0.20580, "lr": 0.00001}
[05/07 13:56:46][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "23/60", "cur_iter": "50", "eta": "0:00:36", "dt": 1.23146, "dt_data": 0.00036, "dt_net": 1.23109, "mode": "train", "loss": 0.16372, "lr": 0.00001}
[05/07 13:56:59][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "23/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.26011, "dt_data": 0.00046, "dt_net": 1.25965, "mode": "train", "loss": 0.20561, "lr": 0.00001}
[05/07 13:57:11][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "23/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.25601, "dt_data": 0.00025, "dt_net": 1.25576, "mode": "train", "loss": 0.19116, "lr": 0.00001}
[05/07 13:57:24][INFO] train_net.py:  669: Epoch 23 takes 131.92s. Epochs from 1 to 23 take 133.54s in average and 133.05s in median.
[05/07 13:57:24][INFO] train_net.py:  675: For epoch 23, each iteraction takes 1.67s in average. From epoch 1 to 23, each iteraction takes 1.69s in average.
[05/07 13:58:10][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "24/60", "cur_iter": "10", "eta": "0:01:25", "dt": 1.21844, "dt_data": 0.00045, "dt_net": 1.21799, "mode": "train", "loss": 0.20633, "lr": 0.00001}
[05/07 13:58:22][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "24/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.23858, "dt_data": 0.00043, "dt_net": 1.23814, "mode": "train", "loss": 0.20387, "lr": 0.00001}
[05/07 13:58:35][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "24/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.24979, "dt_data": 0.00048, "dt_net": 1.24931, "mode": "train", "loss": 0.21207, "lr": 0.00001}
[05/07 13:58:47][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "24/60", "cur_iter": "40", "eta": "0:00:50", "dt": 1.25031, "dt_data": 0.00040, "dt_net": 1.24991, "mode": "train", "loss": 0.18784, "lr": 0.00001}
[05/07 13:59:00][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "24/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.26233, "dt_data": 0.00053, "dt_net": 1.26180, "mode": "train", "loss": 0.20013, "lr": 0.00001}
[05/07 13:59:13][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "24/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.25995, "dt_data": 0.00044, "dt_net": 1.25951, "mode": "train", "loss": 0.18285, "lr": 0.00001}
[05/07 13:59:25][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "24/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.25467, "dt_data": 0.00024, "dt_net": 1.25443, "mode": "train", "loss": 0.18386, "lr": 0.00001}
[05/07 13:59:38][INFO] train_net.py:  669: Epoch 24 takes 133.73s. Epochs from 1 to 24 take 133.54s in average and 133.11s in median.
[05/07 13:59:38][INFO] train_net.py:  675: For epoch 24, each iteraction takes 1.69s in average. From epoch 1 to 24, each iteraction takes 1.69s in average.
[05/07 14:00:23][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "25/60", "cur_iter": "10", "eta": "0:01:25", "dt": 1.21688, "dt_data": 0.00040, "dt_net": 1.21649, "mode": "train", "loss": 0.20900, "lr": 0.00001}
[05/07 14:00:36][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "25/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.24582, "dt_data": 0.00040, "dt_net": 1.24542, "mode": "train", "loss": 0.20531, "lr": 0.00001}
[05/07 14:00:48][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "25/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.24673, "dt_data": 0.00038, "dt_net": 1.24635, "mode": "train", "loss": 0.19831, "lr": 0.00001}
[05/07 14:01:01][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "25/60", "cur_iter": "40", "eta": "0:00:50", "dt": 1.26514, "dt_data": 0.00047, "dt_net": 1.26467, "mode": "train", "loss": 0.16076, "lr": 0.00001}
[05/07 14:01:13][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "25/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.25974, "dt_data": 0.00060, "dt_net": 1.25914, "mode": "train", "loss": 0.19856, "lr": 0.00001}
[05/07 14:01:26][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "25/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.25065, "dt_data": 0.00052, "dt_net": 1.25012, "mode": "train", "loss": 0.21270, "lr": 0.00001}
[05/07 14:01:39][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "25/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.25973, "dt_data": 0.00023, "dt_net": 1.25950, "mode": "train", "loss": 0.20073, "lr": 0.00001}
[05/07 14:01:51][INFO] train_net.py:  669: Epoch 25 takes 133.58s. Epochs from 1 to 25 take 133.54s in average and 133.17s in median.
[05/07 14:01:51][INFO] train_net.py:  675: For epoch 25, each iteraction takes 1.69s in average. From epoch 1 to 25, each iteraction takes 1.69s in average.
[05/07 14:02:30][INFO] logging.py:   98: json_stats: {"_type": "val_iter", "cur_epoch": "25/60", "cur_iter": "10", "eta": "0:00:01", "dt": 0.47556, "dt_data": 0.01209, "dt_net": 0.46347, "mode": "val"}
[05/07 14:02:32][INFO] ava_eval_helper.py:  204: Evaluating with 542 unique GT frames.
[05/07 14:02:32][INFO] ava_eval_helper.py:  208: Evaluating with 542 unique detection frames
[05/07 14:02:32][INFO] ava_eval_helper.py:  469: AVA results wrote to detections_latest.csv
[05/07 14:02:32][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 14:02:32][INFO] ava_eval_helper.py:  469: AVA results wrote to groundtruth_latest.csv
[05/07 14:02:32][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 14:02:35][INFO] object_detection_evaluation.py:  751: The following classes have no ground truth examples: [ 2  3  4  5 10 13 15 16 18 19 20 21 23 25 28 31 32 33 35 37 39 40 41 42
 44 49 50 51 52 53 54 55 56 57 63 64 67 68 70 71 72 73 75 77]
[05/07 14:02:35][INFO] ava_eval_helper.py:  298: mAP@0.5 = 0.17542 | macro-F1 = 0.07813 | macro-AUROC = 0.72500 | macro-recall = 0.06463
[05/07 14:02:35][INFO] logging.py:   98: json_stats: {"mode": "val", "cur_epoch": "25", "map": 0.17542, "f1_macro": 0.07813, "auroc_macro": 0.72500, "recall_macro": 0.06463, "gpu_mem": "18.47G", "RAM": "72.16/251.58G", "_type": "val_epoch"}
[05/07 14:02:35][INFO] ava_eval_helper.py:  469: AVA results wrote to /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/detections_val_25.csv
[05/07 14:02:35][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 14:02:35][INFO] meters.py:  327: Saved CSVs:
  per-class AP: /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/ap_per_class_val_25.csv
  detections: /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/detections_val_25.csv
[05/07 14:03:19][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "26/60", "cur_iter": "10", "eta": "0:01:25", "dt": 1.22352, "dt_data": 0.00037, "dt_net": 1.22315, "mode": "train", "loss": 0.21690, "lr": 0.00001}
[05/07 14:03:31][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "26/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.23529, "dt_data": 0.00036, "dt_net": 1.23492, "mode": "train", "loss": 0.21629, "lr": 0.00001}
[05/07 14:03:43][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "26/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.24375, "dt_data": 0.00039, "dt_net": 1.24337, "mode": "train", "loss": 0.19963, "lr": 0.00001}
[05/07 14:03:56][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "26/60", "cur_iter": "40", "eta": "0:00:50", "dt": 1.25727, "dt_data": 0.00046, "dt_net": 1.25680, "mode": "train", "loss": 0.19096, "lr": 0.00001}
[05/07 14:04:09][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "26/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.25499, "dt_data": 0.00039, "dt_net": 1.25460, "mode": "train", "loss": 0.17643, "lr": 0.00001}
[05/07 14:04:21][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "26/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.25684, "dt_data": 0.00041, "dt_net": 1.25643, "mode": "train", "loss": 0.19959, "lr": 0.00001}
[05/07 14:04:34][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "26/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.25444, "dt_data": 0.00021, "dt_net": 1.25423, "mode": "train", "loss": 0.19201, "lr": 0.00001}
[05/07 14:04:46][INFO] train_net.py:  669: Epoch 26 takes 131.17s. Epochs from 1 to 26 take 133.45s in average and 133.11s in median.
[05/07 14:04:46][INFO] train_net.py:  675: For epoch 26, each iteraction takes 1.66s in average. From epoch 1 to 26, each iteraction takes 1.69s in average.
[05/07 14:05:33][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "27/60", "cur_iter": "10", "eta": "0:01:25", "dt": 1.22180, "dt_data": 0.00034, "dt_net": 1.22146, "mode": "train", "loss": 0.19855, "lr": 0.00001}
[05/07 14:05:45][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "27/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.24323, "dt_data": 0.00039, "dt_net": 1.24283, "mode": "train", "loss": 0.19561, "lr": 0.00001}
[05/07 14:05:57][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "27/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.25365, "dt_data": 0.00037, "dt_net": 1.25328, "mode": "train", "loss": 0.19504, "lr": 0.00001}
[05/07 14:06:10][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "27/60", "cur_iter": "40", "eta": "0:00:49", "dt": 1.23871, "dt_data": 0.00040, "dt_net": 1.23831, "mode": "train", "loss": 0.18952, "lr": 0.00001}
[05/07 14:06:22][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "27/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.26119, "dt_data": 0.00040, "dt_net": 1.26079, "mode": "train", "loss": 0.17664, "lr": 0.00001}
[05/07 14:06:35][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "27/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.25922, "dt_data": 0.00041, "dt_net": 1.25881, "mode": "train", "loss": 0.19071, "lr": 0.00001}
[05/07 14:06:48][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "27/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.25115, "dt_data": 0.00021, "dt_net": 1.25094, "mode": "train", "loss": 0.17663, "lr": 0.00001}
[05/07 14:07:00][INFO] train_net.py:  669: Epoch 27 takes 133.94s. Epochs from 1 to 27 take 133.47s in average and 133.17s in median.
[05/07 14:07:00][INFO] train_net.py:  675: For epoch 27, each iteraction takes 1.70s in average. From epoch 1 to 27, each iteraction takes 1.69s in average.
[05/07 14:07:57][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "28/60", "cur_iter": "10", "eta": "0:01:24", "dt": 1.20358, "dt_data": 0.00040, "dt_net": 1.20319, "mode": "train", "loss": 0.19807, "lr": 0.00001}
[05/07 14:08:09][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "28/60", "cur_iter": "20", "eta": "0:01:13", "dt": 1.23161, "dt_data": 0.00038, "dt_net": 1.23123, "mode": "train", "loss": 0.18604, "lr": 0.00001}
[05/07 14:08:22][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "28/60", "cur_iter": "30", "eta": "0:01:01", "dt": 1.23760, "dt_data": 0.00035, "dt_net": 1.23726, "mode": "train", "loss": 0.19779, "lr": 0.00001}
[05/07 14:08:34][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "28/60", "cur_iter": "40", "eta": "0:00:49", "dt": 1.23458, "dt_data": 0.00038, "dt_net": 1.23419, "mode": "train", "loss": 0.20241, "lr": 0.00001}
[05/07 14:08:46][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "28/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.25915, "dt_data": 0.00050, "dt_net": 1.25865, "mode": "train", "loss": 0.18991, "lr": 0.00001}
[05/07 14:08:59][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "28/60", "cur_iter": "60", "eta": "0:00:24", "dt": 1.23886, "dt_data": 0.00044, "dt_net": 1.23842, "mode": "train", "loss": 0.18192, "lr": 0.00001}
[05/07 14:09:11][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "28/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.22736, "dt_data": 0.00021, "dt_net": 1.22715, "mode": "train", "loss": 0.19272, "lr": 0.00001}
[05/07 14:09:24][INFO] train_net.py:  669: Epoch 28 takes 143.47s. Epochs from 1 to 28 take 133.83s in average and 133.26s in median.
[05/07 14:09:24][INFO] train_net.py:  675: For epoch 28, each iteraction takes 1.82s in average. From epoch 1 to 28, each iteraction takes 1.69s in average.
[05/07 14:10:11][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "29/60", "cur_iter": "10", "eta": "0:01:24", "dt": 1.21311, "dt_data": 0.00035, "dt_net": 1.21275, "mode": "train", "loss": 0.20490, "lr": 0.00001}
[05/07 14:10:23][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "29/60", "cur_iter": "20", "eta": "0:01:13", "dt": 1.23323, "dt_data": 0.00040, "dt_net": 1.23283, "mode": "train", "loss": 0.21034, "lr": 0.00001}
[05/07 14:10:35][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "29/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.25983, "dt_data": 0.00033, "dt_net": 1.25950, "mode": "train", "loss": 0.21179, "lr": 0.00001}
[05/07 14:10:48][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "29/60", "cur_iter": "40", "eta": "0:00:49", "dt": 1.24123, "dt_data": 0.00040, "dt_net": 1.24083, "mode": "train", "loss": 0.17795, "lr": 0.00001}
[05/07 14:11:00][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "29/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.25439, "dt_data": 0.00044, "dt_net": 1.25395, "mode": "train", "loss": 0.20655, "lr": 0.00001}
[05/07 14:11:13][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "29/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.27216, "dt_data": 0.00045, "dt_net": 1.27170, "mode": "train", "loss": 0.20591, "lr": 0.00001}
[05/07 14:11:25][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "29/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.25166, "dt_data": 0.00023, "dt_net": 1.25143, "mode": "train", "loss": 0.18867, "lr": 0.00001}
[05/07 14:11:38][INFO] train_net.py:  669: Epoch 29 takes 134.27s. Epochs from 1 to 29 take 133.84s in average and 133.34s in median.
[05/07 14:11:38][INFO] train_net.py:  675: For epoch 29, each iteraction takes 1.70s in average. From epoch 1 to 29, each iteraction takes 1.69s in average.
[05/07 14:12:23][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "30/60", "cur_iter": "10", "eta": "0:01:25", "dt": 1.22161, "dt_data": 0.00063, "dt_net": 1.22098, "mode": "train", "loss": 0.17930, "lr": 0.00001}
[05/07 14:12:36][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "30/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.23822, "dt_data": 0.00033, "dt_net": 1.23789, "mode": "train", "loss": 0.17818, "lr": 0.00001}
[05/07 14:12:48][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "30/60", "cur_iter": "30", "eta": "0:01:00", "dt": 1.21723, "dt_data": 0.00044, "dt_net": 1.21678, "mode": "train", "loss": 0.19291, "lr": 0.00001}
[05/07 14:13:01][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "30/60", "cur_iter": "40", "eta": "0:00:49", "dt": 1.23348, "dt_data": 0.00041, "dt_net": 1.23307, "mode": "train", "loss": 0.21117, "lr": 0.00001}
[05/07 14:13:13][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "30/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.24196, "dt_data": 0.00039, "dt_net": 1.24156, "mode": "train", "loss": 0.19042, "lr": 0.00001}
[05/07 14:13:26][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "30/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.26083, "dt_data": 0.00047, "dt_net": 1.26036, "mode": "train", "loss": 0.17981, "lr": 0.00001}
[05/07 14:13:38][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "30/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.25143, "dt_data": 0.00021, "dt_net": 1.25122, "mode": "train", "loss": 0.20549, "lr": 0.00001}
[05/07 14:13:51][INFO] train_net.py:  669: Epoch 30 takes 132.68s. Epochs from 1 to 30 take 133.81s in average and 133.26s in median.
[05/07 14:13:51][INFO] train_net.py:  675: For epoch 30, each iteraction takes 1.68s in average. From epoch 1 to 30, each iteraction takes 1.69s in average.
[05/07 14:14:31][INFO] logging.py:   98: json_stats: {"_type": "val_iter", "cur_epoch": "30/60", "cur_iter": "10", "eta": "0:00:01", "dt": 0.47620, "dt_data": 0.01202, "dt_net": 0.46418, "mode": "val"}
[05/07 14:14:32][INFO] ava_eval_helper.py:  204: Evaluating with 542 unique GT frames.
[05/07 14:14:32][INFO] ava_eval_helper.py:  208: Evaluating with 542 unique detection frames
[05/07 14:14:33][INFO] ava_eval_helper.py:  469: AVA results wrote to detections_latest.csv
[05/07 14:14:33][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 14:14:33][INFO] ava_eval_helper.py:  469: AVA results wrote to groundtruth_latest.csv
[05/07 14:14:33][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 14:14:36][INFO] object_detection_evaluation.py:  751: The following classes have no ground truth examples: [ 2  3  4  5 10 13 15 16 18 19 20 21 23 25 28 31 32 33 35 37 39 40 41 42
 44 49 50 51 52 53 54 55 56 57 63 64 67 68 70 71 72 73 75 77]
[05/07 14:14:36][INFO] ava_eval_helper.py:  298: mAP@0.5 = 0.17476 | macro-F1 = 0.08466 | macro-AUROC = 0.72675 | macro-recall = 0.06999
[05/07 14:14:36][INFO] logging.py:   98: json_stats: {"mode": "val", "cur_epoch": "30", "map": 0.17476, "f1_macro": 0.08466, "auroc_macro": 0.72675, "recall_macro": 0.06999, "gpu_mem": "18.47G", "RAM": "72.77/251.58G", "_type": "val_epoch"}
[05/07 14:14:36][INFO] ava_eval_helper.py:  469: AVA results wrote to /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/detections_val_30.csv
[05/07 14:14:36][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 14:14:36][INFO] meters.py:  327: Saved CSVs:
  per-class AP: /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/ap_per_class_val_30.csv
  detections: /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/detections_val_30.csv
[05/07 14:15:19][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "31/60", "cur_iter": "10", "eta": "0:01:24", "dt": 1.20807, "dt_data": 0.00050, "dt_net": 1.20757, "mode": "train", "loss": 0.19460, "lr": 0.00000}
[05/07 14:15:32][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "31/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.23860, "dt_data": 0.00040, "dt_net": 1.23820, "mode": "train", "loss": 0.18224, "lr": 0.00000}
[05/07 14:15:44][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "31/60", "cur_iter": "30", "eta": "0:01:01", "dt": 1.23614, "dt_data": 0.00040, "dt_net": 1.23574, "mode": "train", "loss": 0.18138, "lr": 0.00000}
[05/07 14:15:57][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "31/60", "cur_iter": "40", "eta": "0:00:50", "dt": 1.25006, "dt_data": 0.00034, "dt_net": 1.24972, "mode": "train", "loss": 0.20536, "lr": 0.00000}
[05/07 14:16:09][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "31/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.24692, "dt_data": 0.00047, "dt_net": 1.24644, "mode": "train", "loss": 0.19265, "lr": 0.00000}
[05/07 14:16:22][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "31/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.25636, "dt_data": 0.00041, "dt_net": 1.25595, "mode": "train", "loss": 0.21803, "lr": 0.00000}
[05/07 14:16:34][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "31/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.25555, "dt_data": 0.00022, "dt_net": 1.25533, "mode": "train", "loss": 0.17521, "lr": 0.00000}
[05/07 14:16:47][INFO] train_net.py:  669: Epoch 31 takes 130.97s. Epochs from 1 to 31 take 133.71s in average and 133.17s in median.
[05/07 14:16:47][INFO] train_net.py:  675: For epoch 31, each iteraction takes 1.66s in average. From epoch 1 to 31, each iteraction takes 1.69s in average.
[05/07 14:17:33][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "32/60", "cur_iter": "10", "eta": "0:01:25", "dt": 1.21510, "dt_data": 0.00046, "dt_net": 1.21464, "mode": "train", "loss": 0.18125, "lr": 0.00000}
[05/07 14:17:45][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "32/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.24630, "dt_data": 0.00052, "dt_net": 1.24578, "mode": "train", "loss": 0.20606, "lr": 0.00000}
[05/07 14:17:57][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "32/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.25451, "dt_data": 0.00063, "dt_net": 1.25387, "mode": "train", "loss": 0.16700, "lr": 0.00000}
[05/07 14:18:10][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "32/60", "cur_iter": "40", "eta": "0:00:50", "dt": 1.25070, "dt_data": 0.00040, "dt_net": 1.25030, "mode": "train", "loss": 0.16197, "lr": 0.00000}
[05/07 14:18:23][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "32/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.25955, "dt_data": 0.00042, "dt_net": 1.25912, "mode": "train", "loss": 0.21309, "lr": 0.00000}
[05/07 14:18:35][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "32/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.26470, "dt_data": 0.00051, "dt_net": 1.26419, "mode": "train", "loss": 0.19778, "lr": 0.00000}
[05/07 14:18:48][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "32/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.25593, "dt_data": 0.00022, "dt_net": 1.25571, "mode": "train", "loss": 0.20640, "lr": 0.00000}
[05/07 14:19:00][INFO] train_net.py:  669: Epoch 32 takes 133.51s. Epochs from 1 to 32 take 133.71s in average and 133.26s in median.
[05/07 14:19:00][INFO] train_net.py:  675: For epoch 32, each iteraction takes 1.69s in average. From epoch 1 to 32, each iteraction takes 1.69s in average.
[05/07 14:19:47][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "33/60", "cur_iter": "10", "eta": "0:01:25", "dt": 1.22060, "dt_data": 0.00047, "dt_net": 1.22013, "mode": "train", "loss": 0.18428, "lr": 0.00000}
[05/07 14:19:59][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "33/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.24273, "dt_data": 0.00043, "dt_net": 1.24230, "mode": "train", "loss": 0.21761, "lr": 0.00000}
[05/07 14:20:11][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "33/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.24943, "dt_data": 0.00080, "dt_net": 1.24863, "mode": "train", "loss": 0.19556, "lr": 0.00000}
[05/07 14:20:24][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "33/60", "cur_iter": "40", "eta": "0:00:51", "dt": 1.27504, "dt_data": 0.00039, "dt_net": 1.27465, "mode": "train", "loss": 0.19206, "lr": 0.00000}
[05/07 14:20:37][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "33/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.26349, "dt_data": 0.00046, "dt_net": 1.26304, "mode": "train", "loss": 0.18471, "lr": 0.00000}
[05/07 14:20:49][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "33/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.25329, "dt_data": 0.00050, "dt_net": 1.25278, "mode": "train", "loss": 0.19330, "lr": 0.00000}
[05/07 14:21:02][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "33/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.25514, "dt_data": 0.00024, "dt_net": 1.25489, "mode": "train", "loss": 0.18690, "lr": 0.00000}
[05/07 14:21:14][INFO] train_net.py:  669: Epoch 33 takes 134.07s. Epochs from 1 to 33 take 133.72s in average and 133.34s in median.
[05/07 14:21:14][INFO] train_net.py:  675: For epoch 33, each iteraction takes 1.70s in average. From epoch 1 to 33, each iteraction takes 1.69s in average.
[05/07 14:22:02][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "34/60", "cur_iter": "10", "eta": "0:01:25", "dt": 1.22305, "dt_data": 0.00032, "dt_net": 1.22273, "mode": "train", "loss": 0.18678, "lr": 0.00000}
[05/07 14:22:14][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "34/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.23907, "dt_data": 0.00042, "dt_net": 1.23865, "mode": "train", "loss": 0.20765, "lr": 0.00000}
[05/07 14:22:27][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "34/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.24651, "dt_data": 0.00057, "dt_net": 1.24594, "mode": "train", "loss": 0.21998, "lr": 0.00000}
[05/07 14:22:39][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "34/60", "cur_iter": "40", "eta": "0:00:50", "dt": 1.25571, "dt_data": 0.00068, "dt_net": 1.25503, "mode": "train", "loss": 0.19371, "lr": 0.00000}
[05/07 14:22:52][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "34/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.26167, "dt_data": 0.00035, "dt_net": 1.26132, "mode": "train", "loss": 0.16830, "lr": 0.00000}
[05/07 14:23:05][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "34/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.26211, "dt_data": 0.00043, "dt_net": 1.26168, "mode": "train", "loss": 0.18518, "lr": 0.00000}
[05/07 14:23:17][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "34/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.24699, "dt_data": 0.00023, "dt_net": 1.24676, "mode": "train", "loss": 0.21739, "lr": 0.00000}
[05/07 14:23:30][INFO] train_net.py:  669: Epoch 34 takes 135.31s. Epochs from 1 to 34 take 133.77s in average and 133.40s in median.
[05/07 14:23:30][INFO] train_net.py:  675: For epoch 34, each iteraction takes 1.71s in average. From epoch 1 to 34, each iteraction takes 1.69s in average.
[05/07 14:24:17][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "35/60", "cur_iter": "10", "eta": "0:01:24", "dt": 1.21063, "dt_data": 0.00046, "dt_net": 1.21017, "mode": "train", "loss": 0.20970, "lr": 0.00000}
[05/07 14:24:29][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "35/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.24678, "dt_data": 0.00037, "dt_net": 1.24641, "mode": "train", "loss": 0.19556, "lr": 0.00000}
[05/07 14:24:42][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "35/60", "cur_iter": "30", "eta": "0:01:03", "dt": 1.27874, "dt_data": 0.00045, "dt_net": 1.27829, "mode": "train", "loss": 0.17978, "lr": 0.00000}
[05/07 14:24:54][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "35/60", "cur_iter": "40", "eta": "0:00:49", "dt": 1.23119, "dt_data": 0.00040, "dt_net": 1.23079, "mode": "train", "loss": 0.19165, "lr": 0.00000}
[05/07 14:25:06][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "35/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.24440, "dt_data": 0.00042, "dt_net": 1.24398, "mode": "train", "loss": 0.19966, "lr": 0.00000}
[05/07 14:25:19][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "35/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.25582, "dt_data": 0.00043, "dt_net": 1.25539, "mode": "train", "loss": 0.20309, "lr": 0.00000}
[05/07 14:25:31][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "35/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.22316, "dt_data": 0.00021, "dt_net": 1.22294, "mode": "train", "loss": 0.18548, "lr": 0.00000}
[05/07 14:25:44][INFO] train_net.py:  669: Epoch 35 takes 134.20s. Epochs from 1 to 35 take 133.78s in average and 133.45s in median.
[05/07 14:25:44][INFO] train_net.py:  675: For epoch 35, each iteraction takes 1.70s in average. From epoch 1 to 35, each iteraction takes 1.69s in average.
[05/07 14:26:23][INFO] logging.py:   98: json_stats: {"_type": "val_iter", "cur_epoch": "35/60", "cur_iter": "10", "eta": "0:00:01", "dt": 0.47895, "dt_data": 0.01208, "dt_net": 0.46687, "mode": "val"}
[05/07 14:26:24][INFO] ava_eval_helper.py:  204: Evaluating with 542 unique GT frames.
[05/07 14:26:24][INFO] ava_eval_helper.py:  208: Evaluating with 542 unique detection frames
[05/07 14:26:24][INFO] ava_eval_helper.py:  469: AVA results wrote to detections_latest.csv
[05/07 14:26:24][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 14:26:24][INFO] ava_eval_helper.py:  469: AVA results wrote to groundtruth_latest.csv
[05/07 14:26:24][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 14:26:27][INFO] object_detection_evaluation.py:  751: The following classes have no ground truth examples: [ 2  3  4  5 10 13 15 16 18 19 20 21 23 25 28 31 32 33 35 37 39 40 41 42
 44 49 50 51 52 53 54 55 56 57 63 64 67 68 70 71 72 73 75 77]
[05/07 14:26:27][INFO] ava_eval_helper.py:  298: mAP@0.5 = 0.17464 | macro-F1 = 0.08311 | macro-AUROC = 0.72642 | macro-recall = 0.06916
[05/07 14:26:27][INFO] logging.py:   98: json_stats: {"mode": "val", "cur_epoch": "35", "map": 0.17464, "f1_macro": 0.08311, "auroc_macro": 0.72642, "recall_macro": 0.06916, "gpu_mem": "18.47G", "RAM": "72.57/251.58G", "_type": "val_epoch"}
[05/07 14:26:28][INFO] ava_eval_helper.py:  469: AVA results wrote to /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/detections_val_35.csv
[05/07 14:26:28][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 14:26:28][INFO] meters.py:  327: Saved CSVs:
  per-class AP: /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/ap_per_class_val_35.csv
  detections: /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/detections_val_35.csv
[05/07 14:27:11][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "36/60", "cur_iter": "10", "eta": "0:01:24", "dt": 1.20186, "dt_data": 0.00037, "dt_net": 1.20148, "mode": "train", "loss": 0.20813, "lr": 0.00000}
[05/07 14:27:23][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "36/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.24144, "dt_data": 0.00042, "dt_net": 1.24101, "mode": "train", "loss": 0.20078, "lr": 0.00000}
[05/07 14:27:35][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "36/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.24274, "dt_data": 0.00040, "dt_net": 1.24234, "mode": "train", "loss": 0.19135, "lr": 0.00000}
[05/07 14:27:48][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "36/60", "cur_iter": "40", "eta": "0:00:50", "dt": 1.25297, "dt_data": 0.00042, "dt_net": 1.25255, "mode": "train", "loss": 0.19553, "lr": 0.00000}
[05/07 14:28:00][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "36/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.25371, "dt_data": 0.00036, "dt_net": 1.25335, "mode": "train", "loss": 0.20253, "lr": 0.00000}
[05/07 14:28:13][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "36/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.25539, "dt_data": 0.00046, "dt_net": 1.25493, "mode": "train", "loss": 0.20368, "lr": 0.00000}
[05/07 14:28:25][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "36/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.23570, "dt_data": 0.00021, "dt_net": 1.23549, "mode": "train", "loss": 0.19101, "lr": 0.00000}
[05/07 14:28:38][INFO] train_net.py:  669: Epoch 36 takes 130.07s. Epochs from 1 to 36 take 133.67s in average and 133.40s in median.
[05/07 14:28:38][INFO] train_net.py:  675: For epoch 36, each iteraction takes 1.65s in average. From epoch 1 to 36, each iteraction takes 1.69s in average.
[05/07 14:29:27][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "37/60", "cur_iter": "10", "eta": "0:01:24", "dt": 1.20688, "dt_data": 0.00053, "dt_net": 1.20635, "mode": "train", "loss": 0.21141, "lr": 0.00000}
[05/07 14:29:39][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "37/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.23879, "dt_data": 0.00053, "dt_net": 1.23826, "mode": "train", "loss": 0.21369, "lr": 0.00000}
[05/07 14:29:52][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "37/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.24978, "dt_data": 0.00040, "dt_net": 1.24938, "mode": "train", "loss": 0.19330, "lr": 0.00000}
[05/07 14:30:04][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "37/60", "cur_iter": "40", "eta": "0:00:50", "dt": 1.25377, "dt_data": 0.00046, "dt_net": 1.25330, "mode": "train", "loss": 0.20415, "lr": 0.00000}
[05/07 14:30:17][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "37/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.24694, "dt_data": 0.00042, "dt_net": 1.24653, "mode": "train", "loss": 0.19336, "lr": 0.00000}
[05/07 14:30:29][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "37/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.26176, "dt_data": 0.00099, "dt_net": 1.26076, "mode": "train", "loss": 0.19600, "lr": 0.00000}
[05/07 14:30:42][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "37/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.25145, "dt_data": 0.00024, "dt_net": 1.25121, "mode": "train", "loss": 0.20941, "lr": 0.00000}
[05/07 14:30:54][INFO] train_net.py:  669: Epoch 37 takes 136.58s. Epochs from 1 to 37 take 133.75s in average and 133.45s in median.
[05/07 14:30:54][INFO] train_net.py:  675: For epoch 37, each iteraction takes 1.73s in average. From epoch 1 to 37, each iteraction takes 1.69s in average.
[05/07 14:31:39][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "38/60", "cur_iter": "10", "eta": "0:01:25", "dt": 1.21487, "dt_data": 0.00039, "dt_net": 1.21447, "mode": "train", "loss": 0.22620, "lr": 0.00000}
[05/07 14:31:52][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "38/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.24158, "dt_data": 0.00049, "dt_net": 1.24109, "mode": "train", "loss": 0.19532, "lr": 0.00000}
[05/07 14:32:04][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "38/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.24962, "dt_data": 0.00039, "dt_net": 1.24922, "mode": "train", "loss": 0.20842, "lr": 0.00000}
[05/07 14:32:17][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "38/60", "cur_iter": "40", "eta": "0:00:50", "dt": 1.25753, "dt_data": 0.00038, "dt_net": 1.25715, "mode": "train", "loss": 0.19115, "lr": 0.00000}
[05/07 14:32:29][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "38/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.26465, "dt_data": 0.00040, "dt_net": 1.26424, "mode": "train", "loss": 0.18147, "lr": 0.00000}
[05/07 14:32:42][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "38/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.25337, "dt_data": 0.00042, "dt_net": 1.25295, "mode": "train", "loss": 0.15646, "lr": 0.00000}
[05/07 14:32:54][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "38/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.27267, "dt_data": 0.00033, "dt_net": 1.27234, "mode": "train", "loss": 0.20394, "lr": 0.00000}
[05/07 14:33:07][INFO] train_net.py:  669: Epoch 38 takes 132.64s. Epochs from 1 to 38 take 133.72s in average and 133.40s in median.
[05/07 14:33:07][INFO] train_net.py:  675: For epoch 38, each iteraction takes 1.68s in average. From epoch 1 to 38, each iteraction takes 1.69s in average.
[05/07 14:33:53][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "39/60", "cur_iter": "10", "eta": "0:01:25", "dt": 1.22299, "dt_data": 0.00060, "dt_net": 1.22238, "mode": "train", "loss": 0.19181, "lr": 0.00000}
[05/07 14:34:06][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "39/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.24888, "dt_data": 0.00057, "dt_net": 1.24830, "mode": "train", "loss": 0.16985, "lr": 0.00000}
[05/07 14:34:18][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "39/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.24927, "dt_data": 0.00038, "dt_net": 1.24889, "mode": "train", "loss": 0.17310, "lr": 0.00000}
[05/07 14:34:31][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "39/60", "cur_iter": "40", "eta": "0:00:50", "dt": 1.25910, "dt_data": 0.00047, "dt_net": 1.25863, "mode": "train", "loss": 0.17835, "lr": 0.00000}
[05/07 14:34:43][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "39/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.26581, "dt_data": 0.00035, "dt_net": 1.26546, "mode": "train", "loss": 0.19811, "lr": 0.00000}
[05/07 14:34:56][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "39/60", "cur_iter": "60", "eta": "0:00:24", "dt": 1.24350, "dt_data": 0.00047, "dt_net": 1.24303, "mode": "train", "loss": 0.20295, "lr": 0.00000}
[05/07 14:35:08][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "39/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.23801, "dt_data": 0.00024, "dt_net": 1.23776, "mode": "train", "loss": 0.17936, "lr": 0.00000}
[05/07 14:35:21][INFO] train_net.py:  669: Epoch 39 takes 133.82s. Epochs from 1 to 39 take 133.73s in average and 133.45s in median.
[05/07 14:35:21][INFO] train_net.py:  675: For epoch 39, each iteraction takes 1.69s in average. From epoch 1 to 39, each iteraction takes 1.69s in average.
[05/07 14:36:09][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "40/60", "cur_iter": "10", "eta": "0:01:25", "dt": 1.21789, "dt_data": 0.00053, "dt_net": 1.21735, "mode": "train", "loss": 0.19503, "lr": 0.00000}
[05/07 14:36:21][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "40/60", "cur_iter": "20", "eta": "0:01:15", "dt": 1.25589, "dt_data": 0.00035, "dt_net": 1.25553, "mode": "train", "loss": 0.19560, "lr": 0.00000}
[05/07 14:36:34][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "40/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.25034, "dt_data": 0.00051, "dt_net": 1.24983, "mode": "train", "loss": 0.19626, "lr": 0.00000}
[05/07 14:36:46][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "40/60", "cur_iter": "40", "eta": "0:00:51", "dt": 1.27742, "dt_data": 0.00039, "dt_net": 1.27703, "mode": "train", "loss": 0.19289, "lr": 0.00000}
[05/07 14:36:59][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "40/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.25864, "dt_data": 0.00043, "dt_net": 1.25821, "mode": "train", "loss": 0.20482, "lr": 0.00000}
[05/07 14:37:12][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "40/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.27781, "dt_data": 0.00067, "dt_net": 1.27714, "mode": "train", "loss": 0.20895, "lr": 0.00000}
[05/07 14:37:24][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "40/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.25494, "dt_data": 0.00021, "dt_net": 1.25473, "mode": "train", "loss": 0.19044, "lr": 0.00000}
[05/07 14:37:37][INFO] train_net.py:  669: Epoch 40 takes 136.04s. Epochs from 1 to 40 take 133.78s in average and 133.48s in median.
[05/07 14:37:37][INFO] train_net.py:  675: For epoch 40, each iteraction takes 1.72s in average. From epoch 1 to 40, each iteraction takes 1.69s in average.
[05/07 14:38:16][INFO] logging.py:   98: json_stats: {"_type": "val_iter", "cur_epoch": "40/60", "cur_iter": "10", "eta": "0:00:01", "dt": 0.47524, "dt_data": 0.01207, "dt_net": 0.46317, "mode": "val"}
[05/07 14:38:17][INFO] ava_eval_helper.py:  204: Evaluating with 542 unique GT frames.
[05/07 14:38:17][INFO] ava_eval_helper.py:  208: Evaluating with 542 unique detection frames
[05/07 14:38:17][INFO] ava_eval_helper.py:  469: AVA results wrote to detections_latest.csv
[05/07 14:38:17][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 14:38:17][INFO] ava_eval_helper.py:  469: AVA results wrote to groundtruth_latest.csv
[05/07 14:38:17][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 14:38:20][INFO] object_detection_evaluation.py:  751: The following classes have no ground truth examples: [ 2  3  4  5 10 13 15 16 18 19 20 21 23 25 28 31 32 33 35 37 39 40 41 42
 44 49 50 51 52 53 54 55 56 57 63 64 67 68 70 71 72 73 75 77]
[05/07 14:38:21][INFO] ava_eval_helper.py:  298: mAP@0.5 = 0.17568 | macro-F1 = 0.08309 | macro-AUROC = 0.72669 | macro-recall = 0.06921
[05/07 14:38:21][INFO] logging.py:   98: json_stats: {"mode": "val", "cur_epoch": "40", "map": 0.17568, "f1_macro": 0.08309, "auroc_macro": 0.72669, "recall_macro": 0.06921, "gpu_mem": "18.47G", "RAM": "72.27/251.58G", "_type": "val_epoch"}
[05/07 14:38:21][INFO] ava_eval_helper.py:  469: AVA results wrote to /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/detections_val_40.csv
[05/07 14:38:21][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 14:38:21][INFO] meters.py:  327: Saved CSVs:
  per-class AP: /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/ap_per_class_val_40.csv
  detections: /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/detections_val_40.csv
[05/07 14:39:04][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "41/60", "cur_iter": "10", "eta": "0:01:24", "dt": 1.21415, "dt_data": 0.00042, "dt_net": 1.21373, "mode": "train", "loss": 0.19181, "lr": 0.00000}
[05/07 14:39:17][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "41/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.24497, "dt_data": 0.00054, "dt_net": 1.24443, "mode": "train", "loss": 0.19685, "lr": 0.00000}
[05/07 14:39:29][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "41/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.24558, "dt_data": 0.00036, "dt_net": 1.24521, "mode": "train", "loss": 0.19920, "lr": 0.00000}
[05/07 14:39:42][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "41/60", "cur_iter": "40", "eta": "0:00:50", "dt": 1.25395, "dt_data": 0.00038, "dt_net": 1.25357, "mode": "train", "loss": 0.17691, "lr": 0.00000}
[05/07 14:39:54][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "41/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.26220, "dt_data": 0.00041, "dt_net": 1.26178, "mode": "train", "loss": 0.18181, "lr": 0.00000}
[05/07 14:40:07][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "41/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.25656, "dt_data": 0.00045, "dt_net": 1.25611, "mode": "train", "loss": 0.23526, "lr": 0.00000}
[05/07 14:40:19][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "41/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.23379, "dt_data": 0.00021, "dt_net": 1.23358, "mode": "train", "loss": 0.20481, "lr": 0.00000}
[05/07 14:40:32][INFO] train_net.py:  669: Epoch 41 takes 130.97s. Epochs from 1 to 41 take 133.72s in average and 133.45s in median.
[05/07 14:40:32][INFO] train_net.py:  675: For epoch 41, each iteraction takes 1.66s in average. From epoch 1 to 41, each iteraction takes 1.69s in average.
[05/07 14:41:18][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "42/60", "cur_iter": "10", "eta": "0:01:25", "dt": 1.21896, "dt_data": 0.00041, "dt_net": 1.21855, "mode": "train", "loss": 0.19835, "lr": 0.00000}
[05/07 14:41:30][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "42/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.24411, "dt_data": 0.00042, "dt_net": 1.24369, "mode": "train", "loss": 0.19720, "lr": 0.00000}
[05/07 14:41:43][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "42/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.24325, "dt_data": 0.00034, "dt_net": 1.24290, "mode": "train", "loss": 0.19655, "lr": 0.00000}
[05/07 14:41:55][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "42/60", "cur_iter": "40", "eta": "0:00:50", "dt": 1.27072, "dt_data": 0.00037, "dt_net": 1.27035, "mode": "train", "loss": 0.21761, "lr": 0.00000}
[05/07 14:42:08][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "42/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.26019, "dt_data": 0.00046, "dt_net": 1.25973, "mode": "train", "loss": 0.20414, "lr": 0.00000}
[05/07 14:42:20][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "42/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.25346, "dt_data": 0.00040, "dt_net": 1.25305, "mode": "train", "loss": 0.19084, "lr": 0.00000}
[05/07 14:42:33][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "42/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.24627, "dt_data": 0.00022, "dt_net": 1.24605, "mode": "train", "loss": 0.20142, "lr": 0.00000}
[05/07 14:42:45][INFO] train_net.py:  669: Epoch 42 takes 133.63s. Epochs from 1 to 42 take 133.71s in average and 133.48s in median.
[05/07 14:42:45][INFO] train_net.py:  675: For epoch 42, each iteraction takes 1.69s in average. From epoch 1 to 42, each iteraction takes 1.69s in average.
[05/07 14:43:31][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "43/60", "cur_iter": "10", "eta": "0:01:25", "dt": 1.21439, "dt_data": 0.00037, "dt_net": 1.21401, "mode": "train", "loss": 0.19757, "lr": 0.00000}
[05/07 14:43:43][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "43/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.23672, "dt_data": 0.00043, "dt_net": 1.23629, "mode": "train", "loss": 0.19879, "lr": 0.00000}
[05/07 14:43:56][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "43/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.24366, "dt_data": 0.00040, "dt_net": 1.24325, "mode": "train", "loss": 0.18665, "lr": 0.00000}
[05/07 14:44:08][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "43/60", "cur_iter": "40", "eta": "0:00:49", "dt": 1.24737, "dt_data": 0.00039, "dt_net": 1.24698, "mode": "train", "loss": 0.19353, "lr": 0.00000}
[05/07 14:44:21][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "43/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.24556, "dt_data": 0.00040, "dt_net": 1.24515, "mode": "train", "loss": 0.16598, "lr": 0.00000}
[05/07 14:44:34][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "43/60", "cur_iter": "60", "eta": "0:00:24", "dt": 1.24714, "dt_data": 0.00051, "dt_net": 1.24662, "mode": "train", "loss": 0.20014, "lr": 0.00000}
[05/07 14:44:47][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "43/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.25355, "dt_data": 0.00022, "dt_net": 1.25333, "mode": "train", "loss": 0.18873, "lr": 0.00000}
[05/07 14:44:59][INFO] train_net.py:  669: Epoch 43 takes 133.73s. Epochs from 1 to 43 take 133.71s in average and 133.51s in median.
[05/07 14:44:59][INFO] train_net.py:  675: For epoch 43, each iteraction takes 1.69s in average. From epoch 1 to 43, each iteraction takes 1.69s in average.
[05/07 14:45:57][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "44/60", "cur_iter": "10", "eta": "0:01:24", "dt": 1.21296, "dt_data": 0.00042, "dt_net": 1.21254, "mode": "train", "loss": 0.18575, "lr": 0.00000}
[05/07 14:46:10][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "44/60", "cur_iter": "20", "eta": "0:01:13", "dt": 1.23119, "dt_data": 0.00053, "dt_net": 1.23066, "mode": "train", "loss": 0.20020, "lr": 0.00000}
[05/07 14:46:22][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "44/60", "cur_iter": "30", "eta": "0:01:01", "dt": 1.23939, "dt_data": 0.00044, "dt_net": 1.23895, "mode": "train", "loss": 0.18834, "lr": 0.00000}
[05/07 14:46:34][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "44/60", "cur_iter": "40", "eta": "0:00:49", "dt": 1.24859, "dt_data": 0.00038, "dt_net": 1.24820, "mode": "train", "loss": 0.20188, "lr": 0.00000}
[05/07 14:46:47][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "44/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.24335, "dt_data": 0.00043, "dt_net": 1.24292, "mode": "train", "loss": 0.17844, "lr": 0.00000}
[05/07 14:46:59][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "44/60", "cur_iter": "60", "eta": "0:00:24", "dt": 1.23757, "dt_data": 0.00045, "dt_net": 1.23712, "mode": "train", "loss": 0.20789, "lr": 0.00000}
[05/07 14:47:12][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "44/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.25024, "dt_data": 0.00025, "dt_net": 1.24998, "mode": "train", "loss": 0.19228, "lr": 0.00000}
[05/07 14:47:24][INFO] train_net.py:  669: Epoch 44 takes 145.17s. Epochs from 1 to 44 take 133.97s in average and 133.53s in median.
[05/07 14:47:24][INFO] train_net.py:  675: For epoch 44, each iteraction takes 1.84s in average. From epoch 1 to 44, each iteraction takes 1.70s in average.
[05/07 14:48:11][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "45/60", "cur_iter": "10", "eta": "0:01:25", "dt": 1.22762, "dt_data": 0.00041, "dt_net": 1.22721, "mode": "train", "loss": 0.18796, "lr": 0.00000}
[05/07 14:48:23][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "45/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.24585, "dt_data": 0.00047, "dt_net": 1.24538, "mode": "train", "loss": 0.17631, "lr": 0.00000}
[05/07 14:48:35][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "45/60", "cur_iter": "30", "eta": "0:01:01", "dt": 1.23912, "dt_data": 0.00041, "dt_net": 1.23871, "mode": "train", "loss": 0.19301, "lr": 0.00000}
[05/07 14:48:48][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "45/60", "cur_iter": "40", "eta": "0:00:49", "dt": 1.24055, "dt_data": 0.00044, "dt_net": 1.24010, "mode": "train", "loss": 0.19511, "lr": 0.00000}
[05/07 14:49:00][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "45/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.26076, "dt_data": 0.00055, "dt_net": 1.26020, "mode": "train", "loss": 0.19763, "lr": 0.00000}
[05/07 14:49:13][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "45/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.25579, "dt_data": 0.00050, "dt_net": 1.25528, "mode": "train", "loss": 0.17384, "lr": 0.00000}
[05/07 14:49:25][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "45/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.25161, "dt_data": 0.00025, "dt_net": 1.25136, "mode": "train", "loss": 0.17455, "lr": 0.00000}
[05/07 14:49:38][INFO] train_net.py:  669: Epoch 45 takes 133.70s. Epochs from 1 to 45 take 133.97s in average and 133.54s in median.
[05/07 14:49:38][INFO] train_net.py:  675: For epoch 45, each iteraction takes 1.69s in average. From epoch 1 to 45, each iteraction takes 1.70s in average.
[05/07 14:50:19][INFO] logging.py:   98: json_stats: {"_type": "val_iter", "cur_epoch": "45/60", "cur_iter": "10", "eta": "0:00:01", "dt": 0.47636, "dt_data": 0.01192, "dt_net": 0.46443, "mode": "val"}
[05/07 14:50:21][INFO] ava_eval_helper.py:  204: Evaluating with 542 unique GT frames.
[05/07 14:50:21][INFO] ava_eval_helper.py:  208: Evaluating with 542 unique detection frames
[05/07 14:50:21][INFO] ava_eval_helper.py:  469: AVA results wrote to detections_latest.csv
[05/07 14:50:21][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 14:50:21][INFO] ava_eval_helper.py:  469: AVA results wrote to groundtruth_latest.csv
[05/07 14:50:21][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 14:50:24][INFO] object_detection_evaluation.py:  751: The following classes have no ground truth examples: [ 2  3  4  5 10 13 15 16 18 19 20 21 23 25 28 31 32 33 35 37 39 40 41 42
 44 49 50 51 52 53 54 55 56 57 63 64 67 68 70 71 72 73 75 77]
[05/07 14:50:24][INFO] ava_eval_helper.py:  298: mAP@0.5 = 0.17546 | macro-F1 = 0.08291 | macro-AUROC = 0.72679 | macro-recall = 0.06916
[05/07 14:50:24][INFO] logging.py:   98: json_stats: {"mode": "val", "cur_epoch": "45", "map": 0.17546, "f1_macro": 0.08291, "auroc_macro": 0.72679, "recall_macro": 0.06916, "gpu_mem": "18.47G", "RAM": "73.77/251.58G", "_type": "val_epoch"}
[05/07 14:50:24][INFO] ava_eval_helper.py:  469: AVA results wrote to /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/detections_val_45.csv
[05/07 14:50:24][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 14:50:24][INFO] meters.py:  327: Saved CSVs:
  per-class AP: /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/ap_per_class_val_45.csv
  detections: /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/detections_val_45.csv
[05/07 14:51:09][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "46/60", "cur_iter": "10", "eta": "0:01:25", "dt": 1.21477, "dt_data": 0.00037, "dt_net": 1.21439, "mode": "train", "loss": 0.17511, "lr": 0.00000}
[05/07 14:51:21][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "46/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.24540, "dt_data": 0.00050, "dt_net": 1.24489, "mode": "train", "loss": 0.20240, "lr": 0.00000}
[05/07 14:51:34][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "46/60", "cur_iter": "30", "eta": "0:01:01", "dt": 1.22653, "dt_data": 0.00036, "dt_net": 1.22617, "mode": "train", "loss": 0.19864, "lr": 0.00000}
[05/07 14:51:46][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "46/60", "cur_iter": "40", "eta": "0:00:50", "dt": 1.25782, "dt_data": 0.00037, "dt_net": 1.25745, "mode": "train", "loss": 0.20090, "lr": 0.00000}
[05/07 14:51:59][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "46/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.25864, "dt_data": 0.00048, "dt_net": 1.25815, "mode": "train", "loss": 0.19937, "lr": 0.00000}
[05/07 14:52:11][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "46/60", "cur_iter": "60", "eta": "0:00:24", "dt": 1.24541, "dt_data": 0.00061, "dt_net": 1.24480, "mode": "train", "loss": 0.18893, "lr": 0.00000}
[05/07 14:52:24][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "46/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.25332, "dt_data": 0.00023, "dt_net": 1.25309, "mode": "train", "loss": 0.18441, "lr": 0.00000}
[05/07 14:52:36][INFO] train_net.py:  669: Epoch 46 takes 132.31s. Epochs from 1 to 46 take 133.93s in average and 133.53s in median.
[05/07 14:52:36][INFO] train_net.py:  675: For epoch 46, each iteraction takes 1.67s in average. From epoch 1 to 46, each iteraction takes 1.70s in average.
[05/07 14:53:23][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "47/60", "cur_iter": "10", "eta": "0:01:25", "dt": 1.22533, "dt_data": 0.00044, "dt_net": 1.22488, "mode": "train", "loss": 0.19374, "lr": 0.00000}
[05/07 14:53:35][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "47/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.24415, "dt_data": 0.00035, "dt_net": 1.24379, "mode": "train", "loss": 0.18437, "lr": 0.00000}
[05/07 14:53:48][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "47/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.25996, "dt_data": 0.00039, "dt_net": 1.25957, "mode": "train", "loss": 0.20342, "lr": 0.00000}
[05/07 14:54:00][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "47/60", "cur_iter": "40", "eta": "0:00:50", "dt": 1.25918, "dt_data": 0.00050, "dt_net": 1.25868, "mode": "train", "loss": 0.20833, "lr": 0.00000}
[05/07 14:54:13][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "47/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.26086, "dt_data": 0.00036, "dt_net": 1.26050, "mode": "train", "loss": 0.16489, "lr": 0.00000}
[05/07 14:54:26][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "47/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.25795, "dt_data": 0.00057, "dt_net": 1.25738, "mode": "train", "loss": 0.19940, "lr": 0.00000}
[05/07 14:54:38][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "47/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.26010, "dt_data": 0.00023, "dt_net": 1.25987, "mode": "train", "loss": 0.22065, "lr": 0.00000}
[05/07 14:54:51][INFO] train_net.py:  669: Epoch 47 takes 134.42s. Epochs from 1 to 47 take 133.94s in average and 133.54s in median.
[05/07 14:54:51][INFO] train_net.py:  675: For epoch 47, each iteraction takes 1.70s in average. From epoch 1 to 47, each iteraction takes 1.70s in average.
[05/07 14:55:35][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "48/60", "cur_iter": "10", "eta": "0:01:25", "dt": 1.22539, "dt_data": 0.00036, "dt_net": 1.22503, "mode": "train", "loss": 0.20334, "lr": 0.00000}
[05/07 14:55:47][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "48/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.24304, "dt_data": 0.00036, "dt_net": 1.24267, "mode": "train", "loss": 0.22028, "lr": 0.00000}
[05/07 14:56:00][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "48/60", "cur_iter": "30", "eta": "0:01:03", "dt": 1.26269, "dt_data": 0.00041, "dt_net": 1.26227, "mode": "train", "loss": 0.19538, "lr": 0.00000}
[05/07 14:56:12][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "48/60", "cur_iter": "40", "eta": "0:00:49", "dt": 1.24199, "dt_data": 0.00040, "dt_net": 1.24158, "mode": "train", "loss": 0.19589, "lr": 0.00000}
[05/07 14:56:25][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "48/60", "cur_iter": "50", "eta": "0:00:38", "dt": 1.26678, "dt_data": 0.00043, "dt_net": 1.26635, "mode": "train", "loss": 0.18354, "lr": 0.00000}
[05/07 14:56:37][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "48/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.25489, "dt_data": 0.00046, "dt_net": 1.25443, "mode": "train", "loss": 0.20386, "lr": 0.00000}
[05/07 14:56:50][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "48/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.25830, "dt_data": 0.00022, "dt_net": 1.25808, "mode": "train", "loss": 0.21994, "lr": 0.00000}
[05/07 14:57:03][INFO] train_net.py:  669: Epoch 48 takes 131.88s. Epochs from 1 to 48 take 133.90s in average and 133.53s in median.
[05/07 14:57:03][INFO] train_net.py:  675: For epoch 48, each iteraction takes 1.67s in average. From epoch 1 to 48, each iteraction takes 1.69s in average.
[05/07 14:57:48][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "49/60", "cur_iter": "10", "eta": "0:01:24", "dt": 1.21354, "dt_data": 0.00035, "dt_net": 1.21319, "mode": "train", "loss": 0.20111, "lr": 0.00000}
[05/07 14:58:01][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "49/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.24467, "dt_data": 0.00037, "dt_net": 1.24430, "mode": "train", "loss": 0.20479, "lr": 0.00000}
[05/07 14:58:13][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "49/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.25771, "dt_data": 0.00038, "dt_net": 1.25733, "mode": "train", "loss": 0.18824, "lr": 0.00000}
[05/07 14:58:26][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "49/60", "cur_iter": "40", "eta": "0:00:50", "dt": 1.25986, "dt_data": 0.00048, "dt_net": 1.25937, "mode": "train", "loss": 0.18793, "lr": 0.00000}
[05/07 14:58:38][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "49/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.23626, "dt_data": 0.00037, "dt_net": 1.23589, "mode": "train", "loss": 0.19646, "lr": 0.00000}
[05/07 14:58:51][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "49/60", "cur_iter": "60", "eta": "0:00:24", "dt": 1.24950, "dt_data": 0.00058, "dt_net": 1.24892, "mode": "train", "loss": 0.17060, "lr": 0.00000}
[05/07 14:59:03][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "49/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.24942, "dt_data": 0.00027, "dt_net": 1.24915, "mode": "train", "loss": 0.16926, "lr": 0.00000}
[05/07 14:59:16][INFO] train_net.py:  669: Epoch 49 takes 133.19s. Epochs from 1 to 49 take 133.88s in average and 133.51s in median.
[05/07 14:59:16][INFO] train_net.py:  675: For epoch 49, each iteraction takes 1.69s in average. From epoch 1 to 49, each iteraction takes 1.69s in average.
[05/07 15:00:12][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "50/60", "cur_iter": "10", "eta": "0:01:24", "dt": 1.20901, "dt_data": 0.00053, "dt_net": 1.20848, "mode": "train", "loss": 0.18946, "lr": 0.00000}
[05/07 15:00:24][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "50/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.23688, "dt_data": 0.00041, "dt_net": 1.23647, "mode": "train", "loss": 0.20492, "lr": 0.00000}
[05/07 15:00:36][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "50/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.24779, "dt_data": 0.00042, "dt_net": 1.24737, "mode": "train", "loss": 0.20210, "lr": 0.00000}
[05/07 15:00:49][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "50/60", "cur_iter": "40", "eta": "0:00:49", "dt": 1.23178, "dt_data": 0.00039, "dt_net": 1.23139, "mode": "train", "loss": 0.19535, "lr": 0.00000}
[05/07 15:01:01][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "50/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.23529, "dt_data": 0.00038, "dt_net": 1.23491, "mode": "train", "loss": 0.19610, "lr": 0.00000}
[05/07 15:01:14][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "50/60", "cur_iter": "60", "eta": "0:00:24", "dt": 1.24633, "dt_data": 0.00045, "dt_net": 1.24587, "mode": "train", "loss": 0.19316, "lr": 0.00000}
[05/07 15:01:26][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "50/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.24567, "dt_data": 0.00022, "dt_net": 1.24545, "mode": "train", "loss": 0.21013, "lr": 0.00000}
[05/07 15:01:38][INFO] train_net.py:  669: Epoch 50 takes 142.52s. Epochs from 1 to 50 take 134.06s in average and 133.53s in median.
[05/07 15:01:38][INFO] train_net.py:  675: For epoch 50, each iteraction takes 1.80s in average. From epoch 1 to 50, each iteraction takes 1.70s in average.
[05/07 15:02:17][INFO] logging.py:   98: json_stats: {"_type": "val_iter", "cur_epoch": "50/60", "cur_iter": "10", "eta": "0:00:01", "dt": 0.47551, "dt_data": 0.01205, "dt_net": 0.46347, "mode": "val"}
[05/07 15:02:18][INFO] ava_eval_helper.py:  204: Evaluating with 542 unique GT frames.
[05/07 15:02:18][INFO] ava_eval_helper.py:  208: Evaluating with 542 unique detection frames
[05/07 15:02:18][INFO] ava_eval_helper.py:  469: AVA results wrote to detections_latest.csv
[05/07 15:02:18][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 15:02:18][INFO] ava_eval_helper.py:  469: AVA results wrote to groundtruth_latest.csv
[05/07 15:02:18][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 15:02:21][INFO] object_detection_evaluation.py:  751: The following classes have no ground truth examples: [ 2  3  4  5 10 13 15 16 18 19 20 21 23 25 28 31 32 33 35 37 39 40 41 42
 44 49 50 51 52 53 54 55 56 57 63 64 67 68 70 71 72 73 75 77]
[05/07 15:02:21][INFO] ava_eval_helper.py:  298: mAP@0.5 = 0.17555 | macro-F1 = 0.08384 | macro-AUROC = 0.72706 | macro-recall = 0.06983
[05/07 15:02:21][INFO] logging.py:   98: json_stats: {"mode": "val", "cur_epoch": "50", "map": 0.17555, "f1_macro": 0.08384, "auroc_macro": 0.72706, "recall_macro": 0.06983, "gpu_mem": "18.47G", "RAM": "73.60/251.58G", "_type": "val_epoch"}
[05/07 15:02:22][INFO] ava_eval_helper.py:  469: AVA results wrote to /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/detections_val_50.csv
[05/07 15:02:22][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 15:02:22][INFO] meters.py:  327: Saved CSVs:
  per-class AP: /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/ap_per_class_val_50.csv
  detections: /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/detections_val_50.csv
[05/07 15:03:08][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "51/60", "cur_iter": "10", "eta": "0:01:24", "dt": 1.20745, "dt_data": 0.00058, "dt_net": 1.20686, "mode": "train", "loss": 0.20027, "lr": 0.00000}
[05/07 15:03:21][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "51/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.24859, "dt_data": 0.00052, "dt_net": 1.24807, "mode": "train", "loss": 0.17699, "lr": 0.00000}
[05/07 15:03:33][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "51/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.24843, "dt_data": 0.00048, "dt_net": 1.24795, "mode": "train", "loss": 0.20565, "lr": 0.00000}
[05/07 15:03:46][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "51/60", "cur_iter": "40", "eta": "0:00:49", "dt": 1.24655, "dt_data": 0.00038, "dt_net": 1.24616, "mode": "train", "loss": 0.17996, "lr": 0.00000}
[05/07 15:03:58][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "51/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.24751, "dt_data": 0.00042, "dt_net": 1.24709, "mode": "train", "loss": 0.20945, "lr": 0.00000}
[05/07 15:04:11][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "51/60", "cur_iter": "60", "eta": "0:00:24", "dt": 1.24798, "dt_data": 0.00044, "dt_net": 1.24754, "mode": "train", "loss": 0.21140, "lr": 0.00000}
[05/07 15:04:23][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "51/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.24520, "dt_data": 0.00022, "dt_net": 1.24498, "mode": "train", "loss": 0.21087, "lr": 0.00000}
[05/07 15:04:36][INFO] train_net.py:  669: Epoch 51 takes 134.03s. Epochs from 1 to 51 take 134.06s in average and 133.54s in median.
[05/07 15:04:36][INFO] train_net.py:  675: For epoch 51, each iteraction takes 1.70s in average. From epoch 1 to 51, each iteraction takes 1.70s in average.
[05/07 15:05:20][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "52/60", "cur_iter": "10", "eta": "0:01:25", "dt": 1.21697, "dt_data": 0.00069, "dt_net": 1.21628, "mode": "train", "loss": 0.20251, "lr": 0.00000}
[05/07 15:05:32][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "52/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.24125, "dt_data": 0.00041, "dt_net": 1.24084, "mode": "train", "loss": 0.18513, "lr": 0.00000}
[05/07 15:05:45][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "52/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.25355, "dt_data": 0.00040, "dt_net": 1.25314, "mode": "train", "loss": 0.20258, "lr": 0.00000}
[05/07 15:05:57][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "52/60", "cur_iter": "40", "eta": "0:00:49", "dt": 1.24634, "dt_data": 0.00044, "dt_net": 1.24590, "mode": "train", "loss": 0.22121, "lr": 0.00000}
[05/07 15:06:10][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "52/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.26189, "dt_data": 0.00042, "dt_net": 1.26147, "mode": "train", "loss": 0.21880, "lr": 0.00000}
[05/07 15:06:22][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "52/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.25455, "dt_data": 0.00047, "dt_net": 1.25408, "mode": "train", "loss": 0.17708, "lr": 0.00000}
[05/07 15:06:35][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "52/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.24527, "dt_data": 0.00023, "dt_net": 1.24503, "mode": "train", "loss": 0.19517, "lr": 0.00000}
[05/07 15:06:47][INFO] train_net.py:  669: Epoch 52 takes 131.94s. Epochs from 1 to 52 take 134.02s in average and 133.53s in median.
[05/07 15:06:47][INFO] train_net.py:  675: For epoch 52, each iteraction takes 1.67s in average. From epoch 1 to 52, each iteraction takes 1.70s in average.
[05/07 15:07:32][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "53/60", "cur_iter": "10", "eta": "0:01:25", "dt": 1.22489, "dt_data": 0.00043, "dt_net": 1.22446, "mode": "train", "loss": 0.19961, "lr": 0.00000}
[05/07 15:07:44][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "53/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.23801, "dt_data": 0.00036, "dt_net": 1.23764, "mode": "train", "loss": 0.20665, "lr": 0.00000}
[05/07 15:07:56][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "53/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.25934, "dt_data": 0.00061, "dt_net": 1.25872, "mode": "train", "loss": 0.19989, "lr": 0.00000}
[05/07 15:08:09][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "53/60", "cur_iter": "40", "eta": "0:00:50", "dt": 1.27359, "dt_data": 0.00040, "dt_net": 1.27319, "mode": "train", "loss": 0.17345, "lr": 0.00000}
[05/07 15:08:22][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "53/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.26081, "dt_data": 0.00040, "dt_net": 1.26041, "mode": "train", "loss": 0.22280, "lr": 0.00000}
[05/07 15:08:34][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "53/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.26187, "dt_data": 0.00053, "dt_net": 1.26134, "mode": "train", "loss": 0.20416, "lr": 0.00000}
[05/07 15:08:47][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "53/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.25564, "dt_data": 0.00023, "dt_net": 1.25540, "mode": "train", "loss": 0.21307, "lr": 0.00000}
[05/07 15:08:59][INFO] train_net.py:  669: Epoch 53 takes 131.61s. Epochs from 1 to 53 take 133.97s in average and 133.51s in median.
[05/07 15:08:59][INFO] train_net.py:  675: For epoch 53, each iteraction takes 1.67s in average. From epoch 1 to 53, each iteraction takes 1.70s in average.
[05/07 15:09:45][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "54/60", "cur_iter": "10", "eta": "0:01:25", "dt": 1.21695, "dt_data": 0.00048, "dt_net": 1.21647, "mode": "train", "loss": 0.20626, "lr": 0.00000}
[05/07 15:09:58][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "54/60", "cur_iter": "20", "eta": "0:01:13", "dt": 1.21673, "dt_data": 0.00040, "dt_net": 1.21632, "mode": "train", "loss": 0.19835, "lr": 0.00000}
[05/07 15:10:10][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "54/60", "cur_iter": "30", "eta": "0:01:01", "dt": 1.23150, "dt_data": 0.00039, "dt_net": 1.23111, "mode": "train", "loss": 0.19824, "lr": 0.00000}
[05/07 15:10:23][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "54/60", "cur_iter": "40", "eta": "0:00:50", "dt": 1.25328, "dt_data": 0.00041, "dt_net": 1.25287, "mode": "train", "loss": 0.21449, "lr": 0.00000}
[05/07 15:10:35][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "54/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.25802, "dt_data": 0.00039, "dt_net": 1.25763, "mode": "train", "loss": 0.22058, "lr": 0.00000}
[05/07 15:10:48][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "54/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.26778, "dt_data": 0.00055, "dt_net": 1.26723, "mode": "train", "loss": 0.18840, "lr": 0.00000}
[05/07 15:11:01][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "54/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.26154, "dt_data": 0.00023, "dt_net": 1.26131, "mode": "train", "loss": 0.19400, "lr": 0.00000}
[05/07 15:11:13][INFO] train_net.py:  669: Epoch 54 takes 133.93s. Epochs from 1 to 54 take 133.97s in average and 133.53s in median.
[05/07 15:11:13][INFO] train_net.py:  675: For epoch 54, each iteraction takes 1.70s in average. From epoch 1 to 54, each iteraction takes 1.70s in average.
[05/07 15:11:59][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "55/60", "cur_iter": "10", "eta": "0:01:26", "dt": 1.22976, "dt_data": 0.00042, "dt_net": 1.22933, "mode": "train", "loss": 0.22090, "lr": 0.00000}
[05/07 15:12:12][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "55/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.24556, "dt_data": 0.00038, "dt_net": 1.24518, "mode": "train", "loss": 0.20515, "lr": 0.00000}
[05/07 15:12:24][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "55/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.25843, "dt_data": 0.00042, "dt_net": 1.25801, "mode": "train", "loss": 0.19684, "lr": 0.00000}
[05/07 15:12:37][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "55/60", "cur_iter": "40", "eta": "0:00:50", "dt": 1.26550, "dt_data": 0.00042, "dt_net": 1.26507, "mode": "train", "loss": 0.17585, "lr": 0.00000}
[05/07 15:12:50][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "55/60", "cur_iter": "50", "eta": "0:00:38", "dt": 1.26760, "dt_data": 0.00039, "dt_net": 1.26720, "mode": "train", "loss": 0.18025, "lr": 0.00000}
[05/07 15:13:02][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "55/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.25636, "dt_data": 0.00051, "dt_net": 1.25585, "mode": "train", "loss": 0.18147, "lr": 0.00000}
[05/07 15:13:15][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "55/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.25487, "dt_data": 0.00024, "dt_net": 1.25463, "mode": "train", "loss": 0.21889, "lr": 0.00000}
[05/07 15:13:27][INFO] train_net.py:  669: Epoch 55 takes 134.21s. Epochs from 1 to 55 take 133.97s in average and 133.54s in median.
[05/07 15:13:27][INFO] train_net.py:  675: For epoch 55, each iteraction takes 1.70s in average. From epoch 1 to 55, each iteraction takes 1.70s in average.
[05/07 15:14:09][INFO] logging.py:   98: json_stats: {"_type": "val_iter", "cur_epoch": "55/60", "cur_iter": "10", "eta": "0:00:01", "dt": 0.47596, "dt_data": 0.01208, "dt_net": 0.46388, "mode": "val"}
[05/07 15:14:11][INFO] ava_eval_helper.py:  204: Evaluating with 542 unique GT frames.
[05/07 15:14:11][INFO] ava_eval_helper.py:  208: Evaluating with 542 unique detection frames
[05/07 15:14:11][INFO] ava_eval_helper.py:  469: AVA results wrote to detections_latest.csv
[05/07 15:14:11][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 15:14:11][INFO] ava_eval_helper.py:  469: AVA results wrote to groundtruth_latest.csv
[05/07 15:14:11][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 15:14:14][INFO] object_detection_evaluation.py:  751: The following classes have no ground truth examples: [ 2  3  4  5 10 13 15 16 18 19 20 21 23 25 28 31 32 33 35 37 39 40 41 42
 44 49 50 51 52 53 54 55 56 57 63 64 67 68 70 71 72 73 75 77]
[05/07 15:14:14][INFO] ava_eval_helper.py:  298: mAP@0.5 = 0.17555 | macro-F1 = 0.08384 | macro-AUROC = 0.72706 | macro-recall = 0.06983
[05/07 15:14:14][INFO] logging.py:   98: json_stats: {"mode": "val", "cur_epoch": "55", "map": 0.17555, "f1_macro": 0.08384, "auroc_macro": 0.72706, "recall_macro": 0.06983, "gpu_mem": "18.47G", "RAM": "74.02/251.58G", "_type": "val_epoch"}
[05/07 15:14:14][INFO] ava_eval_helper.py:  469: AVA results wrote to /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/detections_val_55.csv
[05/07 15:14:14][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 15:14:14][INFO] meters.py:  327: Saved CSVs:
  per-class AP: /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/ap_per_class_val_55.csv
  detections: /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/detections_val_55.csv
[05/07 15:14:58][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "56/60", "cur_iter": "10", "eta": "0:01:24", "dt": 1.20884, "dt_data": 0.00042, "dt_net": 1.20841, "mode": "train", "loss": 0.17336, "lr": 0.00000}
[05/07 15:15:10][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "56/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.23845, "dt_data": 0.00038, "dt_net": 1.23807, "mode": "train", "loss": 0.18608, "lr": 0.00000}
[05/07 15:15:23][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "56/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.24100, "dt_data": 0.00069, "dt_net": 1.24031, "mode": "train", "loss": 0.21173, "lr": 0.00000}
[05/07 15:15:35][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "56/60", "cur_iter": "40", "eta": "0:00:49", "dt": 1.22527, "dt_data": 0.00037, "dt_net": 1.22490, "mode": "train", "loss": 0.18523, "lr": 0.00000}
[05/07 15:15:48][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "56/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.25459, "dt_data": 0.00044, "dt_net": 1.25414, "mode": "train", "loss": 0.17567, "lr": 0.00000}
[05/07 15:16:00][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "56/60", "cur_iter": "60", "eta": "0:00:24", "dt": 1.24345, "dt_data": 0.00051, "dt_net": 1.24294, "mode": "train", "loss": 0.18430, "lr": 0.00000}
[05/07 15:16:13][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "56/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.22839, "dt_data": 0.00023, "dt_net": 1.22816, "mode": "train", "loss": 0.20852, "lr": 0.00000}
[05/07 15:16:25][INFO] train_net.py:  669: Epoch 56 takes 131.01s. Epochs from 1 to 56 take 133.92s in average and 133.53s in median.
[05/07 15:16:25][INFO] train_net.py:  675: For epoch 56, each iteraction takes 1.66s in average. From epoch 1 to 56, each iteraction takes 1.70s in average.
[05/07 15:17:12][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "57/60", "cur_iter": "10", "eta": "0:01:24", "dt": 1.21031, "dt_data": 0.00048, "dt_net": 1.20984, "mode": "train", "loss": 0.18302, "lr": 0.00000}
[05/07 15:17:24][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "57/60", "cur_iter": "20", "eta": "0:01:13", "dt": 1.23306, "dt_data": 0.00046, "dt_net": 1.23260, "mode": "train", "loss": 0.19966, "lr": 0.00000}
[05/07 15:17:37][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "57/60", "cur_iter": "30", "eta": "0:01:02", "dt": 1.24321, "dt_data": 0.00040, "dt_net": 1.24280, "mode": "train", "loss": 0.20479, "lr": 0.00000}
[05/07 15:17:49][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "57/60", "cur_iter": "40", "eta": "0:00:48", "dt": 1.22034, "dt_data": 0.00038, "dt_net": 1.21996, "mode": "train", "loss": 0.20973, "lr": 0.00000}
[05/07 15:18:02][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "57/60", "cur_iter": "50", "eta": "0:00:37", "dt": 1.24933, "dt_data": 0.00047, "dt_net": 1.24886, "mode": "train", "loss": 0.20323, "lr": 0.00000}
[05/07 15:18:14][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "57/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.25529, "dt_data": 0.00078, "dt_net": 1.25450, "mode": "train", "loss": 0.18874, "lr": 0.00000}
[05/07 15:18:27][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "57/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.24691, "dt_data": 0.00030, "dt_net": 1.24660, "mode": "train", "loss": 0.17007, "lr": 0.00000}
[05/07 15:18:39][INFO] train_net.py:  669: Epoch 57 takes 133.98s. Epochs from 1 to 57 take 133.92s in average and 133.54s in median.
[05/07 15:18:39][INFO] train_net.py:  675: For epoch 57, each iteraction takes 1.70s in average. From epoch 1 to 57, each iteraction takes 1.70s in average.
[05/07 15:19:29][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "58/60", "cur_iter": "10", "eta": "0:01:24", "dt": 1.20757, "dt_data": 0.00056, "dt_net": 1.20701, "mode": "train", "loss": 0.20371, "lr": 0.00000}
[05/07 15:19:42][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "58/60", "cur_iter": "20", "eta": "0:01:14", "dt": 1.23593, "dt_data": 0.00045, "dt_net": 1.23547, "mode": "train", "loss": 0.19863, "lr": 0.00000}
[05/07 15:19:54][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "58/60", "cur_iter": "30", "eta": "0:01:03", "dt": 1.27434, "dt_data": 0.00039, "dt_net": 1.27394, "mode": "train", "loss": 0.18009, "lr": 0.00000}
[05/07 15:20:06][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "58/60", "cur_iter": "40", "eta": "0:00:49", "dt": 1.24165, "dt_data": 0.00047, "dt_net": 1.24117, "mode": "train", "loss": 0.19640, "lr": 0.00000}
[05/07 15:20:19][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "58/60", "cur_iter": "50", "eta": "0:00:38", "dt": 1.27060, "dt_data": 0.00041, "dt_net": 1.27019, "mode": "train", "loss": 0.20090, "lr": 0.00000}
[05/07 15:20:32][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "58/60", "cur_iter": "60", "eta": "0:00:25", "dt": 1.25522, "dt_data": 0.00048, "dt_net": 1.25473, "mode": "train", "loss": 0.19115, "lr": 0.00000}
[05/07 15:20:44][INFO] logging.py:   98: json_stats: {"_type": "train_iter", "cur_epoch": "58/60", "cur_iter": "70", "eta": "0:00:12", "dt": 1.25149, "dt_data": 0.00022, "dt_net": 1.25127, "mode": "train", "loss": 0.17829, "lr": 0.00000}
[05/07 15:23:50][INFO] test_net.py:  188: Test with config:
[05/07 15:23:50][INFO] test_net.py:  189: AUG:
  AA_TYPE: rand-m7-n4-mstd0.5-inc1
  COLOR_JITTER: 0.4
  ENABLE: True
  GEN_MASK_LOADER: False
  INTERPOLATION: bicubic
  MASK_FRAMES: False
  MASK_RATIO: 0.0
  MASK_TUBE: False
  MASK_WINDOW_SIZE: [8, 7, 7]
  MAX_MASK_PATCHES_PER_BLOCK: None
  NUM_SAMPLE: 2
  RE_COUNT: 1
  RE_MODE: pixel
  RE_PROB: 0.25
  RE_SPLIT: False
AVA:
  ANNOTATION_DIR: ../ava/annotations
  BGR: False
  DETECTION_SCORE_THRESH: 0.0
  EXCLUSION_FILE: ava_val_excluded_timestamps_v2.2.csv
  FRAME_DIR: ../ava/frames
  FRAME_LIST_DIR: ../ava/frame_lists
  FULL_TEST_ON_VAL: True
  GROUNDTRUTH_FILE: ava_test_gt.csv
  IMG_PROC_BACKEND: cv2
  LABEL_MAP_FILE: label_map.pbtxt
  TEST_FORCE_FLIP: False
  TEST_LISTS: ['test.csv']
  TEST_PREDICT_BOX_LISTS: ['ava_test_predicted_boxes.csv']
  TRAIN_GT_BOX_LISTS: ['ava_train.csv']
  TRAIN_LISTS: ['train.csv']
  TRAIN_PCA_JITTER_ONLY: True
  TRAIN_PREDICT_BOX_LISTS: []
  TRAIN_USE_COLOR_AUGMENTATION: False
BENCHMARK:
  LOG_PERIOD: 100
  NUM_EPOCHS: 5
  SHUFFLE: True
BN:
  GLOBAL_SYNC: False
  NORM_TYPE: batchnorm
  NUM_BATCHES_PRECISE: 200
  NUM_SPLITS: 1
  NUM_SYNC_DEVICES: 1
  USE_PRECISE_STATS: False
  WEIGHT_DECAY: 0.0
CONTRASTIVE:
  BN_MLP: False
  BN_SYNC_MLP: False
  DELTA_CLIPS_MAX: inf
  DELTA_CLIPS_MIN: -inf
  DIM: 128
  INTERP_MEMORY: False
  KNN_ON: True
  LENGTH: 239975
  LOCAL_SHUFFLE_BN: True
  MEM_TYPE: 1d
  MLP_DIM: 2048
  MOCO_MULTI_VIEW_QUEUE: False
  MOMENTUM: 0.5
  MOMENTUM_ANNEALING: False
  NUM_CLASSES_DOWNSTREAM: 400
  NUM_MLP_LAYERS: 1
  PREDICTOR_DEPTHS: []
  QUEUE_LEN: 65536
  SEQUENTIAL: False
  SIMCLR_DIST_ON: True
  SWAV_QEUE_LEN: 0
  T: 0.07
  TYPE: mem
DATA:
  COLOR_RND_GRAYSCALE: 0.0
  DECODING_BACKEND: torchvision
  DECODING_SHORT_SIZE: 256
  DUMMY_LOAD: False
  ENSEMBLE_METHOD: sum
  IN22K_TRAINVAL: False
  IN22k_VAL_IN1K: 
  INPUT_CHANNEL_NUM: [3]
  INV_UNIFORM_SAMPLE: False
  IN_VAL_CROP_RATIO: 0.875
  LOADER_CHUNK_OVERALL_SIZE: 0
  LOADER_CHUNK_SIZE: 0
  MEAN: [0.45, 0.45, 0.45]
  MULTI_LABEL: False
  NUM_FRAMES: 16
  PATH_LABEL_SEPARATOR:  
  PATH_PREFIX: 
  PATH_TO_DATA_DIR: ../ava
  PATH_TO_PRELOAD_IMDB: 
  RANDOM_FLIP: True
  REVERSE_INPUT_CHANNEL: False
  SAMPLING_RATE: 4
  SKIP_ROWS: 0
  SSL_BLUR_SIGMA_MAX: [0.0, 2.0]
  SSL_BLUR_SIGMA_MIN: [0.0, 0.1]
  SSL_COLOR_BRI_CON_SAT: [0.4, 0.4, 0.4]
  SSL_COLOR_HUE: 0.1
  SSL_COLOR_JITTER: False
  SSL_MOCOV2_AUG: False
  STD: [0.225, 0.225, 0.225]
  TARGET_FPS: 30
  TEST_CROP_SIZE: 224
  TIME_DIFF_PROB: 0.0
  TRAIN_CROP_NUM_SPATIAL: 1
  TRAIN_CROP_NUM_TEMPORAL: 1
  TRAIN_CROP_SIZE: 224
  TRAIN_JITTER_ASPECT_RELATIVE: [0.75, 1.3333]
  TRAIN_JITTER_FPS: 0.0
  TRAIN_JITTER_MOTION_SHIFT: False
  TRAIN_JITTER_SCALES: [256, 320]
  TRAIN_JITTER_SCALES_RELATIVE: [0.08, 1.0]
  TRAIN_PCA_EIGVAL: [0.225, 0.224, 0.229]
  TRAIN_PCA_EIGVEC: [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]]
  USE_OFFSET_SAMPLING: True
DATA_LOADER:
  ENABLE_MULTI_THREAD_DECODE: False
  NUM_WORKERS: 8
  PIN_MEMORY: True
DEMO:
  BUFFER_SIZE: 0
  CLIP_VIS_SIZE: 10
  COMMON_CLASS_NAMES: ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)']
  COMMON_CLASS_THRES: 0.7
  DETECTRON2_CFG: COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml
  DETECTRON2_THRESH: 0.9
  DETECTRON2_WEIGHTS: detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
  DISPLAY_HEIGHT: 0
  DISPLAY_WIDTH: 0
  ENABLE: False
  FPS: 30
  GT_BOXES: 
  INPUT_FORMAT: BGR
  INPUT_VIDEO: 
  LABEL_FILE_PATH: 
  NUM_CLIPS_SKIP: 0
  NUM_VIS_INSTANCES: 2
  OUTPUT_FILE: 
  OUTPUT_FPS: -1
  PREDS_BOXES: 
  SLOWMO: 1
  STARTING_SECOND: 900
  THREAD_ENABLE: False
  UNCOMMON_CLASS_THRES: 0.3
  VIS_MODE: thres
  WEBCAM: -1
DETECTION:
  ALIGNED: True
  ENABLE: True
  ROI_XFORM_RESOLUTION: 7
  SPATIAL_SCALE_FACTOR: 16
DIST_BACKEND: nccl
LOG_MODEL_INFO: True
LOG_PERIOD: 10
MASK:
  DECODER_DEPTH: 0
  DECODER_EMBED_DIM: 512
  DECODER_SEP_POS_EMBED: False
  DEC_KV_KERNEL: []
  DEC_KV_STRIDE: []
  ENABLE: False
  HEAD_TYPE: separate
  MAE_ON: False
  MAE_RND_MASK: False
  NORM_PRED_PIXEL: True
  PER_FRAME_MASKING: False
  PRED_HOG: False
  PRETRAIN_DEPTH: [15]
  SCALE_INIT_BY_DEPTH: False
  TIME_STRIDE_LOSS: True
MIXUP:
  ALPHA: 0.8
  CUTMIX_ALPHA: 1.0
  ENABLE: False
  LABEL_SMOOTH_VALUE: 0.1
  PROB: 1.0
  SWITCH_PROB: 0.5
MODEL:
  ACT_CHECKPOINT: False
  ARCH: mvit
  DETACH_FINAL_FC: False
  DROPCONNECT_RATE: 0.0
  DROPOUT_RATE: 0.5
  FC_INIT_STD: 0.01
  FP16_ALLREDUCE: False
  FROZEN_BN: False
  HEAD_ACT: none
  LOSS_FUNC: bce_logit
  MODEL_NAME: MViT
  MULTI_PATHWAY_ARCH: ['slowfast']
  NUM_CLASSES: 50
  SINGLE_PATHWAY_ARCH: ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'maskmvit']
MULTIGRID:
  BN_BASE_SIZE: 8
  DEFAULT_B: 0
  DEFAULT_S: 0
  DEFAULT_T: 0
  EPOCH_FACTOR: 1.5
  EVAL_FREQ: 3
  LONG_CYCLE: False
  LONG_CYCLE_FACTORS: [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)]
  LONG_CYCLE_SAMPLING_RATE: 0
  SHORT_CYCLE: False
  SHORT_CYCLE_FACTORS: [0.5, 0.7071067811865476]
MVIT:
  CLS_EMBED_ON: True
  DEPTH: 16
  DIM_MUL: [[1, 2.0], [3, 2.0], [14, 2.0]]
  DIM_MUL_IN_ATT: True
  DROPOUT_RATE: 0.0
  DROPPATH_RATE: 0.2
  EMBED_DIM: 96
  HEAD_INIT_SCALE: 1.0
  HEAD_MUL: [[1, 2.0], [3, 2.0], [14, 2.0]]
  LAYER_SCALE_INIT_VALUE: 0.0
  MLP_RATIO: 4.0
  MODE: conv
  NORM: layernorm
  NORM_STEM: False
  NUM_HEADS: 1
  PATCH_2D: False
  PATCH_KERNEL: [3, 7, 7]
  PATCH_PADDING: [1, 3, 3]
  PATCH_STRIDE: [2, 4, 4]
  POOL_FIRST: False
  POOL_KVQ_KERNEL: [3, 3, 3]
  POOL_KV_STRIDE: []
  POOL_KV_STRIDE_ADAPTIVE: [1, 8, 8]
  POOL_Q_STRIDE: [[0, 1, 1, 1], [1, 1, 2, 2], [2, 1, 1, 1], [3, 1, 2, 2], [4, 1, 1, 1], [5, 1, 1, 1], [6, 1, 1, 1], [7, 1, 1, 1], [8, 1, 1, 1], [9, 1, 1, 1], [10, 1, 1, 1], [11, 1, 1, 1], [12, 1, 1, 1], [13, 1, 1, 1], [14, 1, 2, 2], [15, 1, 1, 1]]
  QKV_BIAS: True
  REL_POS_SPATIAL: True
  REL_POS_TEMPORAL: True
  REL_POS_ZERO_INIT: False
  RESIDUAL_POOLING: True
  REV:
    BUFFER_LAYERS: []
    ENABLE: False
    PRE_Q_FUSION: avg
    RESPATH_FUSE: concat
    RES_PATH: conv
  SEPARATE_QKV: False
  SEP_POS_EMBED: False
  USE_ABS_POS: False
  USE_FIXED_SINCOS_POS: False
  USE_MEAN_POOLING: False
  ZERO_DECAY_POS_CLS: False
NONLOCAL:
  GROUP: [[1], [1], [1], [1]]
  INSTANTIATION: dot_product
  LOCATION: [[[]], [[]], [[]], [[]]]
  POOL: [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]
NUM_GPUS: 3
NUM_SHARDS: 1
OUTPUT_DIR: /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4
RESNET:
  DEPTH: 50
  INPLACE_RELU: True
  NUM_BLOCK_TEMP_KERNEL: [[3], [4], [6], [3]]
  NUM_GROUPS: 1
  SPATIAL_DILATIONS: [[1], [1], [1], [1]]
  SPATIAL_STRIDES: [[1], [2], [2], [2]]
  STRIDE_1X1: False
  TRANS_FUNC: bottleneck_transform
  WIDTH_PER_GROUP: 64
  ZERO_INIT_FINAL_BN: False
  ZERO_INIT_FINAL_CONV: False
RNG_SEED: 0
SHARD_ID: 0
SLOWFAST:
  ALPHA: 8
  BETA_INV: 8
  FUSION_CONV_CHANNEL_RATIO: 2
  FUSION_KERNEL_SZ: 5
SOLVER:
  BASE_LR: 0.0001
  BASE_LR_SCALE_NUM_SHARDS: False
  BETAS: (0.9, 0.999)
  CLIP_GRAD_L2NORM: 1.0
  CLIP_GRAD_VAL: None
  COSINE_AFTER_WARMUP: False
  COSINE_END_LR: 0.0
  DAMPENING: 0.0
  GAMMA: 0.1
  LARS_ON: False
  LAYER_DECAY: 1.0
  LRS: [1, 0.1, 0.01, 0.001, 0.0001]
  LR_POLICY: steps_with_relative_lrs
  MAX_EPOCH: 60
  MOMENTUM: 0.9
  NESTEROV: True
  OPTIMIZING_METHOD: adamw
  STEPS: [0, 20, 30, 40, 50]
  STEP_SIZE: 1
  WARMUP_EPOCHS: 5.0
  WARMUP_FACTOR: 0.1
  WARMUP_START_LR: 1e-06
  WEIGHT_DECAY: 0.05
  ZERO_WD_1D_PARAM: False
TASK: 
TENSORBOARD:
  CATEGORIES_PATH: 
  CLASS_NAMES_PATH: 
  CONFUSION_MATRIX:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
  ENABLE: False
  HISTOGRAM:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
    TOPK: 10
  LOG_DIR: 
  MODEL_VIS:
    ACTIVATIONS: False
    COLORMAP: Pastel2
    ENABLE: False
    GRAD_CAM:
      COLORMAP: viridis
      ENABLE: True
      LAYER_LIST: []
      USE_TRUE_LABEL: False
    INPUT_VIDEO: False
    LAYER_LIST: []
    MODEL_WEIGHTS: False
    TOPK_PREDS: 1
  PREDICTIONS_PATH: 
  WRONG_PRED_VIS:
    ENABLE: False
    SUBSET_PATH: 
    TAG: Incorrectly classified videos.
TEST:
  BATCH_SIZE: 3
  CHECKPOINT_FILE_PATH: /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/checkpoints/checkpoint_epoch_00025.pyth
  CHECKPOINT_TYPE: pytorch
  DATASET: ava
  ENABLE: True
  NUM_ENSEMBLE_VIEWS: 5
  NUM_SPATIAL_CROPS: 1
  NUM_TEMPORAL_CLIPS: [5]
  SAVE_RESULTS_PATH: 
TRAIN:
  AUTO_RESUME: True
  BATCH_SIZE: 48
  CHECKPOINT_CLEAR_NAME_PATTERN: ()
  CHECKPOINT_EPOCH_RESET: True
  CHECKPOINT_FILE_PATH: /home/lqi/lqi_temp/trainingspace/pretrained_models/MViTv2_S_16x4.pyth
  CHECKPOINT_INFLATE: False
  CHECKPOINT_IN_INIT: False
  CHECKPOINT_PERIOD: 5
  CHECKPOINT_TYPE: pytorch
  DATASET: ava
  ENABLE: False
  EVAL_PERIOD: 5
  KILL_LOSS_EXPLOSION_FACTOR: 0.0
  MIXED_PRECISION: True
VIS_MASK:
  ENABLE: False
X3D:
  BN_LIN5: False
  BOTTLENECK_FACTOR: 1.0
  CHANNELWISE_3x3x3: True
  DEPTH_FACTOR: 1.0
  DIM_C1: 12
  DIM_C5: 2048
  SCALE_RES2: False
  WIDTH_FACTOR: 1.0
[05/07 15:23:52][INFO] misc.py:  186: Model:
DistributedDataParallel(
  (module): MViT(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
    )
    (blocks): ModuleList(
      (0): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=384, out_features=96, bias=True)
        )
      )
      (1): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
        (proj): Linear(in_features=96, out_features=192, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (2): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
      )
      (3): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
        (proj): Linear(in_features=192, out_features=384, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (4-13): 10 x MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (14): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (15): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (head): ResNetRoIHead(
      (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
      (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=768, out_features=50, bias=True)
      (act): Identity()
    )
  )
)
[05/07 15:23:52][INFO] misc.py:  188: Params: 34,268,594
[05/07 15:23:52][INFO] misc.py:  189: Mem: 0.2556772232055664 MB
[05/07 15:23:53][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 489 time(s)
[05/07 15:23:53][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 68 time(s)
[05/07 15:23:53][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 96 time(s)
[05/07 15:23:53][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 64 time(s)
[05/07 15:23:53][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 80 time(s)
[05/07 15:23:53][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/07 15:23:53][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/07 15:23:53][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/07 15:23:53][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/07 15:23:53][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/07 15:23:53][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/07 15:23:53][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/07 15:23:53][INFO] misc.py:  191: Flops: 64.45665578399999 G
[05/07 15:23:55][WARNING] jit_analysis.py:  499: Unsupported operator aten::layer_norm encountered 81 time(s)
[05/07 15:23:55][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 489 time(s)
[05/07 15:23:55][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 68 time(s)
[05/07 15:23:55][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 96 time(s)
[05/07 15:23:55][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 64 time(s)
[05/07 15:23:55][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 80 time(s)
[05/07 15:23:55][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/07 15:23:55][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/07 15:23:55][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/07 15:23:55][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/07 15:23:55][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/07 15:23:55][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/07 15:23:55][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/07 15:23:55][INFO] misc.py:  192: Activations: 248.60871500000002 M
[05/07 15:23:55][INFO] misc.py:  197: nvidia-smi
[05/07 15:23:55][INFO] misc.py:  186: Model:
DistributedDataParallel(
  (module): MViT(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
    )
    (blocks): ModuleList(
      (0): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=384, out_features=96, bias=True)
        )
      )
      (1): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
        (proj): Linear(in_features=96, out_features=192, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (2): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
      )
      (3): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
        (proj): Linear(in_features=192, out_features=384, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (4-13): 10 x MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (14): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (15): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (head): ResNetRoIHead(
      (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
      (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=768, out_features=50, bias=True)
      (act): Identity()
    )
  )
)
[05/07 15:23:55][INFO] misc.py:  188: Params: 34,268,594
[05/07 15:23:55][INFO] misc.py:  189: Mem: 1.704592227935791 MB
[05/07 15:23:57][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 489 time(s)
[05/07 15:23:57][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 68 time(s)
[05/07 15:23:57][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 96 time(s)
[05/07 15:23:57][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 64 time(s)
[05/07 15:23:57][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 80 time(s)
[05/07 15:23:57][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/07 15:23:57][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/07 15:23:57][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/07 15:23:57][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/07 15:23:57][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/07 15:23:57][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/07 15:23:57][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/07 15:23:57][INFO] misc.py:  191: Flops: 64.45665578399999 G
[05/07 15:23:58][WARNING] jit_analysis.py:  499: Unsupported operator aten::layer_norm encountered 81 time(s)
[05/07 15:23:58][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 489 time(s)
[05/07 15:23:58][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 68 time(s)
[05/07 15:23:58][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 96 time(s)
[05/07 15:23:58][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 64 time(s)
[05/07 15:23:58][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 80 time(s)
[05/07 15:23:58][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/07 15:23:58][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/07 15:23:58][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/07 15:23:58][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/07 15:23:58][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/07 15:23:58][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/07 15:23:58][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/07 15:23:58][INFO] misc.py:  192: Activations: 248.60871500000002 M
[05/07 15:23:58][INFO] misc.py:  197: nvidia-smi
[05/07 15:23:58][INFO] checkpoint.py:  213: Loading network weights from /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/checkpoints/checkpoint_epoch_00025.pyth.
[05/07 15:23:59][INFO] ava_helper.py:   58: Finished loading image paths from: ../ava/frame_lists/test.csv
[05/07 15:23:59][INFO] ava_helper.py:  139: Finished loading annotations from: ../ava/annotations/ava_test_predicted_boxes.csv
[05/07 15:23:59][INFO] ava_helper.py:  140: Detection threshold: 0.0
[05/07 15:23:59][INFO] ava_helper.py:  141: Number of unique boxes: 1136
[05/07 15:23:59][INFO] ava_helper.py:  142: Number of annotations: 0
[05/07 15:23:59][INFO] ava_helper.py:  185: 1091 keyframes used.
[05/07 15:23:59][INFO] ava_dataset.py:  130: === AVA dataset summary ===
[05/07 15:23:59][INFO] ava_dataset.py:  131: Split: test
[05/07 15:23:59][INFO] ava_dataset.py:  132: Number of videos: 953
[05/07 15:23:59][INFO] ava_dataset.py:  136: Number of frames: 85775
[05/07 15:23:59][INFO] ava_dataset.py:  137: Number of key frames: 1091
[05/07 15:23:59][INFO] ava_dataset.py:  138: Number of boxes: 1136.
[05/07 15:23:59][INFO] test_net.py:  215: Testing model for 364 iterations
[05/07 15:23:59][INFO] ava_helper.py:   58: Finished loading image paths from: ../ava/frame_lists/test.csv
[05/07 15:24:29][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "10", "eta": "0:00:43", "dt": 0.12137, "dt_data": 0.00231, "dt_net": 0.11906, "mode": "test"}
[05/07 15:24:30][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "20", "eta": "0:00:42", "dt": 0.12216, "dt_data": 0.00167, "dt_net": 0.12049, "mode": "test"}
[05/07 15:24:31][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "30", "eta": "0:00:50", "dt": 0.15088, "dt_data": 0.00221, "dt_net": 0.14866, "mode": "test"}
[05/07 15:24:32][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "40", "eta": "0:00:38", "dt": 0.11880, "dt_data": 0.00212, "dt_net": 0.11667, "mode": "test"}
[05/07 15:24:33][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "50", "eta": "0:00:37", "dt": 0.12024, "dt_data": 0.00210, "dt_net": 0.11814, "mode": "test"}
[05/07 15:24:34][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "60", "eta": "0:00:37", "dt": 0.12219, "dt_data": 0.00159, "dt_net": 0.12060, "mode": "test"}
[05/07 15:24:36][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "70", "eta": "0:00:35", "dt": 0.12045, "dt_data": 0.00173, "dt_net": 0.11872, "mode": "test"}
[05/07 15:24:37][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "80", "eta": "0:00:22", "dt": 0.07883, "dt_data": 0.00175, "dt_net": 0.07708, "mode": "test"}
[05/07 15:24:38][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "90", "eta": "0:00:33", "dt": 0.12007, "dt_data": 0.00171, "dt_net": 0.11837, "mode": "test"}
[05/07 15:24:39][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "100", "eta": "0:00:31", "dt": 0.11989, "dt_data": 0.00149, "dt_net": 0.11840, "mode": "test"}
[05/07 15:24:40][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "110", "eta": "0:00:31", "dt": 0.12174, "dt_data": 0.00180, "dt_net": 0.11993, "mode": "test"}
[05/07 15:24:41][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "120", "eta": "0:00:29", "dt": 0.12117, "dt_data": 0.00180, "dt_net": 0.11937, "mode": "test"}
[05/07 15:24:42][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "130", "eta": "0:00:18", "dt": 0.07962, "dt_data": 0.00177, "dt_net": 0.07785, "mode": "test"}
[05/07 15:24:43][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "140", "eta": "0:00:27", "dt": 0.12121, "dt_data": 0.00177, "dt_net": 0.11944, "mode": "test"}
[05/07 15:24:45][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "150", "eta": "0:00:25", "dt": 0.12010, "dt_data": 0.00224, "dt_net": 0.11786, "mode": "test"}
[05/07 15:24:46][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "160", "eta": "0:00:24", "dt": 0.12127, "dt_data": 0.00174, "dt_net": 0.11952, "mode": "test"}
[05/07 15:24:47][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "170", "eta": "0:00:23", "dt": 0.11989, "dt_data": 0.00171, "dt_net": 0.11817, "mode": "test"}
[05/07 15:24:48][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "180", "eta": "0:00:22", "dt": 0.11988, "dt_data": 0.00188, "dt_net": 0.11800, "mode": "test"}
[05/07 15:24:49][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "190", "eta": "0:00:21", "dt": 0.12123, "dt_data": 0.00226, "dt_net": 0.11897, "mode": "test"}
[05/07 15:24:50][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "200", "eta": "0:00:13", "dt": 0.07943, "dt_data": 0.00163, "dt_net": 0.07780, "mode": "test"}
[05/07 15:24:51][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "210", "eta": "0:00:18", "dt": 0.11898, "dt_data": 0.00205, "dt_net": 0.11693, "mode": "test"}
[05/07 15:24:52][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "220", "eta": "0:00:17", "dt": 0.12244, "dt_data": 0.00167, "dt_net": 0.12077, "mode": "test"}
[05/07 15:24:53][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "230", "eta": "0:00:16", "dt": 0.11880, "dt_data": 0.00207, "dt_net": 0.11673, "mode": "test"}
[05/07 15:24:54][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "240", "eta": "0:00:14", "dt": 0.11916, "dt_data": 0.00206, "dt_net": 0.11710, "mode": "test"}
[05/07 15:24:56][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "250", "eta": "0:00:14", "dt": 0.12175, "dt_data": 0.00167, "dt_net": 0.12008, "mode": "test"}
[05/07 15:24:57][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "260", "eta": "0:00:12", "dt": 0.12138, "dt_data": 0.00215, "dt_net": 0.11922, "mode": "test"}
[05/07 15:24:58][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "270", "eta": "0:00:11", "dt": 0.12103, "dt_data": 0.00164, "dt_net": 0.11939, "mode": "test"}
[05/07 15:24:59][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "280", "eta": "0:00:10", "dt": 0.12127, "dt_data": 0.00195, "dt_net": 0.11933, "mode": "test"}
[05/07 15:25:00][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "290", "eta": "0:00:09", "dt": 0.12354, "dt_data": 0.00172, "dt_net": 0.12182, "mode": "test"}
[05/07 15:25:01][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "300", "eta": "0:00:05", "dt": 0.08219, "dt_data": 0.00178, "dt_net": 0.08041, "mode": "test"}
[05/07 15:25:02][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "310", "eta": "0:00:04", "dt": 0.08170, "dt_data": 0.00157, "dt_net": 0.08013, "mode": "test"}
[05/07 15:25:03][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "320", "eta": "0:00:05", "dt": 0.11975, "dt_data": 0.00180, "dt_net": 0.11794, "mode": "test"}
[05/07 15:25:04][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "330", "eta": "0:00:04", "dt": 0.11967, "dt_data": 0.00173, "dt_net": 0.11794, "mode": "test"}
[05/07 15:25:05][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "340", "eta": "0:00:03", "dt": 0.12360, "dt_data": 0.00180, "dt_net": 0.12179, "mode": "test"}
[05/07 15:25:06][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "350", "eta": "0:00:01", "dt": 0.08251, "dt_data": 0.00144, "dt_net": 0.08106, "mode": "test"}
[05/07 15:25:07][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "360", "eta": "0:00:00", "dt": 0.07924, "dt_data": 0.00148, "dt_net": 0.07776, "mode": "test"}
[05/07 15:25:09][INFO] ava_eval_helper.py:  204: Evaluating with 1091 unique GT frames.
[05/07 15:25:09][INFO] ava_eval_helper.py:  208: Evaluating with 1091 unique detection frames
[05/07 15:25:09][INFO] ava_eval_helper.py:  469: AVA results wrote to detections_latest.csv
[05/07 15:25:09][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 15:25:09][INFO] ava_eval_helper.py:  469: AVA results wrote to groundtruth_latest.csv
[05/07 15:25:09][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 15:25:15][INFO] object_detection_evaluation.py:  751: The following classes have no ground truth examples: [ 2  4  9 13 15 16 18 19 20 21 23 25 31 32 33 35 37 39 40 41 42 44 49 50
 51 52 53 54 55 58 63 67 68 71 72 73 75 76 77]
[05/07 15:25:15][INFO] ava_eval_helper.py:  298: mAP@0.5 = 0.14863 | macro-F1 = 0.07885 | macro-AUROC = 0.78460 | macro-recall = 0.06852
[05/07 15:25:15][INFO] logging.py:   98: json_stats: {"mode": "test", "map": 0.14863, "f1_macro": 0.07885, "auroc_macro": 0.78460, "recall_macro": 0.06852}
[05/07 15:25:15][INFO] ava_eval_helper.py:  469: AVA results wrote to /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/detections_test.csv
[05/07 15:25:15][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 15:25:15][INFO] meters.py:  327: Saved CSVs:
  per-class AP: /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/ap_per_class_test.csv
  detections: /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/detections_test.csv
[05/07 15:25:15][INFO] test_net.py:  256: Finalized testing with 5 temporal clips and 1 spatial crops
[05/07 15:25:15][INFO] test_net.py:  275: _p34.27_f64.46_5a14.86 Top5 Acc: 14.86 MEM: 1.76 f: 64.4567
[05/07 15:25:15][INFO] test_net.py:  276: _p34.27_f64.46_5a14.86
[05/07 15:25:49][INFO] test_net.py:  188: Test with config:
[05/07 15:25:49][INFO] test_net.py:  189: AUG:
  AA_TYPE: rand-m7-n4-mstd0.5-inc1
  COLOR_JITTER: 0.4
  ENABLE: True
  GEN_MASK_LOADER: False
  INTERPOLATION: bicubic
  MASK_FRAMES: False
  MASK_RATIO: 0.0
  MASK_TUBE: False
  MASK_WINDOW_SIZE: [8, 7, 7]
  MAX_MASK_PATCHES_PER_BLOCK: None
  NUM_SAMPLE: 2
  RE_COUNT: 1
  RE_MODE: pixel
  RE_PROB: 0.25
  RE_SPLIT: False
AVA:
  ANNOTATION_DIR: ../ava/annotations
  BGR: False
  DETECTION_SCORE_THRESH: 0.0
  EXCLUSION_FILE: ava_val_excluded_timestamps_v2.2.csv
  FRAME_DIR: ../ava/frames
  FRAME_LIST_DIR: ../ava/frame_lists
  FULL_TEST_ON_VAL: True
  GROUNDTRUTH_FILE: ava_test_gt.csv
  IMG_PROC_BACKEND: cv2
  LABEL_MAP_FILE: label_map.pbtxt
  TEST_FORCE_FLIP: False
  TEST_LISTS: ['test.csv']
  TEST_PREDICT_BOX_LISTS: ['ava_test_predicted_boxes.csv']
  TRAIN_GT_BOX_LISTS: ['ava_train.csv']
  TRAIN_LISTS: ['train.csv']
  TRAIN_PCA_JITTER_ONLY: True
  TRAIN_PREDICT_BOX_LISTS: []
  TRAIN_USE_COLOR_AUGMENTATION: False
BENCHMARK:
  LOG_PERIOD: 100
  NUM_EPOCHS: 5
  SHUFFLE: True
BN:
  GLOBAL_SYNC: False
  NORM_TYPE: batchnorm
  NUM_BATCHES_PRECISE: 200
  NUM_SPLITS: 1
  NUM_SYNC_DEVICES: 1
  USE_PRECISE_STATS: False
  WEIGHT_DECAY: 0.0
CONTRASTIVE:
  BN_MLP: False
  BN_SYNC_MLP: False
  DELTA_CLIPS_MAX: inf
  DELTA_CLIPS_MIN: -inf
  DIM: 128
  INTERP_MEMORY: False
  KNN_ON: True
  LENGTH: 239975
  LOCAL_SHUFFLE_BN: True
  MEM_TYPE: 1d
  MLP_DIM: 2048
  MOCO_MULTI_VIEW_QUEUE: False
  MOMENTUM: 0.5
  MOMENTUM_ANNEALING: False
  NUM_CLASSES_DOWNSTREAM: 400
  NUM_MLP_LAYERS: 1
  PREDICTOR_DEPTHS: []
  QUEUE_LEN: 65536
  SEQUENTIAL: False
  SIMCLR_DIST_ON: True
  SWAV_QEUE_LEN: 0
  T: 0.07
  TYPE: mem
DATA:
  COLOR_RND_GRAYSCALE: 0.0
  DECODING_BACKEND: torchvision
  DECODING_SHORT_SIZE: 256
  DUMMY_LOAD: False
  ENSEMBLE_METHOD: sum
  IN22K_TRAINVAL: False
  IN22k_VAL_IN1K: 
  INPUT_CHANNEL_NUM: [3]
  INV_UNIFORM_SAMPLE: False
  IN_VAL_CROP_RATIO: 0.875
  LOADER_CHUNK_OVERALL_SIZE: 0
  LOADER_CHUNK_SIZE: 0
  MEAN: [0.45, 0.45, 0.45]
  MULTI_LABEL: False
  NUM_FRAMES: 16
  PATH_LABEL_SEPARATOR:  
  PATH_PREFIX: 
  PATH_TO_DATA_DIR: ../ava
  PATH_TO_PRELOAD_IMDB: 
  RANDOM_FLIP: True
  REVERSE_INPUT_CHANNEL: False
  SAMPLING_RATE: 4
  SKIP_ROWS: 0
  SSL_BLUR_SIGMA_MAX: [0.0, 2.0]
  SSL_BLUR_SIGMA_MIN: [0.0, 0.1]
  SSL_COLOR_BRI_CON_SAT: [0.4, 0.4, 0.4]
  SSL_COLOR_HUE: 0.1
  SSL_COLOR_JITTER: False
  SSL_MOCOV2_AUG: False
  STD: [0.225, 0.225, 0.225]
  TARGET_FPS: 30
  TEST_CROP_SIZE: 224
  TIME_DIFF_PROB: 0.0
  TRAIN_CROP_NUM_SPATIAL: 1
  TRAIN_CROP_NUM_TEMPORAL: 1
  TRAIN_CROP_SIZE: 224
  TRAIN_JITTER_ASPECT_RELATIVE: [0.75, 1.3333]
  TRAIN_JITTER_FPS: 0.0
  TRAIN_JITTER_MOTION_SHIFT: False
  TRAIN_JITTER_SCALES: [256, 320]
  TRAIN_JITTER_SCALES_RELATIVE: [0.08, 1.0]
  TRAIN_PCA_EIGVAL: [0.225, 0.224, 0.229]
  TRAIN_PCA_EIGVEC: [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]]
  USE_OFFSET_SAMPLING: True
DATA_LOADER:
  ENABLE_MULTI_THREAD_DECODE: False
  NUM_WORKERS: 8
  PIN_MEMORY: True
DEMO:
  BUFFER_SIZE: 0
  CLIP_VIS_SIZE: 10
  COMMON_CLASS_NAMES: ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)']
  COMMON_CLASS_THRES: 0.7
  DETECTRON2_CFG: COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml
  DETECTRON2_THRESH: 0.9
  DETECTRON2_WEIGHTS: detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
  DISPLAY_HEIGHT: 0
  DISPLAY_WIDTH: 0
  ENABLE: False
  FPS: 30
  GT_BOXES: 
  INPUT_FORMAT: BGR
  INPUT_VIDEO: 
  LABEL_FILE_PATH: 
  NUM_CLIPS_SKIP: 0
  NUM_VIS_INSTANCES: 2
  OUTPUT_FILE: 
  OUTPUT_FPS: -1
  PREDS_BOXES: 
  SLOWMO: 1
  STARTING_SECOND: 900
  THREAD_ENABLE: False
  UNCOMMON_CLASS_THRES: 0.3
  VIS_MODE: thres
  WEBCAM: -1
DETECTION:
  ALIGNED: True
  ENABLE: True
  ROI_XFORM_RESOLUTION: 7
  SPATIAL_SCALE_FACTOR: 16
DIST_BACKEND: nccl
LOG_MODEL_INFO: True
LOG_PERIOD: 10
MASK:
  DECODER_DEPTH: 0
  DECODER_EMBED_DIM: 512
  DECODER_SEP_POS_EMBED: False
  DEC_KV_KERNEL: []
  DEC_KV_STRIDE: []
  ENABLE: False
  HEAD_TYPE: separate
  MAE_ON: False
  MAE_RND_MASK: False
  NORM_PRED_PIXEL: True
  PER_FRAME_MASKING: False
  PRED_HOG: False
  PRETRAIN_DEPTH: [15]
  SCALE_INIT_BY_DEPTH: False
  TIME_STRIDE_LOSS: True
MIXUP:
  ALPHA: 0.8
  CUTMIX_ALPHA: 1.0
  ENABLE: False
  LABEL_SMOOTH_VALUE: 0.1
  PROB: 1.0
  SWITCH_PROB: 0.5
MODEL:
  ACT_CHECKPOINT: False
  ARCH: mvit
  DETACH_FINAL_FC: False
  DROPCONNECT_RATE: 0.0
  DROPOUT_RATE: 0.5
  FC_INIT_STD: 0.01
  FP16_ALLREDUCE: False
  FROZEN_BN: False
  HEAD_ACT: none
  LOSS_FUNC: bce_logit
  MODEL_NAME: MViT
  MULTI_PATHWAY_ARCH: ['slowfast']
  NUM_CLASSES: 50
  SINGLE_PATHWAY_ARCH: ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'maskmvit']
MULTIGRID:
  BN_BASE_SIZE: 8
  DEFAULT_B: 0
  DEFAULT_S: 0
  DEFAULT_T: 0
  EPOCH_FACTOR: 1.5
  EVAL_FREQ: 3
  LONG_CYCLE: False
  LONG_CYCLE_FACTORS: [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)]
  LONG_CYCLE_SAMPLING_RATE: 0
  SHORT_CYCLE: False
  SHORT_CYCLE_FACTORS: [0.5, 0.7071067811865476]
MVIT:
  CLS_EMBED_ON: True
  DEPTH: 16
  DIM_MUL: [[1, 2.0], [3, 2.0], [14, 2.0]]
  DIM_MUL_IN_ATT: True
  DROPOUT_RATE: 0.0
  DROPPATH_RATE: 0.2
  EMBED_DIM: 96
  HEAD_INIT_SCALE: 1.0
  HEAD_MUL: [[1, 2.0], [3, 2.0], [14, 2.0]]
  LAYER_SCALE_INIT_VALUE: 0.0
  MLP_RATIO: 4.0
  MODE: conv
  NORM: layernorm
  NORM_STEM: False
  NUM_HEADS: 1
  PATCH_2D: False
  PATCH_KERNEL: [3, 7, 7]
  PATCH_PADDING: [1, 3, 3]
  PATCH_STRIDE: [2, 4, 4]
  POOL_FIRST: False
  POOL_KVQ_KERNEL: [3, 3, 3]
  POOL_KV_STRIDE: []
  POOL_KV_STRIDE_ADAPTIVE: [1, 8, 8]
  POOL_Q_STRIDE: [[0, 1, 1, 1], [1, 1, 2, 2], [2, 1, 1, 1], [3, 1, 2, 2], [4, 1, 1, 1], [5, 1, 1, 1], [6, 1, 1, 1], [7, 1, 1, 1], [8, 1, 1, 1], [9, 1, 1, 1], [10, 1, 1, 1], [11, 1, 1, 1], [12, 1, 1, 1], [13, 1, 1, 1], [14, 1, 2, 2], [15, 1, 1, 1]]
  QKV_BIAS: True
  REL_POS_SPATIAL: True
  REL_POS_TEMPORAL: True
  REL_POS_ZERO_INIT: False
  RESIDUAL_POOLING: True
  REV:
    BUFFER_LAYERS: []
    ENABLE: False
    PRE_Q_FUSION: avg
    RESPATH_FUSE: concat
    RES_PATH: conv
  SEPARATE_QKV: False
  SEP_POS_EMBED: False
  USE_ABS_POS: False
  USE_FIXED_SINCOS_POS: False
  USE_MEAN_POOLING: False
  ZERO_DECAY_POS_CLS: False
NONLOCAL:
  GROUP: [[1], [1], [1], [1]]
  INSTANTIATION: dot_product
  LOCATION: [[[]], [[]], [[]], [[]]]
  POOL: [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]
NUM_GPUS: 3
NUM_SHARDS: 1
OUTPUT_DIR: /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4
RESNET:
  DEPTH: 50
  INPLACE_RELU: True
  NUM_BLOCK_TEMP_KERNEL: [[3], [4], [6], [3]]
  NUM_GROUPS: 1
  SPATIAL_DILATIONS: [[1], [1], [1], [1]]
  SPATIAL_STRIDES: [[1], [2], [2], [2]]
  STRIDE_1X1: False
  TRANS_FUNC: bottleneck_transform
  WIDTH_PER_GROUP: 64
  ZERO_INIT_FINAL_BN: False
  ZERO_INIT_FINAL_CONV: False
RNG_SEED: 0
SHARD_ID: 0
SLOWFAST:
  ALPHA: 8
  BETA_INV: 8
  FUSION_CONV_CHANNEL_RATIO: 2
  FUSION_KERNEL_SZ: 5
SOLVER:
  BASE_LR: 0.0001
  BASE_LR_SCALE_NUM_SHARDS: False
  BETAS: (0.9, 0.999)
  CLIP_GRAD_L2NORM: 1.0
  CLIP_GRAD_VAL: None
  COSINE_AFTER_WARMUP: False
  COSINE_END_LR: 0.0
  DAMPENING: 0.0
  GAMMA: 0.1
  LARS_ON: False
  LAYER_DECAY: 1.0
  LRS: [1, 0.1, 0.01, 0.001, 0.0001]
  LR_POLICY: steps_with_relative_lrs
  MAX_EPOCH: 60
  MOMENTUM: 0.9
  NESTEROV: True
  OPTIMIZING_METHOD: adamw
  STEPS: [0, 20, 30, 40, 50]
  STEP_SIZE: 1
  WARMUP_EPOCHS: 5.0
  WARMUP_FACTOR: 0.1
  WARMUP_START_LR: 1e-06
  WEIGHT_DECAY: 0.05
  ZERO_WD_1D_PARAM: False
TASK: 
TENSORBOARD:
  CATEGORIES_PATH: 
  CLASS_NAMES_PATH: 
  CONFUSION_MATRIX:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
  ENABLE: False
  HISTOGRAM:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
    TOPK: 10
  LOG_DIR: 
  MODEL_VIS:
    ACTIVATIONS: False
    COLORMAP: Pastel2
    ENABLE: False
    GRAD_CAM:
      COLORMAP: viridis
      ENABLE: True
      LAYER_LIST: []
      USE_TRUE_LABEL: False
    INPUT_VIDEO: False
    LAYER_LIST: []
    MODEL_WEIGHTS: False
    TOPK_PREDS: 1
  PREDICTIONS_PATH: 
  WRONG_PRED_VIS:
    ENABLE: False
    SUBSET_PATH: 
    TAG: Incorrectly classified videos.
TEST:
  BATCH_SIZE: 3
  CHECKPOINT_FILE_PATH: /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/checkpoints/checkpoint_epoch_00040.pyth
  CHECKPOINT_TYPE: pytorch
  DATASET: ava
  ENABLE: True
  NUM_ENSEMBLE_VIEWS: 5
  NUM_SPATIAL_CROPS: 1
  NUM_TEMPORAL_CLIPS: [5]
  SAVE_RESULTS_PATH: 
TRAIN:
  AUTO_RESUME: True
  BATCH_SIZE: 48
  CHECKPOINT_CLEAR_NAME_PATTERN: ()
  CHECKPOINT_EPOCH_RESET: True
  CHECKPOINT_FILE_PATH: /home/lqi/lqi_temp/trainingspace/pretrained_models/MViTv2_S_16x4.pyth
  CHECKPOINT_INFLATE: False
  CHECKPOINT_IN_INIT: False
  CHECKPOINT_PERIOD: 5
  CHECKPOINT_TYPE: pytorch
  DATASET: ava
  ENABLE: False
  EVAL_PERIOD: 5
  KILL_LOSS_EXPLOSION_FACTOR: 0.0
  MIXED_PRECISION: True
VIS_MASK:
  ENABLE: False
X3D:
  BN_LIN5: False
  BOTTLENECK_FACTOR: 1.0
  CHANNELWISE_3x3x3: True
  DEPTH_FACTOR: 1.0
  DIM_C1: 12
  DIM_C5: 2048
  SCALE_RES2: False
  WIDTH_FACTOR: 1.0
[05/07 15:25:50][INFO] misc.py:  186: Model:
DistributedDataParallel(
  (module): MViT(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
    )
    (blocks): ModuleList(
      (0): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=384, out_features=96, bias=True)
        )
      )
      (1): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
        (proj): Linear(in_features=96, out_features=192, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (2): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
      )
      (3): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
        (proj): Linear(in_features=192, out_features=384, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (4-13): 10 x MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (14): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (15): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (head): ResNetRoIHead(
      (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
      (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=768, out_features=50, bias=True)
      (act): Identity()
    )
  )
)
[05/07 15:25:50][INFO] misc.py:  188: Params: 34,268,594
[05/07 15:25:50][INFO] misc.py:  189: Mem: 0.2556772232055664 MB
[05/07 15:25:52][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 489 time(s)
[05/07 15:25:52][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 68 time(s)
[05/07 15:25:52][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 96 time(s)
[05/07 15:25:52][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 64 time(s)
[05/07 15:25:52][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 80 time(s)
[05/07 15:25:52][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/07 15:25:52][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/07 15:25:52][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/07 15:25:52][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/07 15:25:52][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/07 15:25:52][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/07 15:25:52][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/07 15:25:52][INFO] misc.py:  191: Flops: 64.45665578399999 G
[05/07 15:25:53][WARNING] jit_analysis.py:  499: Unsupported operator aten::layer_norm encountered 81 time(s)
[05/07 15:25:53][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 489 time(s)
[05/07 15:25:53][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 68 time(s)
[05/07 15:25:53][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 96 time(s)
[05/07 15:25:53][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 64 time(s)
[05/07 15:25:53][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 80 time(s)
[05/07 15:25:53][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/07 15:25:53][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/07 15:25:53][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/07 15:25:53][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/07 15:25:53][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/07 15:25:53][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/07 15:25:53][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/07 15:25:54][INFO] misc.py:  192: Activations: 248.60871500000002 M
[05/07 15:25:54][INFO] misc.py:  197: nvidia-smi
[05/07 15:25:54][INFO] misc.py:  186: Model:
DistributedDataParallel(
  (module): MViT(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
    )
    (blocks): ModuleList(
      (0): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=384, out_features=96, bias=True)
        )
      )
      (1): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
        (proj): Linear(in_features=96, out_features=192, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (2): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
      )
      (3): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
        (proj): Linear(in_features=192, out_features=384, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (4-13): 10 x MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (14): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (15): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (head): ResNetRoIHead(
      (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
      (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=768, out_features=50, bias=True)
      (act): Identity()
    )
  )
)
[05/07 15:25:54][INFO] misc.py:  188: Params: 34,268,594
[05/07 15:25:54][INFO] misc.py:  189: Mem: 1.704592227935791 MB
[05/07 15:25:55][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 489 time(s)
[05/07 15:25:55][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 68 time(s)
[05/07 15:25:55][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 96 time(s)
[05/07 15:25:55][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 64 time(s)
[05/07 15:25:55][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 80 time(s)
[05/07 15:25:55][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/07 15:25:55][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/07 15:25:55][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/07 15:25:55][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/07 15:25:55][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/07 15:25:55][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/07 15:25:55][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/07 15:25:55][INFO] misc.py:  191: Flops: 64.45665578399999 G
[05/07 15:25:57][WARNING] jit_analysis.py:  499: Unsupported operator aten::layer_norm encountered 81 time(s)
[05/07 15:25:57][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 489 time(s)
[05/07 15:25:57][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 68 time(s)
[05/07 15:25:57][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 96 time(s)
[05/07 15:25:57][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 64 time(s)
[05/07 15:25:57][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 80 time(s)
[05/07 15:25:57][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/07 15:25:57][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/07 15:25:57][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/07 15:25:57][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/07 15:25:57][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/07 15:25:57][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/07 15:25:57][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/07 15:25:57][INFO] misc.py:  192: Activations: 248.60871500000002 M
[05/07 15:25:57][INFO] misc.py:  197: nvidia-smi
[05/07 15:25:57][INFO] checkpoint.py:  213: Loading network weights from /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/checkpoints/checkpoint_epoch_00040.pyth.
[05/07 15:25:58][INFO] ava_helper.py:   58: Finished loading image paths from: ../ava/frame_lists/test.csv
[05/07 15:25:58][INFO] ava_helper.py:  139: Finished loading annotations from: ../ava/annotations/ava_test_predicted_boxes.csv
[05/07 15:25:58][INFO] ava_helper.py:  140: Detection threshold: 0.0
[05/07 15:25:58][INFO] ava_helper.py:  141: Number of unique boxes: 1136
[05/07 15:25:58][INFO] ava_helper.py:  142: Number of annotations: 0
[05/07 15:25:58][INFO] ava_helper.py:  185: 1091 keyframes used.
[05/07 15:25:58][INFO] ava_dataset.py:  130: === AVA dataset summary ===
[05/07 15:25:58][INFO] ava_dataset.py:  131: Split: test
[05/07 15:25:58][INFO] ava_dataset.py:  132: Number of videos: 953
[05/07 15:25:58][INFO] ava_dataset.py:  136: Number of frames: 85775
[05/07 15:25:58][INFO] ava_dataset.py:  137: Number of key frames: 1091
[05/07 15:25:58][INFO] ava_dataset.py:  138: Number of boxes: 1136.
[05/07 15:25:58][INFO] test_net.py:  215: Testing model for 364 iterations
[05/07 15:25:58][INFO] ava_helper.py:   58: Finished loading image paths from: ../ava/frame_lists/test.csv
[05/07 15:26:27][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "10", "eta": "0:00:41", "dt": 0.11776, "dt_data": 0.00210, "dt_net": 0.11565, "mode": "test"}
[05/07 15:26:28][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "20", "eta": "0:00:41", "dt": 0.11935, "dt_data": 0.00166, "dt_net": 0.11769, "mode": "test"}
[05/07 15:26:30][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "30", "eta": "0:00:51", "dt": 0.15261, "dt_data": 0.00215, "dt_net": 0.15046, "mode": "test"}
[05/07 15:26:31][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "40", "eta": "0:00:38", "dt": 0.11860, "dt_data": 0.00236, "dt_net": 0.11624, "mode": "test"}
[05/07 15:26:32][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "50", "eta": "0:00:37", "dt": 0.11982, "dt_data": 0.00231, "dt_net": 0.11751, "mode": "test"}
[05/07 15:26:33][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "60", "eta": "0:00:36", "dt": 0.12030, "dt_data": 0.00185, "dt_net": 0.11844, "mode": "test"}
[05/07 15:26:34][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "70", "eta": "0:00:35", "dt": 0.11904, "dt_data": 0.00184, "dt_net": 0.11719, "mode": "test"}
[05/07 15:26:35][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "80", "eta": "0:00:22", "dt": 0.07945, "dt_data": 0.00177, "dt_net": 0.07768, "mode": "test"}
[05/07 15:26:36][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "90", "eta": "0:00:33", "dt": 0.12145, "dt_data": 0.00183, "dt_net": 0.11961, "mode": "test"}
[05/07 15:26:37][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "100", "eta": "0:00:31", "dt": 0.11895, "dt_data": 0.00151, "dt_net": 0.11744, "mode": "test"}
[05/07 15:26:39][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "110", "eta": "0:00:30", "dt": 0.12132, "dt_data": 0.00168, "dt_net": 0.11963, "mode": "test"}
[05/07 15:26:40][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "120", "eta": "0:00:29", "dt": 0.12159, "dt_data": 0.00170, "dt_net": 0.11989, "mode": "test"}
[05/07 15:26:41][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "130", "eta": "0:00:18", "dt": 0.07859, "dt_data": 0.00146, "dt_net": 0.07713, "mode": "test"}
[05/07 15:26:42][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "140", "eta": "0:00:27", "dt": 0.12188, "dt_data": 0.00171, "dt_net": 0.12017, "mode": "test"}
[05/07 15:26:43][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "150", "eta": "0:00:25", "dt": 0.11861, "dt_data": 0.00213, "dt_net": 0.11648, "mode": "test"}
[05/07 15:26:44][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "160", "eta": "0:00:24", "dt": 0.11873, "dt_data": 0.00165, "dt_net": 0.11708, "mode": "test"}
[05/07 15:26:45][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "170", "eta": "0:00:23", "dt": 0.12253, "dt_data": 0.00152, "dt_net": 0.12101, "mode": "test"}
[05/07 15:26:46][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "180", "eta": "0:00:22", "dt": 0.11988, "dt_data": 0.00180, "dt_net": 0.11808, "mode": "test"}
[05/07 15:26:47][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "190", "eta": "0:00:21", "dt": 0.12406, "dt_data": 0.00211, "dt_net": 0.12195, "mode": "test"}
[05/07 15:26:48][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "200", "eta": "0:00:13", "dt": 0.08089, "dt_data": 0.00192, "dt_net": 0.07896, "mode": "test"}
[05/07 15:26:50][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "210", "eta": "0:00:18", "dt": 0.11986, "dt_data": 0.00214, "dt_net": 0.11771, "mode": "test"}
[05/07 15:26:51][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "220", "eta": "0:00:18", "dt": 0.12583, "dt_data": 0.00175, "dt_net": 0.12407, "mode": "test"}
[05/07 15:26:52][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "230", "eta": "0:00:16", "dt": 0.12091, "dt_data": 0.00202, "dt_net": 0.11889, "mode": "test"}
[05/07 15:26:53][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "240", "eta": "0:00:15", "dt": 0.12069, "dt_data": 0.00194, "dt_net": 0.11875, "mode": "test"}
[05/07 15:26:54][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "250", "eta": "0:00:13", "dt": 0.12107, "dt_data": 0.00165, "dt_net": 0.11942, "mode": "test"}
[05/07 15:26:55][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "260", "eta": "0:00:12", "dt": 0.11943, "dt_data": 0.00200, "dt_net": 0.11743, "mode": "test"}
[05/07 15:26:56][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "270", "eta": "0:00:11", "dt": 0.12134, "dt_data": 0.00162, "dt_net": 0.11972, "mode": "test"}
[05/07 15:26:57][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "280", "eta": "0:00:10", "dt": 0.12237, "dt_data": 0.00183, "dt_net": 0.12054, "mode": "test"}
[05/07 15:26:59][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "290", "eta": "0:00:09", "dt": 0.12281, "dt_data": 0.00188, "dt_net": 0.12093, "mode": "test"}
[05/07 15:27:00][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "300", "eta": "0:00:05", "dt": 0.07972, "dt_data": 0.00194, "dt_net": 0.07778, "mode": "test"}
[05/07 15:27:01][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "310", "eta": "0:00:04", "dt": 0.07984, "dt_data": 0.00173, "dt_net": 0.07811, "mode": "test"}
[05/07 15:27:02][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "320", "eta": "0:00:05", "dt": 0.12321, "dt_data": 0.00178, "dt_net": 0.12142, "mode": "test"}
[05/07 15:27:03][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "330", "eta": "0:00:04", "dt": 0.12387, "dt_data": 0.00162, "dt_net": 0.12225, "mode": "test"}
[05/07 15:27:04][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "340", "eta": "0:00:03", "dt": 0.12223, "dt_data": 0.00192, "dt_net": 0.12030, "mode": "test"}
[05/07 15:27:05][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "350", "eta": "0:00:01", "dt": 0.07823, "dt_data": 0.00144, "dt_net": 0.07678, "mode": "test"}
[05/07 15:27:06][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "360", "eta": "0:00:00", "dt": 0.08095, "dt_data": 0.00149, "dt_net": 0.07945, "mode": "test"}
[05/07 15:27:07][INFO] ava_eval_helper.py:  204: Evaluating with 1091 unique GT frames.
[05/07 15:27:07][INFO] ava_eval_helper.py:  208: Evaluating with 1091 unique detection frames
[05/07 15:27:08][INFO] ava_eval_helper.py:  469: AVA results wrote to detections_latest.csv
[05/07 15:27:08][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 15:27:08][INFO] ava_eval_helper.py:  469: AVA results wrote to groundtruth_latest.csv
[05/07 15:27:08][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 15:27:14][INFO] object_detection_evaluation.py:  751: The following classes have no ground truth examples: [ 2  4  9 13 15 16 18 19 20 21 23 25 31 32 33 35 37 39 40 41 42 44 49 50
 51 52 53 54 55 58 63 67 68 71 72 73 75 76 77]
[05/07 15:27:14][INFO] ava_eval_helper.py:  298: mAP@0.5 = 0.15144 | macro-F1 = 0.08155 | macro-AUROC = 0.78610 | macro-recall = 0.07168
[05/07 15:27:14][INFO] logging.py:   98: json_stats: {"mode": "test", "map": 0.15144, "f1_macro": 0.08155, "auroc_macro": 0.78610, "recall_macro": 0.07168}
[05/07 15:27:14][INFO] ava_eval_helper.py:  469: AVA results wrote to /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/detections_test.csv
[05/07 15:27:14][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/07 15:27:14][INFO] meters.py:  327: Saved CSVs:
  per-class AP: /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/ap_per_class_test.csv
  detections: /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/detections_test.csv
[05/07 15:27:14][INFO] test_net.py:  256: Finalized testing with 5 temporal clips and 1 spatial crops
[05/07 15:27:14][INFO] test_net.py:  275: _p34.27_f64.46_5a15.14 Top5 Acc: 15.14 MEM: 1.76 f: 64.4567
[05/07 15:27:14][INFO] test_net.py:  276: _p34.27_f64.46_5a15.14
[05/08 01:48:50][INFO] test_net.py:  188: Test with config:
[05/08 01:48:50][INFO] test_net.py:  189: AUG:
  AA_TYPE: rand-m7-n4-mstd0.5-inc1
  COLOR_JITTER: 0.4
  ENABLE: True
  GEN_MASK_LOADER: False
  INTERPOLATION: bicubic
  MASK_FRAMES: False
  MASK_RATIO: 0.0
  MASK_TUBE: False
  MASK_WINDOW_SIZE: [8, 7, 7]
  MAX_MASK_PATCHES_PER_BLOCK: None
  NUM_SAMPLE: 2
  RE_COUNT: 1
  RE_MODE: pixel
  RE_PROB: 0.25
  RE_SPLIT: False
AVA:
  ANNOTATION_DIR: ../ava/annotations
  BGR: False
  DETECTION_SCORE_THRESH: 0.0
  EXCLUSION_FILE: ava_val_excluded_timestamps_v2.2.csv
  FRAME_DIR: ../ava/frames
  FRAME_LIST_DIR: ../ava/frame_lists
  FULL_TEST_ON_VAL: True
  GROUNDTRUTH_FILE: ava_test_gt.csv
  IMG_PROC_BACKEND: cv2
  LABEL_MAP_FILE: label_map.pbtxt
  TEST_FORCE_FLIP: False
  TEST_LISTS: ['test.csv']
  TEST_PREDICT_BOX_LISTS: ['ava_test_predicted_boxes.csv']
  TRAIN_GT_BOX_LISTS: ['ava_train.csv']
  TRAIN_LISTS: ['train.csv']
  TRAIN_PCA_JITTER_ONLY: True
  TRAIN_PREDICT_BOX_LISTS: []
  TRAIN_USE_COLOR_AUGMENTATION: False
BENCHMARK:
  LOG_PERIOD: 100
  NUM_EPOCHS: 5
  SHUFFLE: True
BN:
  GLOBAL_SYNC: False
  NORM_TYPE: batchnorm
  NUM_BATCHES_PRECISE: 200
  NUM_SPLITS: 1
  NUM_SYNC_DEVICES: 1
  USE_PRECISE_STATS: False
  WEIGHT_DECAY: 0.0
CONTRASTIVE:
  BN_MLP: False
  BN_SYNC_MLP: False
  DELTA_CLIPS_MAX: inf
  DELTA_CLIPS_MIN: -inf
  DIM: 128
  INTERP_MEMORY: False
  KNN_ON: True
  LENGTH: 239975
  LOCAL_SHUFFLE_BN: True
  MEM_TYPE: 1d
  MLP_DIM: 2048
  MOCO_MULTI_VIEW_QUEUE: False
  MOMENTUM: 0.5
  MOMENTUM_ANNEALING: False
  NUM_CLASSES_DOWNSTREAM: 400
  NUM_MLP_LAYERS: 1
  PREDICTOR_DEPTHS: []
  QUEUE_LEN: 65536
  SEQUENTIAL: False
  SIMCLR_DIST_ON: True
  SWAV_QEUE_LEN: 0
  T: 0.07
  TYPE: mem
DATA:
  COLOR_RND_GRAYSCALE: 0.0
  DECODING_BACKEND: torchvision
  DECODING_SHORT_SIZE: 256
  DUMMY_LOAD: False
  ENSEMBLE_METHOD: sum
  IN22K_TRAINVAL: False
  IN22k_VAL_IN1K: 
  INPUT_CHANNEL_NUM: [3]
  INV_UNIFORM_SAMPLE: False
  IN_VAL_CROP_RATIO: 0.875
  LOADER_CHUNK_OVERALL_SIZE: 0
  LOADER_CHUNK_SIZE: 0
  MEAN: [0.45, 0.45, 0.45]
  MULTI_LABEL: False
  NUM_FRAMES: 16
  PATH_LABEL_SEPARATOR:  
  PATH_PREFIX: 
  PATH_TO_DATA_DIR: ../ava
  PATH_TO_PRELOAD_IMDB: 
  RANDOM_FLIP: True
  REVERSE_INPUT_CHANNEL: False
  SAMPLING_RATE: 4
  SKIP_ROWS: 0
  SSL_BLUR_SIGMA_MAX: [0.0, 2.0]
  SSL_BLUR_SIGMA_MIN: [0.0, 0.1]
  SSL_COLOR_BRI_CON_SAT: [0.4, 0.4, 0.4]
  SSL_COLOR_HUE: 0.1
  SSL_COLOR_JITTER: False
  SSL_MOCOV2_AUG: False
  STD: [0.225, 0.225, 0.225]
  TARGET_FPS: 30
  TEST_CROP_SIZE: 224
  TIME_DIFF_PROB: 0.0
  TRAIN_CROP_NUM_SPATIAL: 1
  TRAIN_CROP_NUM_TEMPORAL: 1
  TRAIN_CROP_SIZE: 224
  TRAIN_JITTER_ASPECT_RELATIVE: [0.75, 1.3333]
  TRAIN_JITTER_FPS: 0.0
  TRAIN_JITTER_MOTION_SHIFT: False
  TRAIN_JITTER_SCALES: [256, 320]
  TRAIN_JITTER_SCALES_RELATIVE: [0.08, 1.0]
  TRAIN_PCA_EIGVAL: [0.225, 0.224, 0.229]
  TRAIN_PCA_EIGVEC: [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]]
  USE_OFFSET_SAMPLING: True
DATA_LOADER:
  ENABLE_MULTI_THREAD_DECODE: False
  NUM_WORKERS: 8
  PIN_MEMORY: True
DEMO:
  BUFFER_SIZE: 0
  CLIP_VIS_SIZE: 10
  COMMON_CLASS_NAMES: ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)']
  COMMON_CLASS_THRES: 0.7
  DETECTRON2_CFG: COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml
  DETECTRON2_THRESH: 0.9
  DETECTRON2_WEIGHTS: detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
  DISPLAY_HEIGHT: 0
  DISPLAY_WIDTH: 0
  ENABLE: False
  FPS: 30
  GT_BOXES: 
  INPUT_FORMAT: BGR
  INPUT_VIDEO: 
  LABEL_FILE_PATH: 
  NUM_CLIPS_SKIP: 0
  NUM_VIS_INSTANCES: 2
  OUTPUT_FILE: 
  OUTPUT_FPS: -1
  PREDS_BOXES: 
  SLOWMO: 1
  STARTING_SECOND: 900
  THREAD_ENABLE: False
  UNCOMMON_CLASS_THRES: 0.3
  VIS_MODE: thres
  WEBCAM: -1
DETECTION:
  ALIGNED: True
  ENABLE: True
  ROI_XFORM_RESOLUTION: 7
  SPATIAL_SCALE_FACTOR: 16
DIST_BACKEND: nccl
LOG_MODEL_INFO: True
LOG_PERIOD: 10
MASK:
  DECODER_DEPTH: 0
  DECODER_EMBED_DIM: 512
  DECODER_SEP_POS_EMBED: False
  DEC_KV_KERNEL: []
  DEC_KV_STRIDE: []
  ENABLE: False
  HEAD_TYPE: separate
  MAE_ON: False
  MAE_RND_MASK: False
  NORM_PRED_PIXEL: True
  PER_FRAME_MASKING: False
  PRED_HOG: False
  PRETRAIN_DEPTH: [15]
  SCALE_INIT_BY_DEPTH: False
  TIME_STRIDE_LOSS: True
MIXUP:
  ALPHA: 0.8
  CUTMIX_ALPHA: 1.0
  ENABLE: False
  LABEL_SMOOTH_VALUE: 0.1
  PROB: 1.0
  SWITCH_PROB: 0.5
MODEL:
  ACT_CHECKPOINT: False
  ARCH: mvit
  BLIP2:
    FREEZE: True
    PRETRAINED: Salesforce/blip2-flan-t5-xl
  DETACH_FINAL_FC: False
  DROPCONNECT_RATE: 0.0
  DROPOUT_RATE: 0.5
  FC_INIT_STD: 0.01
  FP16_ALLREDUCE: False
  FROZEN_BN: False
  HEAD_ACT: sigmoid
  LOSS_FUNC: bce
  MODEL_NAME: MViT
  MULTI_PATHWAY_ARCH: ['slowfast']
  NUM_CLASSES: 50
  SINGLE_PATHWAY_ARCH: ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'maskmvit', 'blip2']
MULTIGRID:
  BN_BASE_SIZE: 8
  DEFAULT_B: 0
  DEFAULT_S: 0
  DEFAULT_T: 0
  EPOCH_FACTOR: 1.5
  EVAL_FREQ: 3
  LONG_CYCLE: False
  LONG_CYCLE_FACTORS: [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)]
  LONG_CYCLE_SAMPLING_RATE: 0
  SHORT_CYCLE: False
  SHORT_CYCLE_FACTORS: [0.5, 0.7071067811865476]
MVIT:
  CLS_EMBED_ON: True
  DEPTH: 16
  DIM_MUL: [[1, 2.0], [3, 2.0], [14, 2.0]]
  DIM_MUL_IN_ATT: True
  DROPOUT_RATE: 0.0
  DROPPATH_RATE: 0.2
  EMBED_DIM: 96
  HEAD_INIT_SCALE: 1.0
  HEAD_MUL: [[1, 2.0], [3, 2.0], [14, 2.0]]
  LAYER_SCALE_INIT_VALUE: 0.0
  MLP_RATIO: 4.0
  MODE: conv
  NORM: layernorm
  NORM_STEM: False
  NUM_HEADS: 1
  PATCH_2D: False
  PATCH_KERNEL: [3, 7, 7]
  PATCH_PADDING: [1, 3, 3]
  PATCH_STRIDE: [2, 4, 4]
  POOL_FIRST: False
  POOL_KVQ_KERNEL: [3, 3, 3]
  POOL_KV_STRIDE: []
  POOL_KV_STRIDE_ADAPTIVE: [1, 8, 8]
  POOL_Q_STRIDE: [[0, 1, 1, 1], [1, 1, 2, 2], [2, 1, 1, 1], [3, 1, 2, 2], [4, 1, 1, 1], [5, 1, 1, 1], [6, 1, 1, 1], [7, 1, 1, 1], [8, 1, 1, 1], [9, 1, 1, 1], [10, 1, 1, 1], [11, 1, 1, 1], [12, 1, 1, 1], [13, 1, 1, 1], [14, 1, 2, 2], [15, 1, 1, 1]]
  QKV_BIAS: True
  REL_POS_SPATIAL: True
  REL_POS_TEMPORAL: True
  REL_POS_ZERO_INIT: False
  RESIDUAL_POOLING: True
  REV:
    BUFFER_LAYERS: []
    ENABLE: False
    PRE_Q_FUSION: avg
    RESPATH_FUSE: concat
    RES_PATH: conv
  SEPARATE_QKV: False
  SEP_POS_EMBED: False
  USE_ABS_POS: False
  USE_FIXED_SINCOS_POS: False
  USE_MEAN_POOLING: False
  ZERO_DECAY_POS_CLS: False
NONLOCAL:
  GROUP: [[1], [1], [1], [1]]
  INSTANTIATION: dot_product
  LOCATION: [[[]], [[]], [[]], [[]]]
  POOL: [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]
NUM_GPUS: 4
NUM_SHARDS: 1
OUTPUT_DIR: /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4
RESNET:
  DEPTH: 50
  INPLACE_RELU: True
  NUM_BLOCK_TEMP_KERNEL: [[3], [4], [6], [3]]
  NUM_GROUPS: 1
  SPATIAL_DILATIONS: [[1], [1], [1], [1]]
  SPATIAL_STRIDES: [[1], [2], [2], [2]]
  STRIDE_1X1: False
  TRANS_FUNC: bottleneck_transform
  WIDTH_PER_GROUP: 64
  ZERO_INIT_FINAL_BN: False
  ZERO_INIT_FINAL_CONV: False
RNG_SEED: 0
SHARD_ID: 0
SLOWFAST:
  ALPHA: 8
  BETA_INV: 8
  FUSION_CONV_CHANNEL_RATIO: 2
  FUSION_KERNEL_SZ: 5
SOLVER:
  BASE_LR: 0.0001
  BASE_LR_SCALE_NUM_SHARDS: False
  BETAS: (0.9, 0.999)
  CLIP_GRAD_L2NORM: 1.0
  CLIP_GRAD_VAL: None
  COSINE_AFTER_WARMUP: False
  COSINE_END_LR: 0.0
  DAMPENING: 0.0
  GAMMA: 0.1
  LARS_ON: False
  LAYER_DECAY: 1.0
  LRS: [1, 0.1, 0.01, 0.001, 0.0001]
  LR_POLICY: steps_with_relative_lrs
  MAX_EPOCH: 60
  MOMENTUM: 0.9
  NESTEROV: True
  OPTIMIZING_METHOD: adamw
  STEPS: [0, 20, 30, 40, 50]
  STEP_SIZE: 1
  WARMUP_EPOCHS: 5.0
  WARMUP_FACTOR: 0.1
  WARMUP_START_LR: 1e-06
  WEIGHT_DECAY: 0.05
  ZERO_WD_1D_PARAM: False
TASK: 
TENSORBOARD:
  CATEGORIES_PATH: 
  CLASS_NAMES_PATH: 
  CONFUSION_MATRIX:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
  ENABLE: False
  HISTOGRAM:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
    TOPK: 10
  LOG_DIR: 
  MODEL_VIS:
    ACTIVATIONS: False
    COLORMAP: Pastel2
    ENABLE: False
    GRAD_CAM:
      COLORMAP: viridis
      ENABLE: True
      LAYER_LIST: []
      USE_TRUE_LABEL: False
    INPUT_VIDEO: False
    LAYER_LIST: []
    MODEL_WEIGHTS: False
    TOPK_PREDS: 1
  PREDICTIONS_PATH: 
  WRONG_PRED_VIS:
    ENABLE: False
    SUBSET_PATH: 
    TAG: Incorrectly classified videos.
TEST:
  BATCH_SIZE: 4
  CHECKPOINT_FILE_PATH: /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/checkpoints/checkpoint_epoch_00040.pyth
  CHECKPOINT_TYPE: pytorch
  DATASET: ava
  ENABLE: True
  NUM_ENSEMBLE_VIEWS: 5
  NUM_SPATIAL_CROPS: 1
  NUM_TEMPORAL_CLIPS: [5]
  SAVE_RESULTS_PATH: 
TRAIN:
  AUTO_RESUME: True
  BATCH_SIZE: 48
  CHECKPOINT_CLEAR_NAME_PATTERN: ()
  CHECKPOINT_EPOCH_RESET: True
  CHECKPOINT_FILE_PATH: /home/lqi/lqi_temp/trainingspace/pretrained_models/MViTv2_S_16x4.pyth
  CHECKPOINT_INFLATE: False
  CHECKPOINT_IN_INIT: False
  CHECKPOINT_PERIOD: 5
  CHECKPOINT_TYPE: pytorch
  DATASET: ava
  ENABLE: False
  EVAL_PERIOD: 5
  KILL_LOSS_EXPLOSION_FACTOR: 0.0
  MIXED_PRECISION: True
VIS_MASK:
  ENABLE: False
X3D:
  BN_LIN5: False
  BOTTLENECK_FACTOR: 1.0
  CHANNELWISE_3x3x3: True
  DEPTH_FACTOR: 1.0
  DIM_C1: 12
  DIM_C5: 2048
  SCALE_RES2: False
  WIDTH_FACTOR: 1.0
[05/08 01:48:52][INFO] misc.py:  186: Model:
DistributedDataParallel(
  (module): MViT(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
    )
    (blocks): ModuleList(
      (0): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=384, out_features=96, bias=True)
        )
      )
      (1): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
        (proj): Linear(in_features=96, out_features=192, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (2): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
      )
      (3): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
        (proj): Linear(in_features=192, out_features=384, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (4-13): 10 x MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (14): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (15): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (head): ResNetRoIHead(
      (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
      (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=768, out_features=50, bias=True)
      (act): Sigmoid()
    )
  )
)
[05/08 01:48:52][INFO] misc.py:  188: Params: 34,268,594
[05/08 01:48:52][INFO] misc.py:  189: Mem: 0.2556772232055664 MB
[05/08 01:48:54][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 489 time(s)
[05/08 01:48:54][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 68 time(s)
[05/08 01:48:54][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 96 time(s)
[05/08 01:48:54][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 64 time(s)
[05/08 01:48:54][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 80 time(s)
[05/08 01:48:54][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/08 01:48:54][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/08 01:48:54][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/08 01:48:54][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/08 01:48:54][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/08 01:48:54][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/08 01:48:54][WARNING] jit_analysis.py:  499: Unsupported operator aten::sigmoid encountered 1 time(s)
[05/08 01:48:54][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/08 01:48:54][INFO] misc.py:  191: Flops: 64.45665578399999 G
[05/08 01:48:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::layer_norm encountered 81 time(s)
[05/08 01:48:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 489 time(s)
[05/08 01:48:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 68 time(s)
[05/08 01:48:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 96 time(s)
[05/08 01:48:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 64 time(s)
[05/08 01:48:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 80 time(s)
[05/08 01:48:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/08 01:48:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/08 01:48:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/08 01:48:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/08 01:48:56][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/08 01:48:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/08 01:48:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::sigmoid encountered 1 time(s)
[05/08 01:48:56][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/08 01:48:56][INFO] misc.py:  192: Activations: 248.60871500000002 M
[05/08 01:48:56][INFO] misc.py:  197: nvidia-smi
[05/08 01:48:56][INFO] misc.py:  186: Model:
DistributedDataParallel(
  (module): MViT(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
    )
    (blocks): ModuleList(
      (0): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=384, out_features=96, bias=True)
        )
      )
      (1): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
        (proj): Linear(in_features=96, out_features=192, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (2): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
      )
      (3): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
        (proj): Linear(in_features=192, out_features=384, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (4-13): 10 x MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (14): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (15): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (head): ResNetRoIHead(
      (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
      (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=768, out_features=50, bias=True)
      (act): Sigmoid()
    )
  )
)
[05/08 01:48:56][INFO] misc.py:  188: Params: 34,268,594
[05/08 01:48:56][INFO] misc.py:  189: Mem: 1.704592227935791 MB
[05/08 01:48:57][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 489 time(s)
[05/08 01:48:57][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 68 time(s)
[05/08 01:48:57][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 96 time(s)
[05/08 01:48:57][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 64 time(s)
[05/08 01:48:57][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 80 time(s)
[05/08 01:48:57][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/08 01:48:57][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/08 01:48:57][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/08 01:48:57][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/08 01:48:57][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/08 01:48:57][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/08 01:48:57][WARNING] jit_analysis.py:  499: Unsupported operator aten::sigmoid encountered 1 time(s)
[05/08 01:48:57][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/08 01:48:57][INFO] misc.py:  191: Flops: 64.45665578399999 G
[05/08 01:48:59][WARNING] jit_analysis.py:  499: Unsupported operator aten::layer_norm encountered 81 time(s)
[05/08 01:48:59][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 489 time(s)
[05/08 01:48:59][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 68 time(s)
[05/08 01:48:59][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 96 time(s)
[05/08 01:48:59][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 64 time(s)
[05/08 01:48:59][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 80 time(s)
[05/08 01:48:59][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/08 01:48:59][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/08 01:48:59][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/08 01:48:59][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/08 01:48:59][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/08 01:48:59][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/08 01:48:59][WARNING] jit_analysis.py:  499: Unsupported operator aten::sigmoid encountered 1 time(s)
[05/08 01:48:59][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/08 01:48:59][INFO] misc.py:  192: Activations: 248.60871500000002 M
[05/08 01:48:59][INFO] misc.py:  197: nvidia-smi
[05/08 01:48:59][INFO] checkpoint.py:  213: Loading network weights from /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/checkpoints/checkpoint_epoch_00040.pyth.
[05/08 01:49:00][INFO] ava_helper.py:   58: Finished loading image paths from: ../ava/frame_lists/test.csv
[05/08 01:49:00][INFO] ava_helper.py:  139: Finished loading annotations from: ../ava/annotations/ava_test_predicted_boxes.csv
[05/08 01:49:00][INFO] ava_helper.py:  140: Detection threshold: 0.0
[05/08 01:49:00][INFO] ava_helper.py:  141: Number of unique boxes: 1136
[05/08 01:49:00][INFO] ava_helper.py:  142: Number of annotations: 0
[05/08 01:49:00][INFO] ava_helper.py:  185: 1091 keyframes used.
[05/08 01:49:00][INFO] ava_dataset.py:  130: === AVA dataset summary ===
[05/08 01:49:00][INFO] ava_dataset.py:  131: Split: test
[05/08 01:49:00][INFO] ava_dataset.py:  132: Number of videos: 953
[05/08 01:49:00][INFO] ava_dataset.py:  136: Number of frames: 85775
[05/08 01:49:00][INFO] ava_dataset.py:  137: Number of key frames: 1091
[05/08 01:49:00][INFO] ava_dataset.py:  138: Number of boxes: 1136.
[05/08 01:49:00][INFO] test_net.py:  215: Testing model for 273 iterations
[05/08 01:49:01][INFO] ava_helper.py:   58: Finished loading image paths from: ../ava/frame_lists/test.csv
[05/08 01:49:35][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "10", "eta": "0:00:34", "dt": 0.13111, "dt_data": 0.00391, "dt_net": 0.12719, "mode": "test"}
[05/08 01:49:36][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "20", "eta": "0:00:32", "dt": 0.12925, "dt_data": 0.00304, "dt_net": 0.12621, "mode": "test"}
[05/08 01:49:37][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "30", "eta": "0:00:33", "dt": 0.13577, "dt_data": 0.00340, "dt_net": 0.13237, "mode": "test"}
[05/08 01:49:39][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "40", "eta": "0:00:31", "dt": 0.13284, "dt_data": 0.00417, "dt_net": 0.12866, "mode": "test"}
[05/08 01:49:40][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "50", "eta": "0:00:29", "dt": 0.13145, "dt_data": 0.00306, "dt_net": 0.12840, "mode": "test"}
[05/08 01:49:41][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "60", "eta": "0:00:18", "dt": 0.08832, "dt_data": 0.00302, "dt_net": 0.08530, "mode": "test"}
[05/08 01:49:42][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "70", "eta": "0:00:27", "dt": 0.13319, "dt_data": 0.00310, "dt_net": 0.13008, "mode": "test"}
[05/08 01:49:44][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "80", "eta": "0:00:25", "dt": 0.13108, "dt_data": 0.00299, "dt_net": 0.12809, "mode": "test"}
[05/08 01:49:45][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "90", "eta": "0:00:24", "dt": 0.13548, "dt_data": 0.00413, "dt_net": 0.13135, "mode": "test"}
[05/08 01:49:46][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "100", "eta": "0:00:23", "dt": 0.13605, "dt_data": 0.00401, "dt_net": 0.13203, "mode": "test"}
[05/08 01:49:48][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "110", "eta": "0:00:22", "dt": 0.13532, "dt_data": 0.00457, "dt_net": 0.13075, "mode": "test"}
[05/08 01:49:49][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "120", "eta": "0:00:20", "dt": 0.13079, "dt_data": 0.00410, "dt_net": 0.12669, "mode": "test"}
[05/08 01:49:50][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "130", "eta": "0:00:19", "dt": 0.13275, "dt_data": 0.00321, "dt_net": 0.12954, "mode": "test"}
[05/08 01:49:51][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "140", "eta": "0:00:17", "dt": 0.13109, "dt_data": 0.00322, "dt_net": 0.12787, "mode": "test"}
[05/08 01:49:52][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "150", "eta": "0:00:11", "dt": 0.09183, "dt_data": 0.00312, "dt_net": 0.08871, "mode": "test"}
[05/08 01:49:54][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "160", "eta": "0:00:14", "dt": 0.12999, "dt_data": 0.00370, "dt_net": 0.12629, "mode": "test"}
[05/08 01:49:55][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "170", "eta": "0:00:13", "dt": 0.13200, "dt_data": 0.00396, "dt_net": 0.12804, "mode": "test"}
[05/08 01:49:56][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "180", "eta": "0:00:12", "dt": 0.13535, "dt_data": 0.00372, "dt_net": 0.13163, "mode": "test"}
[05/08 01:49:58][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "190", "eta": "0:00:07", "dt": 0.08852, "dt_data": 0.00295, "dt_net": 0.08557, "mode": "test"}
[05/08 01:49:59][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "200", "eta": "0:00:09", "dt": 0.13266, "dt_data": 0.00304, "dt_net": 0.12962, "mode": "test"}
[05/08 01:50:00][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "210", "eta": "0:00:08", "dt": 0.13355, "dt_data": 0.00296, "dt_net": 0.13058, "mode": "test"}
[05/08 01:50:01][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "220", "eta": "0:00:07", "dt": 0.13595, "dt_data": 0.00380, "dt_net": 0.13214, "mode": "test"}
[05/08 01:50:02][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "230", "eta": "0:00:04", "dt": 0.09196, "dt_data": 0.00335, "dt_net": 0.08861, "mode": "test"}
[05/08 01:50:04][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "240", "eta": "0:00:04", "dt": 0.13502, "dt_data": 0.00397, "dt_net": 0.13105, "mode": "test"}
[05/08 01:50:05][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "250", "eta": "0:00:03", "dt": 0.13952, "dt_data": 0.00414, "dt_net": 0.13538, "mode": "test"}
[05/08 01:50:06][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "260", "eta": "0:00:01", "dt": 0.12824, "dt_data": 0.00279, "dt_net": 0.12545, "mode": "test"}
[05/08 01:50:07][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "270", "eta": "0:00:00", "dt": 0.08832, "dt_data": 0.00285, "dt_net": 0.08547, "mode": "test"}
[05/08 01:50:09][INFO] ava_eval_helper.py:  204: Evaluating with 1091 unique GT frames.
[05/08 01:50:09][INFO] ava_eval_helper.py:  208: Evaluating with 1091 unique detection frames
[05/08 01:50:16][INFO] object_detection_evaluation.py:  751: The following classes have no ground truth examples: [ 2  4  9 13 15 16 18 19 20 21 23 25 31 32 33 35 37 39 40 41 42 44 49 50
 51 52 53 54 55 58 63 67 68 71 72 73 75 76 77]
[05/08 01:50:16][INFO] ava_eval_helper.py:  298: mAP@0.5 = 0.15144 | macro-F1 = 0.09299 | macro-AUROC = 0.78610 | macro-recall = 0.08864
[05/08 01:50:16][INFO] logging.py:   98: json_stats: {"mode": "test", "map": 0.15144, "f1_macro": 0.09299, "auroc_macro": 0.78610, "recall_macro": 0.08864}
[05/08 01:50:16][INFO] ava_eval_helper.py:  469: AVA results wrote to /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/detections_test.csv
[05/08 01:50:16][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/08 01:50:16][INFO] meters.py:  327: Saved CSVs:
  per-class AP: /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/ap_per_class_test.csv
  detections: /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/detections_test.csv
[05/08 01:50:16][INFO] test_net.py:  256: Finalized testing with 5 temporal clips and 1 spatial crops
[05/08 01:50:16][INFO] test_net.py:  275: _p34.27_f64.46_5a15.14 Top5 Acc: 15.14 MEM: 2.22 f: 64.4567
[05/08 01:50:16][INFO] test_net.py:  276: _p34.27_f64.46_5a15.14
[05/13 22:54:12][INFO] test_net.py:  188: Test with config:
[05/13 22:54:12][INFO] test_net.py:  189: AUG:
  AA_TYPE: rand-m7-n4-mstd0.5-inc1
  COLOR_JITTER: 0.4
  ENABLE: True
  GEN_MASK_LOADER: False
  INTERPOLATION: bicubic
  MASK_FRAMES: False
  MASK_RATIO: 0.0
  MASK_TUBE: False
  MASK_WINDOW_SIZE: [8, 7, 7]
  MAX_MASK_PATCHES_PER_BLOCK: None
  NUM_SAMPLE: 2
  RE_COUNT: 1
  RE_MODE: pixel
  RE_PROB: 0.25
  RE_SPLIT: False
AVA:
  ANNOTATION_DIR: ../ava/annotations
  BGR: False
  DETECTION_SCORE_THRESH: 0.0
  EXCLUSION_FILE: ava_val_excluded_timestamps_v2.2.csv
  FRAME_DIR: ../ava/frames
  FRAME_LIST_DIR: ../ava/frame_lists
  FULL_TEST_ON_VAL: True
  GROUNDTRUTH_FILE: ava_test_gt.csv
  IMG_PROC_BACKEND: cv2
  LABEL_MAP_FILE: label_map.pbtxt
  TEST_FORCE_FLIP: False
  TEST_LISTS: ['test.csv']
  TEST_PREDICT_BOX_LISTS: ['ava_test_predicted_boxes.csv']
  TRAIN_GT_BOX_LISTS: ['ava_train.csv']
  TRAIN_LISTS: ['train.csv']
  TRAIN_PCA_JITTER_ONLY: True
  TRAIN_PREDICT_BOX_LISTS: []
  TRAIN_USE_COLOR_AUGMENTATION: False
BENCHMARK:
  LOG_PERIOD: 100
  NUM_EPOCHS: 5
  SHUFFLE: True
BN:
  GLOBAL_SYNC: False
  NORM_TYPE: batchnorm
  NUM_BATCHES_PRECISE: 200
  NUM_SPLITS: 1
  NUM_SYNC_DEVICES: 1
  USE_PRECISE_STATS: False
  WEIGHT_DECAY: 0.0
CONTRASTIVE:
  BN_MLP: False
  BN_SYNC_MLP: False
  DELTA_CLIPS_MAX: inf
  DELTA_CLIPS_MIN: -inf
  DIM: 128
  INTERP_MEMORY: False
  KNN_ON: True
  LENGTH: 239975
  LOCAL_SHUFFLE_BN: True
  MEM_TYPE: 1d
  MLP_DIM: 2048
  MOCO_MULTI_VIEW_QUEUE: False
  MOMENTUM: 0.5
  MOMENTUM_ANNEALING: False
  NUM_CLASSES_DOWNSTREAM: 400
  NUM_MLP_LAYERS: 1
  PREDICTOR_DEPTHS: []
  QUEUE_LEN: 65536
  SEQUENTIAL: False
  SIMCLR_DIST_ON: True
  SWAV_QEUE_LEN: 0
  T: 0.07
  TYPE: mem
DATA:
  COLOR_RND_GRAYSCALE: 0.0
  DECODING_BACKEND: torchvision
  DECODING_SHORT_SIZE: 256
  DUMMY_LOAD: False
  ENSEMBLE_METHOD: sum
  IN22K_TRAINVAL: False
  IN22k_VAL_IN1K: 
  INPUT_CHANNEL_NUM: [3]
  INV_UNIFORM_SAMPLE: False
  IN_VAL_CROP_RATIO: 0.875
  LOADER_CHUNK_OVERALL_SIZE: 0
  LOADER_CHUNK_SIZE: 0
  MEAN: [0.45, 0.45, 0.45]
  MULTI_LABEL: False
  NUM_FRAMES: 16
  PATH_LABEL_SEPARATOR:  
  PATH_PREFIX: 
  PATH_TO_DATA_DIR: ../ava
  PATH_TO_PRELOAD_IMDB: 
  RANDOM_FLIP: True
  REVERSE_INPUT_CHANNEL: False
  SAMPLING_RATE: 4
  SKIP_ROWS: 0
  SSL_BLUR_SIGMA_MAX: [0.0, 2.0]
  SSL_BLUR_SIGMA_MIN: [0.0, 0.1]
  SSL_COLOR_BRI_CON_SAT: [0.4, 0.4, 0.4]
  SSL_COLOR_HUE: 0.1
  SSL_COLOR_JITTER: False
  SSL_MOCOV2_AUG: False
  STD: [0.225, 0.225, 0.225]
  TARGET_FPS: 30
  TEST_CROP_SIZE: 224
  TIME_DIFF_PROB: 0.0
  TRAIN_CROP_NUM_SPATIAL: 1
  TRAIN_CROP_NUM_TEMPORAL: 1
  TRAIN_CROP_SIZE: 224
  TRAIN_JITTER_ASPECT_RELATIVE: [0.75, 1.3333]
  TRAIN_JITTER_FPS: 0.0
  TRAIN_JITTER_MOTION_SHIFT: False
  TRAIN_JITTER_SCALES: [256, 320]
  TRAIN_JITTER_SCALES_RELATIVE: [0.08, 1.0]
  TRAIN_PCA_EIGVAL: [0.225, 0.224, 0.229]
  TRAIN_PCA_EIGVEC: [[-0.5675, 0.7192, 0.4009], [-0.5808, -0.0045, -0.814], [-0.5836, -0.6948, 0.4203]]
  USE_OFFSET_SAMPLING: True
DATA_LOADER:
  ENABLE_MULTI_THREAD_DECODE: False
  NUM_WORKERS: 8
  PIN_MEMORY: True
DEMO:
  BUFFER_SIZE: 0
  CLIP_VIS_SIZE: 10
  COMMON_CLASS_NAMES: ['watch (a person)', 'talk to (e.g., self, a person, a group)', 'listen to (a person)', 'touch (an object)', 'carry/hold (an object)', 'walk', 'sit', 'lie/sleep', 'bend/bow (at the waist)']
  COMMON_CLASS_THRES: 0.7
  DETECTRON2_CFG: COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml
  DETECTRON2_THRESH: 0.9
  DETECTRON2_WEIGHTS: detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
  DISPLAY_HEIGHT: 0
  DISPLAY_WIDTH: 0
  ENABLE: False
  FPS: 30
  GT_BOXES: 
  INPUT_FORMAT: BGR
  INPUT_VIDEO: 
  LABEL_FILE_PATH: 
  NUM_CLIPS_SKIP: 0
  NUM_VIS_INSTANCES: 2
  OUTPUT_FILE: 
  OUTPUT_FPS: -1
  PREDS_BOXES: 
  SLOWMO: 1
  STARTING_SECOND: 900
  THREAD_ENABLE: False
  UNCOMMON_CLASS_THRES: 0.3
  VIS_MODE: thres
  WEBCAM: -1
DETECTION:
  ALIGNED: True
  ENABLE: True
  ROI_XFORM_RESOLUTION: 7
  SPATIAL_SCALE_FACTOR: 16
DIST_BACKEND: nccl
LOG_MODEL_INFO: True
LOG_PERIOD: 10
MASK:
  DECODER_DEPTH: 0
  DECODER_EMBED_DIM: 512
  DECODER_SEP_POS_EMBED: False
  DEC_KV_KERNEL: []
  DEC_KV_STRIDE: []
  ENABLE: False
  HEAD_TYPE: separate
  MAE_ON: False
  MAE_RND_MASK: False
  NORM_PRED_PIXEL: True
  PER_FRAME_MASKING: False
  PRED_HOG: False
  PRETRAIN_DEPTH: [15]
  SCALE_INIT_BY_DEPTH: False
  TIME_STRIDE_LOSS: True
MIXUP:
  ALPHA: 0.8
  CUTMIX_ALPHA: 1.0
  ENABLE: False
  LABEL_SMOOTH_VALUE: 0.1
  PROB: 1.0
  SWITCH_PROB: 0.5
MODEL:
  ACT_CHECKPOINT: False
  ARCH: mvit
  BLIP2:
    FREEZE: True
    PRETRAINED: Salesforce/blip2-flan-t5-xl
  DETACH_FINAL_FC: False
  DROPCONNECT_RATE: 0.0
  DROPOUT_RATE: 0.5
  FC_INIT_STD: 0.01
  FP16_ALLREDUCE: False
  FROZEN_BN: False
  HEAD_ACT: none
  LOSS_FUNC: bce_logit
  MODEL_NAME: MViT
  MULTI_PATHWAY_ARCH: ['slowfast']
  NUM_CLASSES: 50
  SINGLE_PATHWAY_ARCH: ['2d', 'c2d', 'i3d', 'slow', 'x3d', 'mvit', 'maskmvit', 'blip2']
MULTIGRID:
  BN_BASE_SIZE: 8
  DEFAULT_B: 0
  DEFAULT_S: 0
  DEFAULT_T: 0
  EPOCH_FACTOR: 1.5
  EVAL_FREQ: 3
  LONG_CYCLE: False
  LONG_CYCLE_FACTORS: [(0.25, 0.7071067811865476), (0.5, 0.7071067811865476), (0.5, 1), (1, 1)]
  LONG_CYCLE_SAMPLING_RATE: 0
  SHORT_CYCLE: False
  SHORT_CYCLE_FACTORS: [0.5, 0.7071067811865476]
MVIT:
  CLS_EMBED_ON: True
  DEPTH: 16
  DIM_MUL: [[1, 2.0], [3, 2.0], [14, 2.0]]
  DIM_MUL_IN_ATT: True
  DROPOUT_RATE: 0.0
  DROPPATH_RATE: 0.2
  EMBED_DIM: 96
  HEAD_INIT_SCALE: 1.0
  HEAD_MUL: [[1, 2.0], [3, 2.0], [14, 2.0]]
  LAYER_SCALE_INIT_VALUE: 0.0
  MLP_RATIO: 4.0
  MODE: conv
  NORM: layernorm
  NORM_STEM: False
  NUM_HEADS: 1
  PATCH_2D: False
  PATCH_KERNEL: [3, 7, 7]
  PATCH_PADDING: [1, 3, 3]
  PATCH_STRIDE: [2, 4, 4]
  POOL_FIRST: False
  POOL_KVQ_KERNEL: [3, 3, 3]
  POOL_KV_STRIDE: []
  POOL_KV_STRIDE_ADAPTIVE: [1, 8, 8]
  POOL_Q_STRIDE: [[0, 1, 1, 1], [1, 1, 2, 2], [2, 1, 1, 1], [3, 1, 2, 2], [4, 1, 1, 1], [5, 1, 1, 1], [6, 1, 1, 1], [7, 1, 1, 1], [8, 1, 1, 1], [9, 1, 1, 1], [10, 1, 1, 1], [11, 1, 1, 1], [12, 1, 1, 1], [13, 1, 1, 1], [14, 1, 2, 2], [15, 1, 1, 1]]
  QKV_BIAS: True
  REL_POS_SPATIAL: True
  REL_POS_TEMPORAL: True
  REL_POS_ZERO_INIT: False
  RESIDUAL_POOLING: True
  REV:
    BUFFER_LAYERS: []
    ENABLE: False
    PRE_Q_FUSION: avg
    RESPATH_FUSE: concat
    RES_PATH: conv
  SEPARATE_QKV: False
  SEP_POS_EMBED: False
  USE_ABS_POS: False
  USE_FIXED_SINCOS_POS: False
  USE_MEAN_POOLING: False
  ZERO_DECAY_POS_CLS: False
NONLOCAL:
  GROUP: [[1], [1], [1], [1]]
  INSTANTIATION: dot_product
  LOCATION: [[[]], [[]], [[]], [[]]]
  POOL: [[[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]], [[1, 2, 2], [1, 2, 2]]]
NUM_GPUS: 4
NUM_SHARDS: 1
OUTPUT_DIR: /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4
RESNET:
  DEPTH: 50
  INPLACE_RELU: True
  NUM_BLOCK_TEMP_KERNEL: [[3], [4], [6], [3]]
  NUM_GROUPS: 1
  SPATIAL_DILATIONS: [[1], [1], [1], [1]]
  SPATIAL_STRIDES: [[1], [2], [2], [2]]
  STRIDE_1X1: False
  TRANS_FUNC: bottleneck_transform
  WIDTH_PER_GROUP: 64
  ZERO_INIT_FINAL_BN: False
  ZERO_INIT_FINAL_CONV: False
RNG_SEED: 0
SHARD_ID: 0
SLOWFAST:
  ALPHA: 8
  BETA_INV: 8
  FUSION_CONV_CHANNEL_RATIO: 2
  FUSION_KERNEL_SZ: 5
SOLVER:
  BASE_LR: 0.0001
  BASE_LR_SCALE_NUM_SHARDS: False
  BETAS: (0.9, 0.999)
  CLIP_GRAD_L2NORM: 1.0
  CLIP_GRAD_VAL: None
  COSINE_AFTER_WARMUP: False
  COSINE_END_LR: 0.0
  DAMPENING: 0.0
  GAMMA: 0.1
  LARS_ON: False
  LAYER_DECAY: 1.0
  LRS: [1, 0.1, 0.01, 0.001, 0.0001]
  LR_POLICY: steps_with_relative_lrs
  MAX_EPOCH: 60
  MOMENTUM: 0.9
  NESTEROV: True
  OPTIMIZING_METHOD: adamw
  STEPS: [0, 20, 30, 40, 50]
  STEP_SIZE: 1
  WARMUP_EPOCHS: 5.0
  WARMUP_FACTOR: 0.1
  WARMUP_START_LR: 1e-06
  WEIGHT_DECAY: 0.05
  ZERO_WD_1D_PARAM: False
TASK: 
TENSORBOARD:
  CATEGORIES_PATH: 
  CLASS_NAMES_PATH: 
  CONFUSION_MATRIX:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
  ENABLE: False
  HISTOGRAM:
    ENABLE: False
    FIGSIZE: [8, 8]
    SUBSET_PATH: 
    TOPK: 10
  LOG_DIR: 
  MODEL_VIS:
    ACTIVATIONS: False
    COLORMAP: Pastel2
    ENABLE: False
    GRAD_CAM:
      COLORMAP: viridis
      ENABLE: True
      LAYER_LIST: []
      USE_TRUE_LABEL: False
    INPUT_VIDEO: False
    LAYER_LIST: []
    MODEL_WEIGHTS: False
    TOPK_PREDS: 1
  PREDICTIONS_PATH: 
  WRONG_PRED_VIS:
    ENABLE: False
    SUBSET_PATH: 
    TAG: Incorrectly classified videos.
TEST:
  BATCH_SIZE: 4
  CHECKPOINT_FILE_PATH: /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/checkpoints/checkpoint_epoch_00040.pyth
  CHECKPOINT_TYPE: pytorch
  DATASET: ava
  ENABLE: True
  NUM_ENSEMBLE_VIEWS: 5
  NUM_SPATIAL_CROPS: 1
  NUM_TEMPORAL_CLIPS: [5]
  SAVE_RESULTS_PATH: 
TRAIN:
  AUTO_RESUME: True
  BATCH_SIZE: 48
  CHECKPOINT_CLEAR_NAME_PATTERN: ()
  CHECKPOINT_EPOCH_RESET: True
  CHECKPOINT_FILE_PATH: /home/lqi/lqi_temp/trainingspace/pretrained_models/MViTv2_S_16x4.pyth
  CHECKPOINT_INFLATE: False
  CHECKPOINT_IN_INIT: False
  CHECKPOINT_PERIOD: 5
  CHECKPOINT_TYPE: pytorch
  DATASET: ava
  ENABLE: False
  EVAL_PERIOD: 5
  KILL_LOSS_EXPLOSION_FACTOR: 0.0
  MIXED_PRECISION: True
VIS_MASK:
  ENABLE: False
X3D:
  BN_LIN5: False
  BOTTLENECK_FACTOR: 1.0
  CHANNELWISE_3x3x3: True
  DEPTH_FACTOR: 1.0
  DIM_C1: 12
  DIM_C5: 2048
  SCALE_RES2: False
  WIDTH_FACTOR: 1.0
[05/13 22:54:15][INFO] misc.py:  186: Model:
DistributedDataParallel(
  (module): MViT(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
    )
    (blocks): ModuleList(
      (0): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=384, out_features=96, bias=True)
        )
      )
      (1): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
        (proj): Linear(in_features=96, out_features=192, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (2): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
      )
      (3): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
        (proj): Linear(in_features=192, out_features=384, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (4-13): 10 x MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (14): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (15): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (head): ResNetRoIHead(
      (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
      (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=768, out_features=50, bias=True)
      (act): Identity()
    )
  )
)
[05/13 22:54:15][INFO] misc.py:  188: Params: 34,268,594
[05/13 22:54:15][INFO] misc.py:  189: Mem: 0.2556772232055664 MB
[05/13 22:54:16][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 489 time(s)
[05/13 22:54:16][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 68 time(s)
[05/13 22:54:16][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 96 time(s)
[05/13 22:54:16][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 64 time(s)
[05/13 22:54:16][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 80 time(s)
[05/13 22:54:16][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/13 22:54:16][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/13 22:54:16][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/13 22:54:16][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/13 22:54:16][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/13 22:54:16][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/13 22:54:16][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/13 22:54:16][INFO] misc.py:  191: Flops: 64.45665578399999 G
[05/13 22:54:18][WARNING] jit_analysis.py:  499: Unsupported operator aten::layer_norm encountered 81 time(s)
[05/13 22:54:18][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 489 time(s)
[05/13 22:54:18][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 68 time(s)
[05/13 22:54:18][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 96 time(s)
[05/13 22:54:18][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 64 time(s)
[05/13 22:54:18][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 80 time(s)
[05/13 22:54:18][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/13 22:54:18][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/13 22:54:18][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/13 22:54:18][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/13 22:54:18][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/13 22:54:18][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/13 22:54:18][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/13 22:54:18][INFO] misc.py:  192: Activations: 248.60871500000002 M
[05/13 22:54:18][INFO] misc.py:  197: nvidia-smi
[05/13 22:54:18][INFO] misc.py:  186: Model:
DistributedDataParallel(
  (module): MViT(
    (patch_embed): PatchEmbed(
      (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
    )
    (blocks): ModuleList(
      (0): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=288, bias=True)
          (proj): Linear(in_features=96, out_features=96, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=96, out_features=384, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=384, out_features=96, bias=True)
        )
      )
      (1): MultiScaleBlock(
        (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=96, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
        (proj): Linear(in_features=96, out_features=192, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (2): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=576, bias=True)
          (proj): Linear(in_features=192, out_features=192, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=192, out_features=768, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=768, out_features=192, bias=True)
        )
      )
      (3): MultiScaleBlock(
        (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=192, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
        (proj): Linear(in_features=192, out_features=384, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (4-13): 10 x MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=1152, bias=True)
          (proj): Linear(in_features=384, out_features=384, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=384, out_features=1536, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=1536, out_features=384, bias=True)
        )
      )
      (14): MultiScaleBlock(
        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=384, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
        (proj): Linear(in_features=384, out_features=768, bias=True)
        (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
      )
      (15): MultiScaleBlock(
        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (attn): MultiScaleAttention(
          (qkv): Linear(in_features=768, out_features=2304, bias=True)
          (proj): Linear(in_features=768, out_features=768, bias=True)
          (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
          (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
          (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
        )
      )
    )
    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
    (head): ResNetRoIHead(
      (s0_tpool): AvgPool3d(kernel_size=[8, 1, 1], stride=1, padding=0)
      (s0_roi): ROIAlign(output_size=[7, 7], spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      (s0_spool): MaxPool2d(kernel_size=[7, 7], stride=1, padding=0, dilation=1, ceil_mode=False)
      (dropout): Dropout(p=0.5, inplace=False)
      (projection): Linear(in_features=768, out_features=50, bias=True)
      (act): Identity()
    )
  )
)
[05/13 22:54:18][INFO] misc.py:  188: Params: 34,268,594
[05/13 22:54:18][INFO] misc.py:  189: Mem: 1.704592227935791 MB
[05/13 22:54:19][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 489 time(s)
[05/13 22:54:19][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 68 time(s)
[05/13 22:54:19][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 96 time(s)
[05/13 22:54:19][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 64 time(s)
[05/13 22:54:19][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 80 time(s)
[05/13 22:54:19][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/13 22:54:19][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/13 22:54:19][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/13 22:54:19][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/13 22:54:19][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/13 22:54:19][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/13 22:54:19][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/13 22:54:19][INFO] misc.py:  191: Flops: 64.45665578399999 G
[05/13 22:54:21][WARNING] jit_analysis.py:  499: Unsupported operator aten::layer_norm encountered 81 time(s)
[05/13 22:54:21][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 489 time(s)
[05/13 22:54:21][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 68 time(s)
[05/13 22:54:21][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 96 time(s)
[05/13 22:54:21][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 64 time(s)
[05/13 22:54:21][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 80 time(s)
[05/13 22:54:21][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 16 time(s)
[05/13 22:54:21][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 16 time(s)
[05/13 22:54:21][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 3 time(s)
[05/13 22:54:21][WARNING] jit_analysis.py:  499: Unsupported operator aten::avg_pool3d encountered 1 time(s)
[05/13 22:54:21][WARNING] jit_analysis.py:  499: Unsupported operator torchvision::roi_align encountered 1 time(s)
[05/13 22:54:21][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool2d encountered 1 time(s)
[05/13 22:54:21][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
module.blocks.1.drop_path, module.blocks.10.drop_path, module.blocks.11.drop_path, module.blocks.12.drop_path, module.blocks.13.drop_path, module.blocks.14.drop_path, module.blocks.15.drop_path, module.blocks.2.drop_path, module.blocks.3.drop_path, module.blocks.4.drop_path, module.blocks.5.drop_path, module.blocks.6.drop_path, module.blocks.7.drop_path, module.blocks.8.drop_path, module.blocks.9.drop_path
[05/13 22:54:21][INFO] misc.py:  192: Activations: 248.60871500000002 M
[05/13 22:54:21][INFO] misc.py:  197: nvidia-smi
[05/13 22:54:21][INFO] checkpoint.py:  213: Loading network weights from /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/checkpoints/checkpoint_epoch_00040.pyth.
[05/13 22:54:24][INFO] ava_helper.py:   58: Finished loading image paths from: ../ava/frame_lists/test.csv
[05/13 22:54:24][INFO] ava_helper.py:  139: Finished loading annotations from: ../ava/annotations/ava_test_predicted_boxes.csv
[05/13 22:54:24][INFO] ava_helper.py:  140: Detection threshold: 0.0
[05/13 22:54:24][INFO] ava_helper.py:  141: Number of unique boxes: 1136
[05/13 22:54:24][INFO] ava_helper.py:  142: Number of annotations: 0
[05/13 22:54:24][INFO] ava_helper.py:  185: 1091 keyframes used.
[05/13 22:54:24][INFO] ava_dataset.py:  130: === AVA dataset summary ===
[05/13 22:54:24][INFO] ava_dataset.py:  131: Split: test
[05/13 22:54:24][INFO] ava_dataset.py:  132: Number of videos: 953
[05/13 22:54:24][INFO] ava_dataset.py:  136: Number of frames: 85775
[05/13 22:54:24][INFO] ava_dataset.py:  137: Number of key frames: 1091
[05/13 22:54:24][INFO] ava_dataset.py:  138: Number of boxes: 1136.
[05/13 22:54:24][INFO] test_net.py:  215: Testing model for 273 iterations
[05/13 22:54:24][INFO] ava_helper.py:   58: Finished loading image paths from: ../ava/frame_lists/test.csv
[05/13 22:54:58][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "10", "eta": "0:00:34", "dt": 0.13030, "dt_data": 0.00370, "dt_net": 0.12660, "mode": "test"}
[05/13 22:54:59][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "20", "eta": "0:00:32", "dt": 0.12954, "dt_data": 0.00362, "dt_net": 0.12592, "mode": "test"}
[05/13 22:55:00][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "30", "eta": "0:00:32", "dt": 0.13250, "dt_data": 0.00396, "dt_net": 0.12855, "mode": "test"}
[05/13 22:55:01][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "40", "eta": "0:00:31", "dt": 0.13352, "dt_data": 0.00392, "dt_net": 0.12960, "mode": "test"}
[05/13 22:55:03][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "50", "eta": "0:00:29", "dt": 0.12973, "dt_data": 0.00295, "dt_net": 0.12678, "mode": "test"}
[05/13 22:55:04][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "60", "eta": "0:00:18", "dt": 0.08770, "dt_data": 0.00298, "dt_net": 0.08472, "mode": "test"}
[05/13 22:55:05][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "70", "eta": "0:00:27", "dt": 0.13255, "dt_data": 0.00312, "dt_net": 0.12943, "mode": "test"}
[05/13 22:55:07][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "80", "eta": "0:00:25", "dt": 0.13247, "dt_data": 0.00299, "dt_net": 0.12948, "mode": "test"}
[05/13 22:55:08][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "90", "eta": "0:00:24", "dt": 0.13461, "dt_data": 0.00386, "dt_net": 0.13075, "mode": "test"}
[05/13 22:55:09][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "100", "eta": "0:00:23", "dt": 0.13379, "dt_data": 0.00412, "dt_net": 0.12967, "mode": "test"}
[05/13 22:55:10][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "110", "eta": "0:00:21", "dt": 0.13237, "dt_data": 0.00366, "dt_net": 0.12871, "mode": "test"}
[05/13 22:55:12][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "120", "eta": "0:00:20", "dt": 0.13257, "dt_data": 0.00399, "dt_net": 0.12858, "mode": "test"}
[05/13 22:55:13][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "130", "eta": "0:00:18", "dt": 0.13071, "dt_data": 0.00321, "dt_net": 0.12750, "mode": "test"}
[05/13 22:55:14][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "140", "eta": "0:00:17", "dt": 0.13043, "dt_data": 0.00311, "dt_net": 0.12732, "mode": "test"}
[05/13 22:55:15][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "150", "eta": "0:00:11", "dt": 0.09455, "dt_data": 0.00307, "dt_net": 0.09148, "mode": "test"}
[05/13 22:55:17][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "160", "eta": "0:00:15", "dt": 0.13329, "dt_data": 0.00397, "dt_net": 0.12932, "mode": "test"}
[05/13 22:55:18][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "170", "eta": "0:00:14", "dt": 0.13526, "dt_data": 0.00388, "dt_net": 0.13137, "mode": "test"}
[05/13 22:55:19][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "180", "eta": "0:00:12", "dt": 0.13139, "dt_data": 0.00422, "dt_net": 0.12717, "mode": "test"}
[05/13 22:55:20][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "190", "eta": "0:00:07", "dt": 0.09050, "dt_data": 0.00336, "dt_net": 0.08714, "mode": "test"}
[05/13 22:55:22][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "200", "eta": "0:00:09", "dt": 0.12980, "dt_data": 0.00305, "dt_net": 0.12675, "mode": "test"}
[05/13 22:55:23][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "210", "eta": "0:00:08", "dt": 0.13367, "dt_data": 0.00299, "dt_net": 0.13068, "mode": "test"}
[05/13 22:55:24][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "220", "eta": "0:00:07", "dt": 0.13303, "dt_data": 0.00448, "dt_net": 0.12855, "mode": "test"}
[05/13 22:55:25][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "230", "eta": "0:00:04", "dt": 0.09156, "dt_data": 0.00358, "dt_net": 0.08797, "mode": "test"}
[05/13 22:55:27][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "240", "eta": "0:00:04", "dt": 0.13218, "dt_data": 0.00372, "dt_net": 0.12846, "mode": "test"}
[05/13 22:55:28][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "250", "eta": "0:00:03", "dt": 0.13645, "dt_data": 0.00407, "dt_net": 0.13238, "mode": "test"}
[05/13 22:55:29][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "260", "eta": "0:00:01", "dt": 0.12789, "dt_data": 0.00276, "dt_net": 0.12513, "mode": "test"}
[05/13 22:55:30][INFO] logging.py:   98: json_stats: {"_type": "test_iter", "cur_iter": "270", "eta": "0:00:00", "dt": 0.08771, "dt_data": 0.00290, "dt_net": 0.08481, "mode": "test"}
[05/13 22:55:32][INFO] ava_eval_helper.py:  204: Evaluating with 1091 unique GT frames.
[05/13 22:55:32][INFO] ava_eval_helper.py:  208: Evaluating with 1091 unique detection frames
[05/13 22:55:38][INFO] object_detection_evaluation.py:  751: The following classes have no ground truth examples: [ 2  4  9 13 15 16 18 19 20 21 23 25 31 32 33 35 37 39 40 41 42 44 49 50
 51 52 53 54 55 58 63 67 68 71 72 73 75 76 77]
[05/13 22:55:39][INFO] ava_eval_helper.py:  298: mAP@0.5 = 0.15144 | macro-F1 = 0.08155 | macro-AUROC = 0.78610 | macro-recall = 0.07168
[05/13 22:55:39][INFO] logging.py:   98: json_stats: {"mode": "test", "map": 0.15144, "f1_macro": 0.08155, "auroc_macro": 0.78610, "recall_macro": 0.07168}
[05/13 22:55:39][INFO] ava_eval_helper.py:  469: AVA results wrote to /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/detections_test.csv
[05/13 22:55:39][INFO] ava_eval_helper.py:  470: 	took 0 seconds.
[05/13 22:55:39][INFO] meters.py:  327: Saved CSVs:
  per-class AP: /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/ap_per_class_test.csv
  detections: /home/lqi/lqi_temp/trainingspace/results/MVITv2_S_16x4/detailed_csv/detections_test.csv
[05/13 22:55:39][INFO] test_net.py:  256: Finalized testing with 5 temporal clips and 1 spatial crops
[05/13 22:55:39][INFO] test_net.py:  275: _p34.27_f64.46_5a15.14 Top5 Acc: 15.14 MEM: 2.22 f: 64.4567
[05/13 22:55:39][INFO] test_net.py:  276: _p34.27_f64.46_5a15.14
